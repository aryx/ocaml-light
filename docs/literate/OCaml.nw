\documentclass[12pt]{report}
%12pt, twocolumn, landscape

%******************************************************************************
% Prelude
%******************************************************************************
\newif\iffinal
\newif\ifverbose
\finaltrue\verbosefalse % see also other newif in Macros.tex

%------------------------------------------------------------------------------
%history: 
%------------------------------------------------------------------------------

%thx to LP, I changed for the better a few things:
% - found deadcode in ocaml itself :) with some still in ocaml 4.00
%   (all.ml, codegen.ml, a few functions, Ident.equal)
% - found duplicated code (debug_info)
 

%thx to codemap/codegraph/scheck:
% - use cg to to look at backward deps (but the linker already enforces layers)
%   (harder to understand non layered code)
% - use scheck to remove deadcode, found some even in latest ocaml :)
%   (harder to understand big files)
% - TODO use cg to reduce number of globals by moving them closer to the
%   relevant file (or even function), better cluster the code
%   (harder to understand non functional code using lots of globals)

%thx to this manual, better understand OCaml:
% - TODO how a GC works, the root
% - SEMI how values are represented at runtime, the Obj module
%   for a long time I didn't have a good idea of how (Foo 1) was
%   represented in memory exactly
% - TODO how compiler backends work (register, liveness, etc)
% - how type inference works in ocaml itself,
%   type schema, generalization, instantiation, value restriction (partially)
% - bootstrapping, so simple, make bootstrap
% - SEMI the -custom, libs, libxxx.a, etc
% - setitimer and SIGVTALRM and how to write a user-level scheduler
% - how a simple thread scheduler works
% - TODO fast compilation of match on string? transformed in hashtbl?
%   similar to compilation of switch in C?
% - TODO when have let f x = let bigarray = Array.create ... in 
%   do we get a new bigarray allocated each time we call f?
% - how ocamlc and ocamlrun agree with each other to get
%   a primitive binding
% - how ocamlc and ocamlrun manage external C libs (e.g. libunix.a)
% - TODO how is compiled toplevel globals with complex expression value
%   like let x = Array.create 10 (complex_function())? when executed?

%history LP-ization:
% - skeleton, mostly copy paste of Template.nw skeleton
% - put all content of files in the Extra section, via 'pfff -lpize'
%   which also now split in chunks!
%    * function, type, exception, constant
%    * TODO ctor/dtor, dumper
%    * TODO [[xxx]] other fields, [[xxx]] extra fields
% - read Extra section, identify concepts, first TOC
% - SEMI distribute parts of the Extra section in the main file
% - SEMI understand main(), LP split main, improve TOC
% - SEMI understand main functions, LP split, cluster, improve TOC
% - SEMI LP split the structures, use datalog for flow to field info
% - SEMI scheckify, plan9ify
% - SEMI aspecify advanced features! remove useless features, error, debug, 
%        secu
% - TODO add figures
% - TODO add explanations

%------------------------------------------------------------------------------
% Packages
%------------------------------------------------------------------------------

\usepackage{xspace}
\usepackage{verbatim}
%note: required by 'syncweb -to_tex' for the \t \l \n in this file
\usepackage{fancyvrb}
\usepackage{url}
\usepackage{hyperref}
 \hypersetup{colorlinks=true}
\usepackage[pageref]{backref}
 \def\backref{{\footnotesize cited page(s)}~}
\usepackage{booktabs} 
 \newcommand{\otoprule}{\midrule[\heavyrulewidth]}
\usepackage{graphicx}

\input{../docs/latex/Config}
\usepackage{../docs/latex/noweb}
 \noweboptions{footnotesizecode,nomargintag}
 %note: allow chunk on different pages, less white space at bottom of pages
 \def\nwendcode{\endtrivlist \endgroup}
 \let\nwdocspar=\par
\usepackage{../docs/latex/syncweb}

%------------------------------------------------------------------------------
% Macros
%------------------------------------------------------------------------------
\input{../docs/latex/Macros}

%------------------------------------------------------------------------------
% Config
%------------------------------------------------------------------------------
\allcodefalse
% ifallcode is used for:
% - extra copyright, 
% - composite operations optimisations in interprete()
% - native compiler (but at some point should be explained and part of the book)

\begin{document}
%******************************************************************************
% Title
%******************************************************************************
\title{
{\Huge 
Principia Softwarica: The OCaml (Light) Compilers
}\\
{version 0.1}
}
%less: OCaml light? Caml Special Light (after all what I have is close
% to csl and I should have forked from there)
%note: compilers, with an s, ocamlc and ocamlopt

\author{
Yoann Padioleau\\
\texttt{yoann.padioleau@gmail.com}\\
\\
with code from\\
Xavier Leroy and Damien Doligez
}


\maketitle 

%\onecolumn
\hrule
\begin{quote}
Copyright \copyright{} 2015 Yoann Padioleau \\
Permission is granted to copy, distribute and/or modify this document,
except all the source code it contains, under the terms of the GNU Free
Documentation License, Version 1.3.
\end{quote}
\hrule
%\twocolumn

\begingroup
\hypersetup{linkcolor=blue}
% need to s/onecolumn/twocolumn in report.cls :) for \tableofcontents
\tableofcontents
\endgroup

%******************************************************************************
% Body
%******************************************************************************

\chapter{Introduction}

The goal of this book is to present with full details the source code of
a {compiler} for the functional language ML.
\l \cite (higher than C), 

\section{Motivations}

Why? Because I think you are better programmer 
if you fully understand how things work under the hood, and 
given that more and more programs are written in
dialects of this language (Haskell, OCaml, Scala, F\#, Swift, etc),
and that many of its features are now incorporated in 
mainstream languages (closures, type inference, etc),
I think it is important to understand how this language is implemented.

% Good increments over C (see section below in first chapter).

Here are a few questions I hope this book will answer:
\begin{itemize}
\item How are implemented closures?

\item How does garbage collection work?

\item How does ML compare to the lambda calculus?

\item How records, variants, lists, and more are represented internally
in memory?

\end{itemize}

\section{OCaml light}

% I chose Ocaml because good compromise! functional, and imperative.
% I removed parts that were more complicated:
%  - objects
%  - functors
% (indeed they were not that used in the code of ocaml itself ... hmm)
% And the compiler code is quite elegant.

%%good to vary a bit, not always C code written by the same people :)
%%and also different language! help also to explore concepts for Compiler.nw

%20 years anniversary! (of caml special light actually)
% https://sympa.inria.fr/sympa/arc/caml-list/2015-09/msg00079.html
% actually I show mostly this code :) the old version code in this book

\section{Other high-level languages}

Here are other high-level programming languages that I considered
for this book but which I ultimately discarded:
\begin{itemize}
\item Scheme
% not typed, no ADT, but some nice things: macros, call/cc, eval
\item SML
% not active
\item Haskell
% nice but lazy, and too strict (no pun intended) forcing programmer
% to be purely functional (or to use intrusive and complex monads IO),
% but some nice things to steal (typeclasses, deriving, monadic do)
\item Scala
% too big, don't need objects anyway.
% implicits are nice, but controversial, just like OO they can
% lead to spaghetti code or hard to follow code
\item Rust
% excellent for low-level high-level language, but want here
% high-level high-level language :)
\end{itemize}

% so many candidates to list here actually.
%mini:
% - mincaml
% - mini-MLhttps://hal.inria.fr/inria-00076025/file/RR-0529.pdf
% - make a lisp in many different languages https://github.com/kanaka/mal
% - write you a haskell compiler:
%   http://dev.stephendiehl.com/fun/
%proved:
% - verified-ML: https://cakeml.org/

%todo?
%https://rwmj.wordpress.com/2009/08/04/ocaml-internals/
%https://github.com/ocamllabs/ocaml-internals/wiki

%why ocaml vs smlnj, moscowml, etc:
%http://thebreakfastpost.com/2015/05/10/sml-and-ocaml-so-why-was-the-ocaml-faster/

%tags used in this file
%thih: how ocaml implem differs from 'typing haskell in haskell' paper

\section{Getting started}

\section{Requirements}

% actually the code presented below is written in OCaml so you
% need to understand OCaml :)

% also help to understand target language (in addition to host),
% so that you understand the features you are implementing,
% e.g. what is a variant, a record, a closure, etc.

\section{About this document}
#include "../docs/latex/About.nw"

\section{Copyright}

Most of this document is actually source code from OCaml, so
those parts are copyright by INRIA.

<<copyright header>>=
(***********************************************************************)
(*                                                                     *)
(*                           Objective Caml                            *)
(*                                                                     *)
(*            Xavier Leroy, projet Cristal, INRIA Rocquencourt         *)
(*                                                                     *)
(*  Copyright 1996 Institut National de Recherche en Informatique et   *)
(*  Automatique.  Distributed only by permission.                      *)
(*                                                                     *)
(***********************************************************************)
@

\ifallcode
<<copyright header 1997>>=
(***********************************************************************)
(*                                                                     *)
(*                           Objective Caml                            *)
(*                                                                     *)
(*            Xavier Leroy, projet Cristal, INRIA Rocquencourt         *)
(*                                                                     *)
(*  Copyright 1997 Institut National de Recherche en Informatique et   *)
(*  Automatique.  Distributed only by permission.                      *)
(*                                                                     *)
(***********************************************************************)
@

<<copyright header 1998>>=
(***********************************************************************)
(*                                                                     *)
(*                           Objective Caml                            *)
(*                                                                     *)
(*            Xavier Leroy, projet Cristal, INRIA Rocquencourt         *)
(*                                                                     *)
(*  Copyright 1998 Institut National de Recherche en Informatique et   *)
(*  Automatique.  Distributed only by permission.                      *)
(*                                                                     *)
(***********************************************************************)
@


<<copyright header C xavier>>=
/***********************************************************************/
/*                                                                     */
/*                           Objective Caml                            */
/*                                                                     */
/*            Xavier Leroy, projet Cristal, INRIA Rocquencourt         */
/*                                                                     */
/*  Copyright 1996 Institut National de Recherche en Informatique et   */
/*  Automatique.  Distributed only by permission.                      */
/*                                                                     */
/***********************************************************************/
@
% in parser.mly and many stdlib support C code in byterun

<<copyright header C xavier and damien>>=
/***********************************************************************/
/*                                                                     */
/*                           Objective Caml                            */
/*                                                                     */
/*         Xavier Leroy and Damien Doligez, INRIA Rocquencourt         */
/*                                                                     */
/*  Copyright 1996 Institut National de Recherche en Informatique et   */
/*  Automatique.  Distributed only by permission.                      */
/*                                                                     */
/***********************************************************************/
@

<<copyright header C damien>>=
/***********************************************************************/
/*                                                                     */
/*                           Objective Caml                            */
/*                                                                     */
/*             Damien Doligez, projet Para, INRIA Rocquencourt         */
/*                                                                     */
/*  Copyright 1996 Institut National de Recherche en Informatique et   */
/*  Automatique.  Distributed only by permission.                      */
/*                                                                     */
/***********************************************************************/
@

<<copyright header C damien 1997>>=
/***********************************************************************/
/*                                                                     */
/*                           Objective Caml                            */
/*                                                                     */
/*            Damien Doligez, projet Para, INRIA Rocquencourt          */
/*                                                                     */
/*  Copyright 1997 Institut National de Recherche en Informatique et   */
/*  Automatique.  Distributed only by permission.                      */
/*                                                                     */
/***********************************************************************/
@


<<copyright header0>>=
(***********************************************************************)
(*                                                                     *)
(*                         Caml Special Light                          *)
(*                                                                     *)
(*            Xavier Leroy, projet Cristal, INRIA Rocquencourt         *)
(*                                                                     *)
(*  Copyright 1995 Institut National de Recherche en Informatique et   *)
(*  Automatique.  Distributed only by permission.                      *)
(*                                                                     *)
(***********************************************************************)
@
% for typing/
\fi


The prose is mine and is licensed under the GNU Free Documentation
License.


\section{Acknowledgments}

I would like to thank of course Xavier Leroy
the main author of OCaml.







\chapter{Overview}

\section{High-level language principles}

% have seen C in other book, which is a big improvment over assembly:
% - functions, more structured and typed than CALL
% - while/if/..., more structured than JMP
% - expressions better than limited 3 address code
% - struct/union/array, more structured than manual offsets manipulation,
%   and pointers? needed for complex structures (e.g. lists, hashtbl, etc)

%ocaml has many advanced features not in C, so it is good increment too:
% (stuff other functional languages have, e.g. Lisp)
% - gc (no more malloc/free and bugs), which imply special bit
%   for each values (and some tricks around integer operations)
% - parametric polymorphism (no more code duplication and void* loophole)
%   which imply boxing values for certain implementation strategy
% - closures (can factorize more code, no more loop for everything)
% (now stuff really specific to ML)
% - ADT and pattern matching (no more enum/switch loophole)
%   had type "and", now have really a type "or"!
% - type inference (less boilerplate, especially needed when have
%   polymorphism and closures and quite complicated types)
% - references: disciplined safe pointers!
% - exceptions: disciplined setjmp/longjmp

% missing: 
%  - call/cc, too advanced? too complex for mere mortal?
%    but could, see
%    http://gallium.inria.fr/~xleroy/software/ocaml-callcc-1.0.tar.gz
%    or 
%    http://okmij.org/ftp/continuations/implementations.html
%  - macros 
%    but could at least implement deriving
% missing on purpose: 
%  - objects (see lablgtk mess), 
%  - functors (see ocamlgraph or ocsigen mess).
% toadd: 
%  - type classes (no more + vs +., print_xxx, can factorize more code)
%  - compile time metaprogramming? (no more boilerplate, show, map, visit, etc)
%    staging?

\section{[[ocamlc]] command-line interface}

<<constant [[Main.usage]]>>=
let usage = "Usage: ocamlc <options> <files>\nOptions are:"
@

\section{[[ocamlrun]] command-line interface}


\section{[[calc.ml]]}

\section{Input OCaml-Light language}

% vs SML:
%  - good implicit mli is sig and ml is struct, in SML you have to
%    repeat yourself in the .sig and .sml and so

% vs Haskell:
%  - no package, flat module, can reference without import.
%    In the end it's far better. See darcs code with hundreds of
%    line of boilerplate import and then unqualified call to external
%    functions.

%history of ML:
%https://www.youtube.com/watch?v=NVEgyJCTee4&feature=youtu.be

\section{Code organization}

%config/m.h machine config
%config/s.h (operating) system config

% datarepr.ml:  
%  "Compute constructor and label descriptions from type declarations, determining their representation"
% ctype.ml: 
%  "Operations on core types"

% typedecl.ml: typing of the type declarations
%  "Typing of type definitions and primitive definitions"

% matching.ml: 
%  "Compilation of pattern matching"
% emitcode.ml:
%  "Generation of bytecode for .cmo files"

%https://github.com/ocamllabs/ocaml-internals/wiki/Source-layout

% byterun/primitives (and prims.c) and bytecomp/runtimedef.ml

\section{Software architecture}

% https://github.com/ocamllabs/ocaml-internals/wiki/Compiler-pipelines


% .cmi! contain signature info (Obj.marshall of types really),
% kinda .h

% http://caml.inria.fr/pub/docs/manual-ocaml-4.00/manual033.html#c:intf-c
% "The OCaml runtime system comprises three main parts: the bytecode
% interpreter, the memory manager, and a set of C functions that
% implement the primitive operations"

\section{Bootstrapping}

<<constant [[Clflags.nopervasives]]>>=
let nopervasives = ref false            (* -nopervasives *)
@
<<[[Main.main()]] command line options>>=
"-nopervasives", Arg.Set nopervasives, " (undocumented)";
@

% 'make coldstart' is nice. See the basic stuff needed.

% 'make bootstrap' has beautiful comments!
% (but can't use syncweb with Makefiles, but maybe can with mk!!)


% can you change instruct.h? if do so then can't run anymore
% boot/ocamlc. But there is also boot/ocamlrun, so it should
% work!

% plan9 port: need an ocamlrun, need an ocamlc, and then need boot/*.cmi
% stdlib.cma and std_exit.cmo at the standard place (/usr/local/lib/ocaml).
% And that's it!

% take care if modify stdlib/ and for instance adds use of builtins
% (e.g. when I added Printexc.get_backtrace using some new builtins
% in backtrace.c). Do not make clean! instead make bootstrap.



%###############################################################################

\chapter{Core Data Structures}

% core DS for ocamlc
%parsing/parsetree.mli and asttypes.mli
%typing/types.mli
%typing/typedtree.mli (and asttypes.mli)
%bytecomp/lambda.mli
%bytecomp/instruct.mli

% core DS for ocamlrun
%byterun/instruct.h
%byterun/mlvalues.h

% opcodes.ml? is the link!


\section{Abstract syntax tree}

\subsection{Positions}

<<type [[Location.t]]>>=
(* Source code locations, used in parsetree *)

type t =
  { loc_start: int; loc_end: int }
@
%the int is a charpos

<<signature [[Location.none]]>>=
val none: t
@
<<constant [[Location.none]]>>=
let none = { loc_start = -1; loc_end = -1 }
@

<<signature [[Location.symbol_loc]]>>=
val symbol_loc: unit -> t
@
<<function [[Location.symbol_loc]]>>=
let symbol_loc () = 
  { loc_start = Parsing.symbol_start(); loc_end = Parsing.symbol_end() }
@
% ?? global?

% Compile.parse_file -> <>
<<signature [[Location.input_name]]>>=
val input_name: string ref
@
<<constant [[Location.input_name]]>>=
let input_name = ref ""
@
%alt: my info scheme, where the filaneme, charpos, and also
% line is stored in the token.






\subsection{Names}

<<type [[Longident.t]]>>=
(* Long identifiers, used in parsetree. *)

type t =
  | Lident of string
  | Ldot of t * string
@
%note: like a list, but enforce have at least one element
% Foo.Bar.x -> Ldot (Ldot (Lident "Foo", "Bar"), "x")

%dead:
%<<signature Longident.flatten>>=
%val flatten: t -> string list
%@
%<<function Longident.flat>>=
%let rec flat accu = function
%    Lident s -> s :: accu
%  | Ldot(lid, s) -> flat (s :: accu) lid
%@
%<<function Longident.flatten>>=
%let flatten lid = flat [] lid
%@
%% dead, maybe dead because removed functors, module type, etc


\subsection{Types}

% ocaml is a statically typed language! types are important!

\subsubsection{Type expressions}
% this is the type "system", not the declaration of the types themselves.

<<type [[Parsetree.core_type]]>>=
type core_type =
  { ptyp_desc: core_type_desc;
    ptyp_loc: Location.t }
@
%alt: my info scheme and embedded token instead of wrapper extra type.
%less: at least could factorize? 'a wrap = 'a * Location.t  no?

<<type [[Parsetree.core_type_desc]]>>=
and core_type_desc = 
  | Ptyp_var of string
  | Ptyp_arrow of core_type * core_type
  | Ptyp_tuple of core_type list
  | Ptyp_constr of Longident.t * core_type list
@
%  <<[[Parsetree.core_type_desc]] cases>>
%less: how represent base type? like int? 
% it will be Ptyp_constr "int" [] ??
%see later: any? it's _, I think I can remove it
%note: rename constr? it's not constructor, it's apply,
% but well it's kinda a constructor, but for type level.
%note: alias here, but should disappear at some point.

% note that there is no '_a here, because it's not representable
% by the user. It can't appear in the source code itself.

\subsubsection{Type declarations}


<<type [[Parsetree.type_declaration]]>>=
type type_declaration =
  { ptype_params: string list;
    ptype_kind: type_kind;
    ptype_loc: Location.t;
    <<[[Parsetree.type_declaration]] other fields>>
  }
@

<<type [[Parsetree.type_kind]]>>=
and type_kind =
  | Ptype_variant of (string * core_type list) list
  | Ptype_record of (string * mutable_flag * core_type) list
  <<[[Parsetree.type_kind]] cases>>
@
% type sum, type product.

% int/float/array are actually neither a variant or a record,
% they are kinda builtin, so could have a Ptype_builtin of string,
% but those types are not defined in Pervasive.mli, they
% are really builtins and do not need a concrete representation.
% They need to be in the Env though, and so they have a
% Type_abstract for that (that they use also for abstract types,
% but primitive types are indeed kinda abstract types).

% The user can not define builtin types, so really Ptype_abstract is
% just for user defined abstract data type! so I didn't put
% it here.




<<type [[Asttypes.mutable_flag]]>>=
type mutable_flag = Immutable | Mutable
@
% remove? just use ref? I get confused, but it's true the sugar 
% with mutable is nice.

%  | Psig_type of (string * type_declaration) list
% list when mutually recursive!

\subsubsection{Exception declarations}

<<type [[Parsetree.exception_declaration]]>>=
type exception_declaration = core_type list
@
% ??

%  | Psig_exception of string * exception_declaration


\subsection{Expressions}

% ocaml is an expression language! fully compositional

<<type [[Parsetree.expression]]>>=
type expression =
  { pexp_desc: expression_desc;
    pexp_loc: Location.t }
@

% rich type; this includes also statements, locals, and even
% functions/constants/globals since ocaml is very regular.

<<type [[Parsetree.expression_desc]]>>=
and expression_desc =
  | Pexp_constant of Asttypes.constant
  | Pexp_construct of Longident.t * expression option
  | Pexp_record of (Longident.t * expression) list
  | Pexp_tuple of expression list

  (* lambda calcul! abs and app *)
  | Pexp_function of (pattern * expression) list
  | Pexp_apply of expression * expression list

  | Pexp_field of expression * Longident.t
  | Pexp_setfield of expression * Longident.t * expression

  | Pexp_let of rec_flag * (pattern * expression) list * expression
  | Pexp_ident of Longident.t

  | Pexp_match of expression * (pattern * expression) list
  (* todo? not only in match? *)
  | Pexp_when of expression * expression

  | Pexp_constraint of expression * core_type

  <<[[Parsetree.expression_desc]] cases>>
@
% list for let, for mutually recursive functions or data

<<type [[Asttypes.rec_flag]]>>=
type rec_flag = Nonrecursive | Recursive
@
% actually can also have rec_flag for constants? build a cycle?


%  | Pexp_construct of Longident.t * expression option
% so if multi args? then have an intermediate Pexp_tuple!

\subsection{Patterns}

<<type [[Parsetree.pattern]]>>=
type pattern =
  { ppat_desc: pattern_desc;
    ppat_loc: Location.t }
@

<<type [[Parsetree.pattern_desc]]>>=
and pattern_desc =
    Ppat_any
  | Ppat_var of string

  | Ppat_constant of constant
  | Ppat_construct of Longident.t * pattern option
  | Ppat_record of (Longident.t * pattern) list
  | Ppat_tuple of pattern list

  | Ppat_alias of pattern * string
  | Ppat_constraint of pattern * core_type
  | Ppat_or of pattern * pattern
@
%less: aspectize more advanced patterns? like alias, constraint, or?

\subsection{Statements}

% actually stmts are exprs in ocaml!

<<[[Parsetree.expression_desc]] cases>>=
| Pexp_sequence of expression * expression

| Pexp_ifthenelse of expression * expression * expression option
| Pexp_while of expression * expression
| Pexp_for of string * expression * expression * direction_flag * expression

| Pexp_try of expression * (pattern * expression) list
@
% the first expression for 'for' needs to be a special kind of expr?
% like i = 1? for introduce a new variable!

<<type [[Asttypes.direction_flag]]>>=
type direction_flag = Upto | Downto
@

\subsection{Modules}

\subsubsection{Signatures}

% mli

<<type [[Parsetree.signature]]>>=
and signature = signature_item list
@

<<type [[Parsetree.signature_item]]>>=
and signature_item =
  { psig_desc: signature_item_desc;
    psig_loc: Location.t }
@
<<type [[Parsetree.signature_item_desc]]>>=
and signature_item_desc =
    Psig_value of string * value_description
  | Psig_type of (string * type_declaration) list
  | Psig_exception of string * exception_declaration

  | Psig_module of string * module_type
  | Psig_open of Longident.t
@
% recursive module type
% type_declaration list  for mutually recursive types

%less: should not allow Psig_open, or just for implicit Pervasives open

<<type [[Parsetree.value_description]]>>=
(* Value descriptions *)

type value_description =
  { pval_type: core_type;
    pval_prim: string list }
@
%    Psig_value of string * value_description

%pval_prim for external primitives. [] for non-primitives.
\l aspectize?

<<type [[Parsetree.module_type]]>>=
type module_type =
  { pmty_desc: module_type_desc;
    pmty_loc: Location.t }
@
<<type [[Parsetree.module_type_desc]]>>=
and module_type_desc =
    Pmty_ident of Longident.t
  | Pmty_signature of signature
@
% recursive back to signature!
%less: remove PPmty_ident? no aliases for sig? because no module type
% hmm can be useful actually for module Set = Set_poly in .mli?
% to be backward compatible with ocaml




\subsubsection{Structures}

% ml

<<type [[Parsetree.structure]]>>=
and structure = structure_item list
@

<<type [[Parsetree.structure_item]]>>=
and structure_item =
  { pstr_desc: structure_item_desc;
    pstr_loc: Location.t }
@

<<type [[Parsetree.structure_item_desc]]>>=
and structure_item_desc =
    Pstr_eval of expression
  | Pstr_value of rec_flag * (pattern * expression) list
  | Pstr_primitive of string * value_description

  | Pstr_type of (string * type_declaration) list
  | Pstr_exception of string * exception_declaration

  | Pstr_module of string * module_expr
  | Pstr_open of Longident.t
@
% Pstr_value is a special case of Pstr_eval where the expr
% is a let! it's treated specially
% expression list  for mutually recursive functions
% value_description for Pstr_primitive must always have non-empty prim_val?

<<type [[Parsetree.module_expr]]>>=
type module_expr =
  { pmod_desc: module_expr_desc;
    pmod_loc: Location.t }
@

<<type [[Parsetree.module_expr_desc]]>>=
and module_expr_desc =
    Pmod_ident of Longident.t
  | Pmod_structure of structure
  | Pmod_constraint of module_expr * module_type
@
% recurse back to structure
%note: here we want to keep Tmod_ident, it allows to do module aliases
% which is useful

\section{Types and the typed tree}

<<type [[Types.type_expr]]>>=
type type_expr =
    Tvar of type_variable

  | Tarrow of type_expr * type_expr
  | Ttuple of type_expr list
  | Tconstr of Path.t * type_expr list
@
% Tconstr, type "constructor"
% diff with core_type_desc: 
% - no more Any
% - no more type aliases (but I removed them in the previous basic chunk)
% - no manifest (type abbreviations) (but I aspectized it)
%thih: diff with THIH
% - arrow is seens as a form of type constructor but with a higher kind
%   (not sure it simplifies things)

<<type [[Types.type_variable]]>>=
and type_variable = 
  { mutable tvar_link: type_expr option;
    <<[[Types.type_variable]] other fields>>
  }
@
% kinda use a "global", that's what Prolog Does in some way
% (and indeed oleg said the same in his article, "reference cells").
% the variable carries its substitution, so no need to
% return substitutions in unify, etc, simpler code (especially
% in language with no monadic do syntax)
%less: have also Qvar like in oleg's article instead of abusing generic_level?
% and replace the option with Ubound of level | Link of typ?

% alternatives: 
% - return equations?
% - works with type substitutions (like in THIH)


% many Types.xxx are really close to Parsetree.xxx
% they actually have the same name, but core_type
% has been replaced by type_expr.

% In the same way many Pxxx become Txxx


\section{[[Lambda]] and [[Instruction]] intermediate languages}

% will see later?

\section{Bytecode}
% core DS for ocamlrun now!
% Bytecode opcodes?

% https://github.com/ocamllabs/ocaml-internals/wiki/Bytecode-compiler-pipeline

<<enum [[instructions]]>>=
/* The instruction set. */

enum instructions {

  /* integers */
  <<integer arithmetics opcodes>>

  /* stack, env, heap, data */
  <<basic stack operations opcodes>>
  <<env access opcodes>>
  <<blocks allocation opcodes>>
  <<blocks access opcodes>>
  <<global data access opcodes>>

  /* control */
  <<branching opcodes>>
  <<function application opcodes>>
  <<recursive definition opcodes>>
  <<exception [[opcodes]]>>

  <<signal opcodes>>
  <<foreign C calls opcodes>>

  /* special data */
  <<string opcodes>>
  <<array opcodes>>

  /* misc */
  <<misc opcodes>>
  <<debugger opcodes>>
};
@
%note: I changed the order with what was originally there, I think it's
% more logical that way, better grouping. I added the comments.
%But the order is important!! if you change it then you will not be able
% to run boot/ocamlc because it will use a different order
% for the opcodes. But remember that there is boot/ocamlrun too! 
% so you can change things if you do make bootstrap.
%
% What happens when you modify instruct.h? Then by running
% make this will update opcodes.ml which will force all the ML
% code that is generating code to be recompiled and a new ocamlc
% will be produced (but one that runs on boot/ocamlrun but not
% byterun/ocamlrun though). With boot/ocamlrun ./ocamlc you
% can recompile everything including a new ocamlc that this time
% will run on the new byterun/ocamlrun. Now you can promote
% byterun/ocamlrun to boot/ocamlrun and ./ocamlc as boot/ocamlc.

% A lot more cases compared to Machine.nw or Assembler.nw opcodes.
% similar: 
%  - branching
%  - arithmetics
%  - foreign c calls =~ syscalls/interrupts opcodes
%  - basic stack =~ memory opcodes
% different: all the rest ... exn, env, function call, debugger, etc.
% note that there is no label here because the bytecode is really
% closer to Machine.nw than Assembler.nw. Instruction has labels though.


% notion of abstract machine, virtual machine
%history: p-code of wirth, secd of landin?

% autogenerated
<<bytecomp/opcodes.ml>>=
@

% autogenerated
<<bytecomp/runtimedef.ml>>=
@

\section{Runtime [[value]]s}

%https://rwmj.wordpress.com/2009/08/04/ocaml-internals/
%see also oreilly book, very good chapter on values

%This section will help understand elts from Lambda and Instruct

<<mlvalues.h top comment>>=
/* Definitions

  word: Four bytes on 32 and 16 bit architectures,
        eight bytes on 64 bit architectures.
  long: A C long integer.
  int32: Four bytes on all architectures.

  val: The ML representation of something.  A long or a block or a pointer
       outside the heap.  If it is a block, it is the (encoded) address
       of an object.  If it is a long, it is encoded as well.

  hd: A header.
  tag: The value of the tag field of the header.
  color: The value of the color field of the header.
         This is for use only by the GC.

  block: Something allocated.  It always has a header and some
          fields or some number of bytes (a multiple of the word size).
  field: A word-sized val which is part of a block.

  hp: Pointer to the header of a block.  (a char *)
  op: Pointer to the first field of a block.  (a value *)
  bp: Pointer to the first byte of a block.  (a char *)

  Remark: A block size is always a multiple of the word size, and at least
          one word plus the header.

  bosize: Size (in bytes) of the "bytes" part.
  wosize: Size (in words) of the "fields" part.
  bhsize: Size (in bytes) of the block with its header.
  whsize: Size (in words) of the block with its header.

*/
@

<<toplevel comment on header format>>=
/* Structure of the header:

For 16-bit and 32-bit architectures:
     +--------+-------+-----+
     | wosize | color | tag |
     +--------+-------+-----+
bits  31    10 9     8 7   0

For 64-bit architectures:

     +--------+-------+-----+
     | wosize | color | tag |
     +--------+-------+-----+
bits  63    10 9     8 7   0

*/
@

%FIGURE! where see relation betwen value, fields, byte, tag, etc.

<<typedef [[value]]>>=
typedef long value;
@
% big abuse of int ... variant via special tag bit
% but really should be Long of int | Block of ...?
% todo: look at zamcov?

%http://caml.inria.fr/pub/docs/manual-ocaml-4.00/manual033.html#c:intf-c
%"All OCaml objects are represented by the C type value, defined in the
%include file caml/mlvalues.h, along with macros to manipulate values
%of that type. An object of type value is either:
% - an unboxed integer;
% - a pointer to a block inside the heap (such as the blocks allocated
%   through one of the caml_alloc_* functions below);
% - a pointer to an object outside the heap (e.g., a pointer to a block
%   allocated by malloc, or to a C variable).
%"


<<function [[Is_long]]>>=
/* Longs vs blocks. */
#define Is_long(x)   (((x) & 1) != 0)
@

<<function [[Is_block]]>>=
#define Is_block(x)  (((x) & 1) == 0)
@

% so first bit set for ints, so to get value you need to shift,
% to add you need to do stuff, etc. It complicates things.
% Why not opposite? why not use bit 31 as the marker instead of bit0?
% look at zinc report? because they every dereference will need a
% a conversion. Here just integer access need some special care.
% but that way it's convenient for pointer which anyway need to be
% word aligned and so for blocks can dereference the value directly;
% no need any conversion.

% what about is_pointer_outside_heap?

\subsection{Long}

%/* Conversion macro names are always of the form  "to_from". */
<<function [[Val_long]]>>=
/* Example: Val_long as in "Val from long" or "Val of long". */
#define Val_long(x)     (((long)(x) << 1) + 1)
@
% >>


<<function [[Long_val]]>>=
#define Long_val(x)     ((x) >> 1)
@
% Long of val
% >>

<<constant [[Val_int]]>>=
#define Val_int Val_long
@
<<function [[Int_val]]>>=
#define Int_val(x) ((int) Long_val(x))
@



<<constant [[Max_long]]>>=
#define Max_long ((1L << (8 * sizeof(value) - 2)) - 1)
@
% >>
% 4 * 8 because 8 bits * 4 bytes, - 2 because 1 bit for
% the mark, 1 bit for the sign, and the final because ?

<<constant [[Min_long]]>>=
#define Min_long (-(1L << (8 * sizeof(value) - 2)))
@
% >>

\subsection{Blocks}
% =~ pointer, when not an int then the long is interpreted
% as a pointer to an area with a header and possibly more stuff.

\subsubsection{Header}

% seen figure before. 

<<typedef [[header_t]]>>=
typedef unsigned long header_t;
@
% the whole thing



% 10-31 -> max size of string is?

<<constant [[Max_wosize]] (ifndef [[ARCH_SIXTYFOUR]])>>=
#define Max_wosize ((1 << 22) - 1)
@
%>>
<<constant [[Max_wosize]] (ifdef [[ARCH_SIXTYFOUR]])>>=
#define Max_wosize ((1L << 54) - 1)
@
%>>




<<function [[Tag_hd]]>>=
#define Tag_hd(hd) ((tag_t) ((hd) & 0xFF))
@
% Tag of hd

<<typedef [[tag_t]]>>=
typedef unsigned int tag_t;             /* Actually, an unsigned char */
@

<<typedef [[color_t]]>>=
typedef unsigned long color_t; // bit 8-9
@
% will see in Gc section


<<function [[Wosize_hd]]>>=
#define Wosize_hd(hd) ((mlsize_t) ((hd) >> 10))
@
% >>

<<function [[Make_header]]>>=
/* This depends on the layout of the header.  See [mlvalues.h]. */
#define Make_header(wosize, tag, color)                                       \
       ((header_t) (((header_t) (wosize) << 10)                               \
                    + (color)                                                 \
                    + (tag_t) (tag)))
@
% no color << 8 because the color value do that already,
%  see Grey, Black, White macros


\subsubsection{Header pointer vs value}

% value is always just after the header.
% the header is really metadata for the GC, so it's not
% really the value itself.

<<function [[Val_hp]]>>=
#define Val_hp(hp) ((value) (((header_t *) (hp)) + 1))
@
% Val(ue) of header pointer.
% +1 ? pointer arithmetic so really it adds 4
% the "value" is represented as a pointer just after the header
% (why not directly the header? wins?)

<<function [[Hd_val]]>>=
#define Hd_val(val) (((header_t *) (val)) [-1])        /* Also an l-value. */
@



% so if want the tag of a value, just get the header, and then
% get the first byte
<<function [[Tag_val]] (ifdef [[ARCH_BIG_ENDIAN]])>>=
#define Tag_val(val) (((unsigned char *) (val)) [-1])
@

<<function [[Wosize_val]]>>=
#define Wosize_val(val) (Wosize_hd (Hd_val (val)))
@

\subsubsection{Tags}

%todo: use enum?

% tagspace: 0 -> 251 -> 255.
%/* 1- If tag < No_scan_tag : a tuple of fields.  */
% and so the Field macro will be used
%/* 2- If tag > No_scan_tag : a sequence of bytes. */
% and so the Bp_val macro will be used. No scan because
% the gc should not traverse this data

% special values are then used here in builtin_hash and builtin_compare
% to do special things.

<<constant [[Infix_tag]]>>=
/* Infix_tag must be 1 modulo 4 and infix headers can only occur in blocks
   with tag Closure_tag (see compact.c). */

#define Infix_tag 249
@
<<constant [[Closure_tag]]>>=
/* Special case of tuples of fields: closures */

#define Closure_tag 250
@



<<constant [[No_scan_tag]]>>=
/* The lowest tag for blocks containing no value. */
#define No_scan_tag 251
@
<<constant [[Abstract_tag]]>>=
/* Abstract things.  Their contents is not traced by the GC; therefore they
   must not contain any [value].
*/
#define Abstract_tag 251
@


<<constant [[Final_tag]]>>=
/* Finalized things.  Just like abstract things, but the GC will call the
   [Final_fun] before deallocation.
*/
#define Final_tag 255
@


\subsection{Values}

% How are represented:
% - true?
% - 1? 
% - Foo? 
% - (Foo (1,2)) ? 
% - (1,2)?
% - [1;2] ?
% - ...

%http://caml.inria.fr/pub/docs/manual-ocaml-4.00/manual033.html#toc144
% interesting that in the manual they better classify those macros
% than in the actual code.

\subsubsection{Booleans}

<<function [[Val_bool]]>>=
/* Booleans are integers 0 or 1 */

#define Val_bool(x) Val_int((x) != 0)
@
% could assert passed x is 0 or 1?

<<function [[Bool_val]]>>=
#define Bool_val(x) Int_val(x)
@

<<constant [[Val_false]]>>=
#define Val_false Val_int(0)
@

<<constant [[Val_true]]>>=
#define Val_true Val_int(1)
@

\subsubsection{Unit}

<<constant [[Val_unit]]>>=
/* The unit value is 0 */

#define Val_unit Val_int(0)
@

\subsubsection{Atoms}
% =~ simple constructors with no arguments? =~ enums?

%/* 3- Atoms are 0-tuples.  They are statically allocated once and for all. */

<<function [[Atom]]>>=
#define Atom(tag) (Val_hp (&(atom_table [tag])))
@
% prebuilt pointers for simple tags! so Foo is a pointer
% to en entry in atom_table with tag value at 0, wosize 0.

<<function [[Is_atom]]>>=
#define Is_atom(v) ((v) >= Atom(0) && (v) <= Atom(255))
@

%/* Is_atom tests whether a well-formed block is statically allocated
%   outside the heap. For the bytecode system, only zero-sized block (Atoms)
%   fall in this class. For the native-code generator, data
%   emitted by the code generator (as described in the table
%   caml_data_segments) are also atoms. */



<<global [[atom_table]]>>=
header_t atom_table[256];
@

% caml_main? -> <>
<<function [[init_atoms]]>>=
/* Initialize the atom table */

static void init_atoms(void)
{
  int i;
  for(i = 0; i < 256; i++) atom_table[i] = Make_header(0, i, White);
}
@
% white? means? do not gc?

\subsubsection{Objects}
% in the general sense

<<function [[Field]]>>=
/* Fields are numbered from 0. */
#define Field(x, i) (((value *)(x)) [i])           /* Also an l-value. */
@

%\section{Native CMM, lambda, etc?}







\chapter{[[Main.main()]] ([[ocamlc]])}
% main of ocamlc (there is also the main of ocamlrun!)

<<toplevel [[Main._1]]>>=
let _ = 
  Printexc.catch main ()
@

<<function [[Main.main]]>>=
let main () =
  try
    Arg.parse [
       <<[[Main.main()]] command line options>>

       "-output-c", Arg.Unit(fun () -> output_c := true;
                                       custom_runtime := true),
             "Output a C file instead of an executable";
      ] 
      process_file 
      usage;

    (match () with
    <<[[Main.main()]] if make archive case>>
    <<[[Main.main()]] if linking case>>
    | _ -> ()
    );
    exit 0
  with x ->
    Format.set_formatter_out_channel stderr;
    Errors.report_error x;
    exit 2
@
% see report_error in appendix

% Bytegen.link -> <>
<<constant [[Clflags.exec_name]]>>=
let exec_name = ref "a.out"             (* -o *)
@
<<[[Main.main()]] command line options>>=
"-o", Arg.String(fun s -> exec_name := s;
                          archive_name := s;
                          object_name := s),
      "<file>  Set output file name to <file> (default a.out)";
@






<<[[Main.main()]] command line options>>=
"-v", Arg.Unit print_version_number, " Print compiler version number";
@

<<function [[Main.print_version_number]]>>=
let print_version_number () =
  print_string "The Objective Caml compiler, version ";
  print_string Config.version; 
  print_newline();
  print_string "Standard library directory: ";
  print_string Config.standard_library; 
  print_newline()
@
%less: use printf

<<signature [[Config.version]]>>=
val version: string
        (* The current version number of the system *)
@

<<signature [[Config.standard_library]]>>=
val standard_library: string
        (* The directory containing the standard libraries *)
@

\section{[[Main.process_file()]]}

<<constant [[Clflags.objfiles]]>>=
let objfiles = ref ([] : string list)   (* .cmo and .cma files *)
@


<<function [[Main.process_file]]>>=
let process_file name =
  Logs.info (fun m -> m "processing %s" name);
  match () with
  | _ when Filename.check_suffix name ".ml" ->
      Compile.implementation name;
      objfiles := (Filename.chop_extension name ^ ".cmo") :: !objfiles

  | _ when Filename.check_suffix name ".mli" ->
      Compile.interface name

  <<[[Main.process_file()]] cases>>
  | _ -> 
      raise(Arg.Bad("don't know what to do with " ^ name))
@
%old: or Filename.check_suffix name ".mlt" ??
%old: I rewrote with match () with when


\ifallcode
<<[[Main.main()]] command line options>>=
"-", Arg.String process_file,
     "<file>  Treat <file> as a file name (even if it starts with `-')";
@
\fi


\section{[[Compile.implementation()]]}

<<signature [[Compile.implementation]]>>=
val implementation: string -> unit
@
% filename



<<signature [[Compile.init_path]]>>=
val init_path: unit -> unit
@
% ? for load_path, use the -I ?

<<signature [[Compile.initial_env]]>>=
val initial_env: unit -> Env.t
@


<<function [[Compile.implementation]]>>=
let implementation sourcefile =
  init_path();
  let prefixname = Filename.chop_extension sourcefile in
  let modulename = String.capitalize(Filename.basename prefixname) in
  let inputfile = preprocess sourcefile (prefixname ^ ".ppo") in

  (* parsing *)
  let ast = parse_file inputfile Parse.implementation ast_impl_magic_number in

  let objfile = prefixname ^ ".cmo" in
  let oc = open_out objfile in
  try

    (* typing *)
    let (struc, sg, finalenv) =
      Typemod.type_structure (initial_env()) ast in

    if !Clflags.print_types 
    then (Printtyp.signature sg; print_newline());

    (* checking *)
    let (coercion, _crc) =
      if Sys.file_exists (prefixname ^ ".mli") then begin
        let intf_file =
          try find_in_path !load_path (prefixname ^ ".cmi")
          with Not_found -> prefixname ^ ".cmi" 
        in
        let (dclsig, crc) = Env.read_signature modulename intf_file in
        (Includemod.compunit sourcefile sg intf_file dclsig, crc)
      end else begin
        let crc = Env.save_signature sg modulename (prefixname ^ ".cmi") in
        Typemod.check_nongen_schemes struc;
        (Tcoerce_none, crc)
      end 
    in

    (* generating *)
    Translmod.transl_implementation modulename struc coercion
    |> print_if Clflags.dump_rawlambda Printlambda.lambda
    |> Simplif.simplify_lambda
    |> print_if Clflags.dump_lambda Printlambda.lambda
    |> Bytegen.compile_implementation modulename
    |> print_if Clflags.dump_instr Printinstr.instrlist
    |> Emitcode.to_file oc modulename
    ;

    remove_preprocessed inputfile;
    close_out oc
  with x ->
    close_out oc;
    remove_file objfile;
    raise x
@
%less: Common.finalize
%with later typing/
%(*
%    let coercion =
%      if Sys.file_exists (prefixname ^ ".mli") then begin
%        let intf_file =
%          try find_in_path !load_path (prefixname ^ ".cmi")
%          with Not_found -> prefixname ^ ".cmi" in
%        let dclsig = Env.read_signature modulename intf_file in
%        Includemod.compunit sourcefile sg intf_file dclsig
%      end else begin
%        Typemod.check_nongen_schemes finalenv str;
%        Env.save_signature sg modulename (prefixname ^ ".cmi");
%        Tcoerce_none
%      end in
%*)
%todo: crc seems unused later, why? and actually we don't use it here

% ast_impl_magic_number, see in advanced topics section

<<signature [[Config.load_path]]>>=
val load_path: string list ref
        (* Directories in the search path for .cmi and .cmo files *)
@


\ifallcode
% -impl
<<function [[Main.process_implementation_file]]>>=
let process_implementation_file name =
  Compile.implementation name;
  objfiles := (Filename.chop_extension name ^ ".cmo") :: !objfiles
@
<<[[Main.main()]] command line options>>=
"-impl", Arg.String process_implementation_file,
      "<file>  Compile <file> as a .ml file";
@
\fi

\section{[[Compile.interface()]]}


<<signature [[Compile.interface]]>>=
val interface: string -> unit
@
% filename

<<function [[Compile.interface]]>>=
(* Compile a .mli file *)

let interface sourcefile =
  init_path();
  let prefixname = Filename.chop_extension sourcefile in
  let modulename = String.capitalize(Filename.basename prefixname) in
  let inputfile = preprocess sourcefile (prefixname ^ ".ppi") in

  (* parsing *)
  let ast = parse_file inputfile Parse.interface ast_intf_magic_number in

  (* typing *)
  let sg = Typemod.transl_signature (initial_env()) ast in

  if !Clflags.print_types 
  then (Printtyp.signature sg; print_newline());

  Env.save_signature sg modulename (prefixname ^ ".cmi") |> ignore;
  remove_preprocessed inputfile
@


\ifallcode
% -intf
<<[[Main.main()]] command line options>>=
"-intf", Arg.String process_interface_file,
      "<file>  Compile <file> as a .mli file";
@
<<function [[Main.process_interface_file]]>>=
let process_interface_file name =
  Compile.interface name
@
% delete?
\fi

\section{[[Bytelink.link()]]}

<<[[Main.main()]] command line options>>=
"-c", Arg.Set compile_only, " Compile only (do not link)";
@

<<[[Main.main()]] if linking case>>=
| _ when not !compile_only & !objfiles <> [] ->
    Compile.init_path();
    Bytelink.link (List.rev !objfiles)
@

% will see Bytelink.link later





\chapter{Lexing}

% See lex&yacc tutorial, even ocamllex/ocamlyacc tutorial.
% bootstrapping issue? yes for ocamllex.

% see also preprocessing section in advanced topics

<<signature [[Lexer.token]]>>=
(* The lexical analyzer *)

val token: Lexing.lexbuf -> Parser.token
@


<<./parsing/lexer.mll>>=
<<copyright header>>

(* The lexer definition *)

{
open Misc
open Parser

<<type [[Lexer.error]]>>
<<exception [[Lexer.Error]]>>

<<Lexer helpers>>

(* Error report *)
open Format
<<function [[Lexer.report_error]]>>
}

<<rule Lexer.token>>

<<rule Lexer.comment>>

<<rule Lexer.string>>

@
%$




<<rule Lexer.token>>=
rule token = parse
  <<[[Lexer.token()]] space case>>
  <<[[Lexer.token()]] comment case>>

  <<[[Lexer.token()]] underscore case>>

  (* pad: partial support just enough to parse xix code *)
  | "~" ['a'-'z'  '_'] (['A'-'Z' 'a'-'z' '_' '\'' '0'-'9' ]) * ':'
      { 
        let s = Lexing.lexeme lexbuf in
        Logs.warn (fun m -> m "use of label %s (skipping it)" s);
        token lexbuf
      }

  <<[[Lexer.token()]] identifier or keyword cases>>

  <<[[Lexer.token()]] integer case>>
  <<[[Lexer.token()]] float case>>

  <<[[Lexer.token()]] string case>>
  <<[[Lexer.token()]] character case>>

  <<[[Lexer.token()]] directive case>>
  <<[[Lexer.token()]] sharp case>>

  <<[[Lexer.token()]] operator cases>>
  (* pad: partial support just enough to parse xix code *)
  | "[@@" { LBRACKETATAT }
  | ":>"  { COLONGREATER }
  | eof { EOF }
  | _
      { raise (Error(Illegal_character,
                     Lexing.lexeme_start lexbuf, Lexing.lexeme_end lexbuf)) }

@
% the order of the patterns matter in ocamllex, so I prefer
% to be more explicit instead of having just a <<[[Lexer.token()]] cases ...


\ifallcode
% this could be in Extra.nw
<<Lexer helpers>>=
(* For nested comments *)

<<global [[Lexer.comment_depth]]>>

(* The table of keywords *)

<<constant [[Lexer.keyword_table]]>>

(* To buffer string literals *)

<<Lexer string related functions>>

(* To translate escape sequences *)

<<Lexer escape sequences related functions>>

(* To store the position of the beginning of a string or comment *)

<<global [[Lexer.start_pos]]>>
@
\fi



<<Parser tokens>>=
%token TRUE
%token FALSE
%token <int> INT
%token <char> CHAR
%token <string> FLOAT
%token <string> STRING

%token <string> LIDENT
%token <string> UIDENT

%token LET REC IN   FUN FUNCTION
%token IF THEN ELSE  BEGIN END  WHILE FOR DO DONE TO DOWNTO
%token MATCH WITH WHEN AS
%token TRY EXCEPTION
%token TYPE OF VAL EXTERNAL MUTABLE
%token MODULE SIG STRUCT OPEN
%token LAZY ASSERT
%token AND OR

%token LPAREN RPAREN
%token LBRACE RBRACE
%token LBRACKET RBRACKET
%token LBRACKETBAR BARRBRACKET

%token AMPERSAND
%token BAR
%token AMPERAMPER BARBAR
%token COLON
%token COLONCOLON
%token COMMA
%token DOT
%token DOTDOT
%token MINUSGREATER
%token LESSMINUS
%token COLONEQUAL
%token QUOTE
%token SEMI
%token SEMISEMI
%token STAR
%token UNDERSCORE
%token SHARP

%token EQUAL
%token LESS
%token GREATER
%token <string> PREFIXOP
%token <string> INFIXOP0
%token <string> INFIXOP1
%token <string> INFIXOP2
%token <string> INFIXOP3
%token <string> INFIXOP4
%token <string> SUBTRACTIVE

%token EOF

@
%less: regroup? can put multiple on one line
%todo: can remove 'and' 'or'

% the INFIXOPxxx is to have different priorities, 
% plus-like operators, multiply-like operators, etc.
%less: but I think 5 different operators priorities is already too much.

% for syncweb
<<parsing/lexer.ml>>=
@

\section{Comments}
% space and comments?

<<[[Lexer.token()]] space case>>=
  [' ' '\010' '\013' '\009' '\012'] +
    { token lexbuf }
@
% 13 = return, 9 = tabs, 10 = ? 12 = ?

<<[[Lexer.token()]] comment case>>=
| "(*"
    { comment_depth := 1;
      start_pos := Lexing.lexeme_start lexbuf;
      comment lexbuf;
      token lexbuf }
@

<<global [[Lexer.comment_depth]]>>=
let comment_depth = ref 0
@

<<global [[Lexer.start_pos]]>>=
let start_pos = ref 0
@

<<rule Lexer.comment>>=
and comment = parse
    "(*"
      { comment_depth := succ !comment_depth; comment lexbuf }
  | "*)"
      { comment_depth := pred !comment_depth;
        if !comment_depth > 0 then comment lexbuf }
  <<[[Lexer.comment()]] string or char in comment cases>>
  | eof
      { raise (Error(Unterminated_comment, !start_pos, !start_pos+2)) }
  | _
      { comment lexbuf }
@
%+2??
%less: succ -> incr, pred -> decr?




\section{Keywords and identifiers}

<<[[Lexer.token()]] identifier or keyword cases>>=
| ['a'-'z'  '_'] (['A'-'Z' 'a'-'z' '_' '\'' '0'-'9' ]) *
    { let s = Lexing.lexeme lexbuf in
        try
          Hashtbl.find keyword_table s
        with Not_found ->
          LIDENT s 
     }
| ['A'-'Z'  ] (['A'-'Z' 'a'-'z' '_' '\'' '0'-'9' ]) *
    { UIDENT(Lexing.lexeme lexbuf) }       (* No capitalized keywords *)
@
%old: was 
%| ['a'-'z' '\223'-'\246' '\248'-'\255' '_']
%  (['A'-'Z' 'a'-'z' '_' '\192'-'\214' '\216'-'\246' '\248'-'\255'
%| ['A'-'Z' '\192'-'\214' '\216'-'\222' ]
%  (['A'-'Z' 'a'-'z' '_' '\192'-'\214' '\216'-'\246' '\248'-'\255'
% not sure why allowed that
%note: note the \' prime! ocaml is math friendly :)

<<constant [[Lexer.keyword_table]]>>=
let keyword_table =
  create_hashtable 149 [
    "true", TRUE;
    "false", FALSE;

    "let", LET;
    "rec", REC;
    "in", IN;
    "fun", FUN;
    "function", FUNCTION;

    "if", IF;
    "then", THEN;
    "else", ELSE;
    "begin", BEGIN;
    "end", END;
    "while", WHILE;
    "for", FOR;
    "do", DO;
    "done", DONE;
    "to", TO;
    "downto", DOWNTO;

    "match", MATCH;
    "with", WITH;
    "when", WHEN;
    "as", AS;

    "try", TRY;
    "exception", EXCEPTION;

    "type", TYPE;
    "of", OF;
    "val", VAL;
    "external", EXTERNAL;
    "mutable", MUTABLE;

    "module", MODULE;
    "sig", SIG;
    "struct", STRUCT;
    "open", OPEN;

    "mod",  INFIXOP3("mod");
    "land", INFIXOP3("land");
    "lor",  INFIXOP3("lor");
    "lxor", INFIXOP3("lxor");
    "lsl",  INFIXOP4("lsl");
    "lsr",  INFIXOP4("lsr");
    "asr",  INFIXOP4("asr");

    <<[[Lexer.keyword_table]] elements>>
    (* pad: partial support just enough to parse xix code *)
    "object", OBJECT;
    "method", METHOD;
]
@
%old: was sorted originally
%todo: and and or are obsolete no?

<<[[Lexer.token()]] underscore case>>=
| "_"  { UNDERSCORE }
@
% special rule, not an identifier!

<<[[Lexer.keyword_table]] elements>>=
"and", AND;
"or", OR;
@
% obsolete? delete?

\section{Operators}

<<[[Lexer.token()]] operator cases>>=
| "("  { LPAREN } | ")"  { RPAREN }
| "{"  { LBRACE } | "}"  { RBRACE }
| "["  { LBRACKET } | "]"  { RBRACKET }
@
% paren for expressions, brace for records, bracket for lists

<<[[Lexer.token()]] operator cases>>=
| "|"  { BAR }
| "*"  { STAR }
| "'"  { QUOTE }
@
% | for patterns, * for type tuples, ' for polymorphic types



<<[[Lexer.token()]] operator cases>>=
| ","  { COMMA }
| "->" { MINUSGREATER }
| "."  { DOT }
| ":"  { COLON }
| "::" { COLONCOLON }
| ":=" { COLONEQUAL }
| "<-" { LESSMINUS }
| ";"  { SEMI }
@

<<[[Lexer.token()]] operator cases>>=
| "="  { EQUAL }
| "!=" { INFIXOP0 "!=" }
| "<"  { LESS } | ">"  { GREATER }
@

<<[[Lexer.token()]] operator cases>>=
| "&&" { AMPERAMPER }
| "||" { BARBAR }
@

<<[[Lexer.token()]] operator cases>>=
| "&"  { AMPERSAND }
@
%less: remove & ?


<<[[Lexer.token()]] operator cases>>=
| "-"  { SUBTRACTIVE "-" }
| "-." { SUBTRACTIVE "-." }
@

<<[[Lexer.token()]] operator cases>>=
| ['!' '?' '~']
  ['!' '$' '%' '&' '*' '+' '-' '.' '/' ':' '<' '=' '>' '?' '@' '^' '|' '~'] *
          { PREFIXOP(Lexing.lexeme lexbuf) }

| ['=' '<' '>' '|' '&' '$']
  ['!' '$' '%' '&' '*' '+' '-' '.' '/' ':' '<' '=' '>' '?' '@' '^' '|' '~'] *
          { INFIXOP0(Lexing.lexeme lexbuf) }
| ['@' '^']
  ['!' '$' '%' '&' '*' '+' '-' '.' '/' ':' '<' '=' '>' '?' '@' '^' '|' '~'] *
          { INFIXOP1(Lexing.lexeme lexbuf) }
| ['+' '-']
  ['!' '$' '%' '&' '*' '+' '-' '.' '/' ':' '<' '=' '>' '?' '@' '^' '|' '~'] *
          { INFIXOP2(Lexing.lexeme lexbuf) }
| "**"
  ['!' '$' '%' '&' '*' '+' '-' '.' '/' ':' '<' '=' '>' '?' '@' '^' '|' '~'] *
          { INFIXOP4(Lexing.lexeme lexbuf) }
| ['*' '/' '%']
  ['!' '$' '%' '&' '*' '+' '-' '.' '/' ':' '<' '=' '>' '?' '@' '^' '|' '~'] *
          { INFIXOP3(Lexing.lexeme lexbuf) }
@
%$
%different priorities, mimicing the smaller version
%less: factorize ?
%less: why special case for **, it's exponentiation, different associativity?

% in ocaml 4.00
%  | "!" symbolchar +
%            { PREFIXOP(Lexing.lexeme lexbuf) }
%  | ['~' '?'] symbolchar +
%            { PREFIXOP(Lexing.lexeme lexbuf) }
%  | ['=' '<' '>' '|' '&' '$'] symbolchar *
%            { INFIXOP0(Lexing.lexeme lexbuf) }
%  | ['@' '^'] symbolchar *
%            { INFIXOP1(Lexing.lexeme lexbuf) }
%  | ['+' '-'] symbolchar *
%            { INFIXOP2(Lexing.lexeme lexbuf) }
%  | "**" symbolchar *
%            { INFIXOP4(Lexing.lexeme lexbuf) }
%  | ['*' '/' '%'] symbolchar *
%            { INFIXOP3(Lexing.lexeme lexbuf) }
%$
%clearer

<<[[Lexer.token()]] sharp case>>=
| "#"  { SHARP }
@
% special case because have also #line

\section{Numbers}

\subsection{Integers}

<<[[Lexer.token()]] integer case>>=
| ['0'-'9']+
| '0' ['x' 'X'] ['0'-'9' 'A'-'F' 'a'-'f']+
| '0' ['o' 'O'] ['0'-'7']+
| '0' ['b' 'B'] ['0'-'1']+
    { INT (int_of_string(Lexing.lexeme lexbuf)) }
@
%int_of_string from pervasives handles many format

\subsection{Floats}

<<[[Lexer.token()]] float case>>=
| ['0'-'9']+ ('.' ['0'-'9']*)? (['e' 'E'] ['+' '-']? ['0'-'9']+)?
    { FLOAT (Lexing.lexeme lexbuf) }
@

\section{Characters}


<<[[Lexer.token()]] character case>>=
| "'" [^ '\\' '\''] "'"
    { CHAR(Lexing.lexeme_char lexbuf 1) }
@


<<[[Lexer.token()]] character case>>=
| "'" '\\' ['\\' '\'' 'n' 't' 'b' 'r'] "'"
    { CHAR(char_for_backslash (Lexing.lexeme_char lexbuf 2)) }
@

<<Lexer escape sequences related functions>>=
let char_for_backslash =
  match Sys.os_type with
  | "Unix" ->
      begin function
      | 'n' -> '\010'
      | 'r' -> '\013'
      | 'b' -> '\008'
      | 't' -> '\009'
      | c   -> c
      end
  | x -> fatal_error "Lexer: unknown system type"
@

<<[[Lexer.token()]] character case>>=
| "'" '\\' ['0'-'9'] ['0'-'9'] ['0'-'9'] "'"
    { CHAR(char_for_decimal_code lexbuf 2) }
@
% it's actually what is used above in char_for_backslash :) bootstrapping!

<<Lexer escape sequences related functions>>=
let char_for_decimal_code lexbuf i =
  let c = 100 * (Char.code(Lexing.lexeme_char lexbuf (i+0)) - 48) +
           10 * (Char.code(Lexing.lexeme_char lexbuf (i+1)) - 48) +
                (Char.code(Lexing.lexeme_char lexbuf (i+2)) - 48) 
  in  
  Char.chr(c land 0xFF)
@


\section{Strings}

<<[[Lexer.token()]] string case>>=
| "\""
    { reset_string_buffer();
      let string_start = Lexing.lexeme_start lexbuf in
      start_pos := string_start;

      string lexbuf;

      lexbuf.Lexing.lex_start_pos <-
        string_start - lexbuf.Lexing.lex_abs_pos;
      STRING (get_stored_string()) }
@

<<rule Lexer.string>>=
and string = parse
    '"'
      { () }
  | '\\' ("\010" | "\013" | "\013\010") [' ' '\009'] *
      { string lexbuf }
  | '\\' ['\\' '"' 'n' 't' 'b' 'r']
      { store_string_char(char_for_backslash(Lexing.lexeme_char lexbuf 1));
        string lexbuf }
  | '\\' ['0'-'9'] ['0'-'9'] ['0'-'9']
      { store_string_char(char_for_decimal_code lexbuf 1);
        string lexbuf }
  | eof
      { raise (Error(Unterminated_string, !start_pos, !start_pos+1)) }
  | _
      { store_string_char(Lexing.lexeme_char lexbuf 0);
        string lexbuf }
@

% what about unicode?

<<Lexer string related functions>>=
let initial_string_buffer = Bytes.create 256
let string_buff = ref initial_string_buffer
let string_index = ref 0

let reset_string_buffer () =
  string_buff := initial_string_buffer;
  string_index := 0

let store_string_char c =
  if !string_index >= Bytes.length (!string_buff) then begin
    let new_buff = Bytes.create (Bytes.length (!string_buff) * 2) in
      String.blit (Bytes.to_string !string_buff) 0 new_buff 0 (Bytes.length (!string_buff));
      string_buff := new_buff
  end;
  String.unsafe_set (!string_buff) (!string_index) c;
  incr string_index

let get_stored_string () =
  let s = String.sub (Bytes.to_string !string_buff) 0 (!string_index) in
  string_buff := initial_string_buffer;
  s
@


\ifallcode
<<[[Lexer.comment()]] string or char in comment cases>>=
| "\""
    { reset_string_buffer();
      start_pos := Lexing.lexeme_start lexbuf;
      string lexbuf;
      string_buff := initial_string_buffer;
      comment lexbuf }
| "''"
    { comment lexbuf }
| "'" [^ '\\' '\''] "'"
    { comment lexbuf }
| "'\\" ['\\' '\'' 'n' 't' 'b' 'r'] "'"
    { comment lexbuf }
| "'\\" ['0'-'9'] ['0'-'9'] ['0'-'9'] "'"
    { comment lexbuf }
@
%less: meh for the string in comment honestly
\fi






\chapter{Parsing}

\section{Overview}


% parse_file -> Parse.impementation (= wrap Parser.implementation) -> 
%  Parser_implementation


% Again, see lex&yacc tutorial, even ocamllex/ocamlyacc tutorial.
% bootstrapping issue? no for ocamlyacc as it's written in C.

<<./parsing/parser.mly>>=
<<copyright header C xavier>>

/* The parser definition */

%{
<<Parser header>>
%}

/* Tokens */

<<Parser tokens>>

/* Precedences and associativities. Lower precedences come first. */

<<Parser precedences and associativities>>

/* Entry points */

<<Parser entry points types>>

%%

<<grammar>>
%%

@

% put tokens in previous chapter on Lexing, but it's
% actually defined in the grammar file because it's the
% interface

<<Parser precedences and associativities>>=
%right prec_let                         /* let ... in ... */
%right prec_type_def                    /* = in type definitions */
%right SEMI                             /* e1; e2 (sequence) */
%right prec_fun prec_match prec_try     /* match ... with ... */
%right prec_list                        /* e1; e2 (list, array, record) */
%right prec_if                          /* if ... then ... else ... */
%right COLONEQUAL LESSMINUS             /* assignments */
%left  AS                               /* as in patterns */
%left  BAR                              /* | in patterns */
%left  COMMA                            /* , in expressions, patterns, types */
%right prec_type_arrow                  /* -> in type expressions */
%right OR BARBAR                        /* || */
%right AMPERSAND AMPERAMPER             /* && */
%left  INFIXOP0 EQUAL LESS GREATER      /* = < > etc */
%right INFIXOP1                         /* @ ^ etc */
%right COLONCOLON                       /* :: */
%left  INFIXOP2 SUBTRACTIVE             /* + - */
%left  INFIXOP3 STAR                    /* * / */
%right INFIXOP4                         /* ** */
%right prec_unary_minus                 /* - unary */
%left  prec_appl                        /* function application */
%right prec_constr_appl                 /* constructor application */
%left  DOT                              /* record access, array access */
%right PREFIXOP                         /* ! */
@
%todo: fix many conflicts by forwardporting from 4.00
% argh, ugly list above


<<grammar>>=

/* Entry points */

<<entry points rules>>


/* Module expressions */

<<structure rules>>

/* Module types */

<<signature [[rules]]>>


/* Core expressions */

<<expression rules>>

/* Patterns */

<<pattern rules>>

/* Type declarations */

<<type declaration rules>>

/* Core types */

<<type expression rules>>


/* Identifiers and long identifiers */

<<name rules>>

/* Toplevel directives */

<<toplevel [[rules]]>>

<<extra rules>>

/* Miscellaneous */

<<misc rules>>
<<ebnf rules>>
@


% the opt
<<ebnf rules>>=
opt_bar:
    /* empty */                                 { () }
  | BAR                                         { () }
;
opt_semi:
  | /* empty */                                 { () }
  | SEMI                                        { () }
;
@

% for syncweb
<<parsing/parser.ml>>=
@

\section{[[Compile.parse_file()]]}

%  let ast = parse_file inputfile Parse.implementation ast_impl_magic_number in
%  let ast = parse_file inputfile Parse.interface ast_intf_magic_number in

<<function [[Compile.parse_file]]>>=
let parse_file inputfile parse_fun ast_magic =
  let ic = open_in inputfile in
  <<[[Compile.parse_file()]] let [[is_ast_file]]>>
  let ast =
    try
      <<[[Compile.parse_file()]] if [[is_ast_file]]>>
      else begin
        seek_in ic 0;
        Location.input_name := inputfile;
        parse_fun (Lexing.from_channel ic)
      end
    with x -> close_in ic; raise x
  in
  close_in ic;
  ast
@
%less: can remove this intermediate? could not do everything in wrap?

<<signature [[Parse.implementation]]>>=
val implementation : Lexing.lexbuf -> Parsetree.structure
@
<<signature [[Parse.interface]]>>=
val interface : Lexing.lexbuf -> Parsetree.signature
@

<<function [[Parse.implementation]]>>=
let implementation = wrap Parser.implementation
@
<<function [[Parse.interface]]>>=
let interface = wrap Parser.interface
@


<<function [[Parse.wrap]]>>=
let wrap parsing_fun lexbuf =
  try
    let ast = parsing_fun Lexer.token lexbuf in
    Parsing.clear_parser();
    ast
  with
    | Parsing.Parse_error | Syntaxerr.Escape_error ->
        let loc = { loc_start = Lexing.lexeme_start lexbuf;
                    loc_end = Lexing.lexeme_end lexbuf } in
        if !Location.input_name = "" 
        then maybe_skip_phrase lexbuf;
        raise (Syntaxerr.Error(Syntaxerr.Other loc))

    | Lexer.Error(Lexer.Unterminated_comment, _, _) as err -> raise err
    | Lexer.Error(Lexer.Unterminated_string, _, _) as err -> raise err
    | Lexer.Error(_, _, _) as err ->
        if !Location.input_name = "" 
        then skip_phrase lexbuf;
        raise err
    | Syntaxerr.Error _ as err ->
        if !Location.input_name = "" 
        then maybe_skip_phrase lexbuf;
        raise err
@
%todo: factorize and aspectize maybe_skip_phrase

\section{The grammar entry points}

<<Parser entry points types>>=
%start implementation                   /* for implementation files */
%type <Parsetree.structure> implementation
%start interface                        /* for interface files */
%type <Parsetree.signature> interface
@


<<entry points rules>>=
implementation:
    structure EOF                        { $1 }
;
interface:
    signature EOF                        { List.rev $1 }
;
@



\subsection{Structures ([[.ml]])}
% the .ml
% Implementation


<<structure rules>>=
structure:
    structure_tail                              { $1 }
  | seq_expr structure_tail                     { mkstrexp $1 :: $2 }
;
structure_tail:
    /* empty */                                 { [] }
  | structure_item structure_tail               { $1 :: $2 }
  <<rule [[structure_tail]] optional semisemi cases>>
;
@
%$
%less: remove seq_expr? need? for directives? #open stuff?


<<structure rules>>=
structure_item:
    LET rec_flag let_bindings
      { match $3 with
          [{ppat_desc = Ppat_any}, exp] -> mkstr(Pstr_eval exp)
        | _ -> mkstr(Pstr_value($2, List.rev $3)) }
  | EXTERNAL val_ident COLON core_type EQUAL primitive_declaration
      { mkstr(Pstr_primitive($2, {pval_type = $4; pval_prim = $6})) }

  | TYPE type_declarations
      { mkstr(Pstr_type(List.rev $2)) }
  | EXCEPTION UIDENT constructor_arguments
      { mkstr(Pstr_exception($2, $3)) }

  | MODULE UIDENT module_binding
      { mkstr(Pstr_module($2, $3)) }
  | OPEN mod_longident
      { mkstr(Pstr_open $2) }
;
@

<<misc rules>>=
rec_flag:
    /* empty */                                 { Nonrecursive }
  | REC                                         { Recursive }
;
@

<<structure rules>>=
module_binding:
    EQUAL module_expr
      { $2 }
  | COLON module_type EQUAL module_expr
      { mkmod(Pmod_constraint($4, $2)) }
;
module_expr:
    mod_longident
      { mkmod(Pmod_ident $1) }
  | STRUCT structure END
      { mkmod(Pmod_structure($2)) }
  | LPAREN module_expr COLON module_type RPAREN
      { mkmod(Pmod_constraint($2, $4)) }
  | LPAREN module_expr RPAREN
      { $2 }
  <<rule [[module_expr]] error cases>>
;
@
%$

\ifallcode
<<rule [[structure_tail]] optional semisemi cases>>=
| SEMISEMI                                    { [] }
| SEMISEMI seq_expr structure_tail            { mkstrexp $2 :: $3 }
| SEMISEMI structure_item structure_tail      { $2 :: $3 }
@
%less: legacy, could remove
\fi


\subsection{Signatures ([[.mli]])}
% the .mli
% Ininterface

<<signature [[rules]]>>=
signature:
    /* empty */                                 { [] }
  | signature signature_item                    { $2 :: $1 }
  <<rule signature optional semisemi cases>>
;
@

<<signature [[rules]]>>=
signature_item:
    VAL val_ident COLON core_type
      { mksig(Psig_value($2, {pval_type = $4; pval_prim = []})) }
  | EXTERNAL val_ident COLON core_type EQUAL primitive_declaration
      { mksig(Psig_value($2, {pval_type = $4; pval_prim = $6})) }

  | TYPE type_declarations
      { mksig(Psig_type(List.rev $2)) }
  | EXCEPTION UIDENT constructor_arguments
      { mksig(Psig_exception($2, $3)) }

  | MODULE UIDENT module_declaration
      { mksig(Psig_module($2, $3)) }
  | OPEN mod_longident
      { mksig(Psig_open $2) }
;
@
%$

<<signature [[rules]]>>=
module_declaration:
    COLON module_type
      { $2 }
;

module_type:
    mty_longident
      { mkmty(Pmty_ident $1) }
  | SIG signature END
      { mkmty(Pmty_signature(List.rev $2)) }
  | LPAREN module_type RPAREN
      { $2 }
  <<rule [[module_type]] error cases>>
;

@
%$
%less: delete mty_longident, no module_type since removed functors,
% they make less sense then

<<extra rules>>=
primitive_declaration:
    STRING                                      { [$1] }
  | STRING primitive_declaration                { $1 :: $2 }
;
@
%$

\ifallcode
<<rule signature optional semisemi cases>>=
| signature signature_item SEMISEMI           { $2 :: $1 }
@
\fi


<<name rules>>=
mty_longident:
    ident                                       { Lident $1 }
  | mod_longident DOT ident                 { Ldot($1, $3) }
;
@
%$
%old: was mod_ex_longident
%less: maybe can remove now that don't allow module type

\section{Names}

% upper ident, lower ident

% when accept both?
<<name rules>>=
ident:
    UIDENT                                      { $1 }
  | LIDENT                                      { $1 }
;
@

<<name rules>>=
mod_longident:
    UIDENT                                      { Lident $1 }
  | mod_longident DOT UIDENT                    { Ldot($1, $3) }
;
@
%$
%old:
%mod_ext_longident:
%    UIDENT                                      { Lident $1 }
%  | mod_ext_longident DOT UIDENT                { Ldot($1, $3) }
%;
% diff? factorize no?



<<name rules>>=
val_ident:
    LIDENT                                      { $1 }
  | LPAREN operator RPAREN                      { $2 }
;
operator:
    PREFIXOP                                    { $1 }
  | INFIXOP0                                    { $1 }
  | INFIXOP1                                    { $1 }
  | INFIXOP2                                    { $1 }
  | INFIXOP3                                    { $1 }
  | INFIXOP4                                    { $1 }
  | SUBTRACTIVE                                 { $1 }
  | STAR                                        { "*" }
  | EQUAL                                       { "=" }
  | LESS                                        { "<" }
  | GREATER                                     { ">" }
  | OR                                          { "or" }
  | BARBAR                                      { "||" }
  | AMPERSAND                                   { "&" }
  | AMPERAMPER                                  { "&&" }
  | COLONEQUAL                                  { ":=" }
;
@
%$



\section{Types}

\subsection{Type expressions}
% type expressions?

% ?complex?, core, simple, 

% simple_xxx when have no -> or tuples, so certain atomic elts
% have priorities. -> is less priority than type application for
% instance.
<<type expression rules>>=

core_type:
    simple_core_type
      { $1 }
  | core_type MINUSGREATER core_type %prec prec_type_arrow
      { mktyp(Ptyp_arrow($1, $3)) }
  | core_type_tuple
      { mktyp(Ptyp_tuple(List.rev $1)) }
;

simple_core_type:
    QUOTE ident
      { mktyp(Ptyp_var $2) }

  | type_longident
      { mktyp(Ptyp_constr($1, [])) }
  | simple_core_type type_longident %prec prec_constr_appl
      { mktyp(Ptyp_constr($2, [$1])) }
  | LPAREN core_type_comma_list RPAREN type_longident
      %prec prec_constr_appl
      { mktyp(Ptyp_constr($4, List.rev $2)) }

  | LPAREN core_type RPAREN
      { $2 }
;
core_type_tuple:
    simple_core_type STAR simple_core_type      { [$3; $1] }
  | core_type_tuple STAR simple_core_type       { $3 :: $1 }
;
core_type_list:
    simple_core_type                            { [$1] }
  | core_type_list STAR simple_core_type        { $3 :: $1 }
;
@
%less: diff core_type_tuple and core_type_list?
%old:  <<rule core_type cases>>
%old:  <<rule simple_core_type cases>>

<<ebnf rules>>=
core_type_comma_list:
    core_type COMMA core_type                   { [$3; $1] }
  | core_type_comma_list COMMA core_type        { $3 :: $1 }
;
@


<<name rules>>=
type_longident:
    LIDENT                                      { Lident $1 }
  | mod_longident DOT LIDENT                { Ldot($1, $3) }
;
@
%old: was mod_ex_longident
%$

\subsection{Type declarations}

<<type declaration rules>>=
type_declarations:
    type_declaration                            { [$1] }
  | type_declarations AND type_declaration      { $3 :: $1 }
;
@
%$
% mutually recursive types

<<type declaration rules>>=
type_declaration:
    type_parameters LIDENT type_kind
      { let (kind, manifest) = $3 in
        ($2, {ptype_params = $1;
              ptype_kind = kind;
              ptype_manifest = manifest;
              ptype_loc = Location.symbol_loc()}) }
;
@
%$
% will see manifest later, it's for abbrev type (and abstract types
%  which are treated as a form of abbrev type I think)

<<type declaration rules>>=
type_kind:
  <<rule [[type_kind]] cases>>
;
@
%$ 
% can't use opt_bar?



\subsection{Polymorphic types}
% part2 (def), part1(use) is  in core type expr

<<type declaration rules>>=
type_parameters:
    /*empty*/                                   { [] }
  | type_parameter                              { [$1] }
  | LPAREN type_parameter_list RPAREN           { List.rev $2 }
;
type_parameter:
    QUOTE ident                                 { $2 }
;
@
%$

<<ebnf rules>>=
type_parameter_list:
    type_parameter                              { [$1] }
  | type_parameter_list COMMA type_parameter    { $3 :: $1 }
;
@
%$

\subsection{Variants, sum types}

<<rule [[type_kind]] cases>>=
| EQUAL constructor_declarations
    { (Ptype_variant(List.rev $2), None) }
| EQUAL BAR constructor_declarations
    { (Ptype_variant(List.rev $3), None) }
@

<<ebnf rules>>=
constructor_declarations:
    constructor_declaration                     { [$1] }
  | constructor_declarations BAR constructor_declaration { $3 :: $1 }
;
@
%$

<<type declaration rules>>=
constructor_declaration:
    constr_ident constructor_arguments          { ($1, $2) }
;
constructor_arguments:
    /*empty*/                                   { [] }
  | OF core_type_list                           { List.rev $2 }
;
@
%$

<<name rules>>=
constr_ident:
    UIDENT                                      { $1 }

  | LBRACKET RBRACKET                           { "[]" }
  | LPAREN RPAREN                               { "()" }
  | COLONCOLON                                  { "::" }
  | FALSE                                       { "false" }
  | TRUE                                        { "true" }
;
@
%$
% useful to have those builtins here? anyway
% we don't let user redefined them no?    

\subsection{Records, product types}

<<rule [[type_kind]] cases>>=
| EQUAL LBRACE label_declarations opt_semi RBRACE
    { (Ptype_record(List.rev $3), None) }
@
%$

<<ebnf rules>>=
label_declarations:
    label_declaration                           { [$1] }
  | label_declarations SEMI label_declaration   { $3 :: $1 }
;
@
%$

<<type declaration rules>>=
label_declaration:
    mutable_flag LIDENT COLON core_type         { ($2, $1, $4) }
;
@
%$

<<misc rules>>=
mutable_flag:
    /* empty */                                 { Immutable }
  | MUTABLE                                     { Mutable }
;
@


\section{Expressions}

<<expression rules>>=
expr:
    simple_expr
      { $1 }
  <<rule expr cases>>
  <<rule expr error cases>>
;
@
%$

% no "application" in simple_expr, atomic elts, e.g. constructor with no arg
<<expression rules>>=
simple_expr:
  | constant
      { mkexp(Pexp_constant $1) }
  | LPAREN seq_expr RPAREN
      { $2 }
  | BEGIN seq_expr END
      { $2 }
  <<rule [[simple_expr]] cases>>
  <<rule [[simple_expr]] error cases>>
;
@
%$


\subsection{Constants}

<<type [[Asttypes.constant]]>>=
type constant =
    Const_int of int
  | Const_char of char
  | Const_string of string
  | Const_float of string
@

<<extra rules>>=
constant:
    INT                                         { Const_int $1 }
  | CHAR                                        { Const_char $1 }
  | STRING                                      { Const_string $1 }
  | FLOAT                                       { Const_float $1 }
;
@

\subsection{Constructors}

<<rule [[simple_expr]] cases>>=
| constr_longident
    { mkexp(Pexp_construct($1, None)) }
@
%$
<<rule expr cases>>=
| constr_longident simple_expr %prec prec_constr_appl
    { mkexp(Pexp_construct($1, Some $2)) }
@
%$

<<name rules>>=
constr_longident:
    mod_longident                               { $1 }

  | LBRACKET RBRACKET                           { Lident "[]" }
  | LPAREN RPAREN                               { Lident "()" }
  | FALSE                                       { Lident "false" }
  | TRUE                                        { Lident "true" }
;
@
%$
% and why not :: here? because constr_longident can appear
% in pattern context and in that case :: is not a prefix but infix
% and so there is a special rule to pattern match ::

\subsection{Lists}

% special sugar
<<rule expr cases>>=
| expr COLONCOLON expr
    { mkexp(Pexp_construct(Lident "::", Some(mkexp(Pexp_tuple[$1;$3])))) }
@
%$
<<rule [[simple_expr]] cases>>=
| LBRACKET expr_semi_list opt_semi RBRACKET
    { mklistexp(List.rev $2) }
@
%$
% of Pexp_tuple! extra boxing?

<<function [[Parser.mklistexp]]>>=
let rec mklistexp = function
    [] ->
      mkexp(Pexp_construct(Lident "[]", None))
  | e1 :: el ->
      mkexp(Pexp_construct(Lident "::",
                           Some(mkexp(Pexp_tuple[e1; mklistexp el]))
                           ))
@

<<ebnf rules>>=
expr_semi_list:
    expr %prec prec_list                        { [$1] }
  | expr_semi_list SEMI expr %prec prec_list    { $3 :: $1 }
;
@

\subsection{Records}


<<rule [[simple_expr]] cases>>=
| LBRACE lbl_expr_list opt_semi RBRACE
    { mkexp(Pexp_record(List.rev $2)) }
@
%$

<<expression rules>>=
lbl_expr_list:
                       label_longident EQUAL expr %prec prec_list
      { [$1,$3] }
  | lbl_expr_list SEMI label_longident EQUAL expr %prec prec_list
      { ($3, $5) :: $1 }
;
@
%$
%less: could have lbl_expr intermdiate that factorize things no?

<<name rules>>=
label_longident:
    LIDENT                                      { Lident $1 }
  | mod_longident DOT LIDENT                    { Ldot($1, $3) }
;
@
%$


<<rule [[simple_expr]] cases>>=
| simple_expr DOT label_longident
    { mkexp(Pexp_field($1, $3)) }
@
% get

<<rule expr cases>>=
| simple_expr DOT label_longident LESSMINUS expr
    { mkexp(Pexp_setfield($1, $3, $5)) }
@
%$
% set


\subsection{Tuples}

%kinda of sugar for records? anon records?

<<rule expr cases>>=
| expr_comma_list
    { mkexp(Pexp_tuple(List.rev $1)) }
@
%$

<<ebnf rules>>=
expr_comma_list:
    expr_comma_list COMMA expr                  { $3 :: $1 }
  | expr COMMA expr                             { [$3; $1] }
;
@


\subsection{Functions, closures}

% lambda calcul! abs and app

<<rule expr cases>>=
| FUNCTION opt_bar match_cases %prec prec_fun
    { mkexp(Pexp_function(List.rev $3)) }
| FUN simple_pattern fun_def %prec prec_fun
    { mkexp(Pexp_function([$2, $3])) }
@
%$
% 2 different syntaxes in ocaml; confusing a bit

<<expression rules>>=
fun_def:
    match_action                                { $1 }
  | simple_pattern fun_def                      { mkexp(Pexp_function[$1,$2]) }
;
@
%$



<<rule expr cases>>=
| simple_expr simple_expr_list %prec prec_appl
    { mkexp(Pexp_apply($1, List.rev $2)) }
@
%$
% lambda calcul! app, core! and can be an expr! not just an ident

% curry
<<ebnf rules>>=
simple_expr_list:
    simple_expr                                 { [$1] }
  | simple_expr_list simple_expr                { $2 :: $1 }
;
@
%$

\subsection{[[let]], entity definitions}

<<rule expr cases>>=
| LET rec_flag let_bindings IN seq_expr %prec prec_let
    { mkexp(Pexp_let($2, List.rev $3, $5)) }
@

<<ebnf rules>>=
let_bindings:
    let_binding                                 { [$1] }
  | let_bindings AND let_binding                { $3 :: $1 }
;
@
%$
% mutually recursive, AND

<<expression rules>>=
let_binding:
    val_ident fun_binding
      { ({ppat_desc = Ppat_var $1; ppat_loc = rhs_loc 1}, $2) }
  | pattern EQUAL seq_expr %prec prec_let
      { ($1, $3) }
;
@
% pattern can't be an ident?

<<expression rules>>=
fun_binding:
    EQUAL seq_expr %prec prec_let
      { $2 }
  | simple_pattern fun_binding
      { mkexp(Pexp_function[$1,$2]) }
  <<rule [[fun_binding]] cases>>
;
@
%$
% not necessarally a function actually



\subsection{Entity uses}

<<rule [[simple_expr]] cases>>=
|  val_longident
    { mkexp(Pexp_ident $1) }
@
%$

<<name rules>>=
val_longident:
    val_ident                                   { Lident $1 }
  | mod_longident DOT val_ident                 { Ldot($1, $3) }
;
@
%$


\subsection{Operators}

\subsubsection{Infix operators}

<<rule expr cases>>=
| expr INFIXOP0 expr
    { mkinfix $1 $2 $3 }
| expr INFIXOP1 expr
    { mkinfix $1 $2 $3 }
| expr INFIXOP2 expr
    { mkinfix $1 $2 $3 }
| expr INFIXOP3 expr
    { mkinfix $1 $2 $3 }
| expr INFIXOP4 expr
    { mkinfix $1 $2 $3 }

| expr SUBTRACTIVE expr
    { mkinfix $1 $2 $3 } 
| expr STAR expr
    { mkinfix $1 "*" $3 } 

| expr EQUAL expr
    { mkinfix $1 "=" $3 } 
| expr LESS expr
    { mkinfix $1 "<" $3 } 
| expr GREATER expr
    { mkinfix $1 ">" $3 } 

| expr BARBAR expr
    { mkinfix $1 "||" $3 }
| expr AMPERAMPER expr
    { mkinfix $1 "&&" $3 }

| expr COLONEQUAL expr
    { mkinfix $1 ":=" $3 }
@

%less: remove
<<rule expr cases>>=
| expr OR expr
    { mkinfix $1 "or" $3 }
| expr AMPERSAND expr
    { mkinfix $1 "&" $3 }

@

<<function [[Parser.mkinfix]]>>=
let mkinfix arg1 name arg2 =
  mkexp(Pexp_apply(mkoperator name 2, [arg1; arg2]))
@

\subsubsection{Prefix operators}

<<rule expr cases>>=
| SUBTRACTIVE expr %prec prec_unary_minus
    { mkuminus $1 $2 }
@
% not sure why can't be merged with next case

<<function [[Parser.mkuminus]]>>=
let mkuminus name arg =
  match arg.pexp_desc with
    Pexp_constant(Const_int n) ->
      mkexp(Pexp_constant(Const_int(-n)))
  | Pexp_constant(Const_float f) ->
      mkexp(Pexp_constant(Const_float("-" ^ f)))
  | _ ->
      mkexp(Pexp_apply(mkoperator ("~" ^ name) 1, [arg]))
@

<<rule [[simple_expr]] cases>>=
| PREFIXOP simple_expr
    { mkexp(Pexp_apply(mkoperator $1 1, [$2])) }
@

<<functions Parser.mkoperator>>=
let mkoperator name pos =
  { pexp_desc = Pexp_ident(Lident name); pexp_loc = rhs_loc pos }
@


<<signature [[Location.rhs_loc]]>>=
val rhs_loc: int -> t
@
<<function [[Location.rhs_loc]]>>=
let rhs_loc n =
  { loc_start = Parsing.rhs_start n; loc_end = Parsing.rhs_end n }
@

\subsection{Casts}

<<rule [[simple_expr]] cases>>=
| LPAREN seq_expr type_constraint RPAREN
    { mkexp(Pexp_constraint($2, $3)) }
@
%$

<<expression rules>>=
type_constraint:
    COLON core_type                             { ($2) }
  | COLON error                                 { syntax_error() }
;
@
%$



<<rule [[fun_binding]] cases>>=
| type_constraint EQUAL seq_expr %prec prec_let
    { mkexp(Pexp_constraint($3, $1)) }
@


\section{Patterns}

<<rule expr cases>>=
| MATCH seq_expr WITH opt_bar match_cases %prec prec_match
    { mkexp(Pexp_match($2, List.rev $5)) }
@

% also in FUNCTION and FUN have a match_cases

<<expression rules>>=
match_cases:
    pattern match_action                        { [$1, $2] }
  | match_cases BAR pattern match_action        { ($3, $4) :: $1 }
;
match_action:
    MINUSGREATER seq_expr                       { $2 }
  | WHEN seq_expr MINUSGREATER seq_expr         { mkexp(Pexp_when($2, $4)) }
;
@

<<pattern rules>>=
pattern:
    simple_pattern
      { $1 }

  | constr_longident pattern %prec prec_constr_appl
      { mkpat(Ppat_construct($1, Some $2)) }
  | pattern COLONCOLON pattern
      { mkpat(Ppat_construct(Lident "::", Some(mkpat(Ppat_tuple[$1;$3]))
                             )) }
  | pattern_comma_list
      { mkpat(Ppat_tuple(List.rev $1)) }

  | pattern AS val_ident
      { mkpat(Ppat_alias($1, $3)) }
  | pattern BAR pattern
      { mkpat(Ppat_or($1, $3)) }
;
@
% special case for :: here
%todo? could do other constructor like operator? e.g. :=>

% again, just atomic elt here, no application, e.g. constructor with no args
<<pattern rules>>=
simple_pattern:
  | signed_constant
      { mkpat(Ppat_constant $1) }

  | constr_longident
      { mkpat(Ppat_construct($1, None)) }
  | LBRACE lbl_pattern_list opt_semi RBRACE
      { mkpat(Ppat_record(List.rev $2)) }

  | val_ident
      { mkpat(Ppat_var $1) }
  | UNDERSCORE
      { mkpat(Ppat_any) }

  | LPAREN pattern RPAREN
      { $2 }

  | LPAREN pattern COLON core_type RPAREN
      { mkpat(Ppat_constraint($2, $4)) }
  <<rule [[simple_pattern]] other cases>>
  <<rule [[simple_pattern]] error cases>>
;
@
%$
% another special case of lists


<<extra rules>>=
signed_constant:
    constant                                    { $1 }
  | SUBTRACTIVE INT                             { Const_int(- $2) }
  | SUBTRACTIVE FLOAT                           { Const_float("-" ^ $2) }
;
@
%$

<<pattern rules>>=
lbl_pattern_list:
    label_longident EQUAL pattern               { [($1, $3)] }
  | lbl_pattern_list SEMI label_longident EQUAL pattern { ($3, $5) :: $1 }
;
@
%$



<<ebnf rules>>=
pattern_comma_list:
    pattern_comma_list COMMA pattern            { $3 :: $1 }
  | pattern COMMA pattern                       { [$3; $1] }
;
@

<<ebnf rules>>=
pattern_semi_list:
    pattern                                     { [$1] }
  | pattern_semi_list SEMI pattern              { $3 :: $1 }
;
@
%$

<<rule [[simple_pattern]] other cases>>=
  | LBRACKET pattern_semi_list opt_semi RBRACKET
      { mklistpat(List.rev $2) }
@
%$

<<function [[Parser.mklistpat]]>>=
let rec mklistpat = function
    [] ->
      mkpat(Ppat_construct(Lident "[]", None))
  | p1 :: pl ->
      mkpat(Ppat_construct(Lident "::",
                           Some(mkpat(Ppat_tuple[p1; mklistpat pl]))
                           ))
@

\section{Statements}

\subsection{Sequences}

<<expression rules>>=
seq_expr:
  | expr                          { $1 }
  | expr SEMI                     { $1 }
  | expr SEMI seq_expr            { mkexp(Pexp_sequence($1, $3)) }
;
@

\subsection{Conditionals}

<<rule expr cases>>=
| IF seq_expr THEN expr ELSE expr %prec prec_if
    { mkexp(Pexp_ifthenelse($2, $4, Some $6)) }
| IF seq_expr THEN expr %prec prec_if
    { mkexp(Pexp_ifthenelse($2, $4, None)) }
@
%$

% why seq_expr for the condition? bof

\subsection{Loops}

<<rule expr cases>>=
| WHILE seq_expr DO seq_expr DONE
    { mkexp(Pexp_while($2, $4)) }
| FOR val_ident EQUAL seq_expr direction_flag seq_expr DO seq_expr DONE
    { mkexp(Pexp_for($2, $4, $6, $5, $8)) }
@
%$

<<misc rules>>=
direction_flag:
    TO                                          { Upto }
  | DOWNTO                                      { Downto }
;
@

\subsection{Exceptions}

<<rule expr cases>>=
| TRY seq_expr WITH opt_bar match_cases %prec prec_try
    { mkexp(Pexp_try($2, List.rev $5)) }
@

% see also exception declaration

\section{Helpers}

<<functions Parser.mkxxx>>=
let mktyp d =
  { ptyp_desc = d; ptyp_loc = Location.symbol_loc() }
let mkpat d =
  { ppat_desc = d; ppat_loc = Location.symbol_loc() }
let mkexp d =
  { pexp_desc = d; pexp_loc = Location.symbol_loc() }
let mkmty d =
  { pmty_desc = d; pmty_loc = Location.symbol_loc() }
let mksig d =
  { psig_desc = d; psig_loc = Location.symbol_loc() }
let mkmod d =
  { pmod_desc = d; pmod_loc = Location.symbol_loc() }
let mkstr d =
  { pstr_desc = d; pstr_loc = Location.symbol_loc() }
@


<<Parser header>>=
open Location
open Asttypes
open Longident
open Parsetree

<<functions Parser.mkxxx>>

<<functions Parser.mkoperator>>

<<function [[Parser.mkassert]]>>

<<function [[Parser.mklazy]]>>

<<function [[Parser.mkinfix]]>>

<<function [[Parser.mkuminus]]>>

<<function [[Parser.mklistexp]]>>

<<function [[Parser.mklistpat]]>>

<<function [[Parser.mkstrexp]]>>

<<function [[Parser.array_function]]>>

<<function [[Parser.mkrangepat]]>>

let syntax_error () =
  raise Syntaxerr.Escape_error

let unclosed opening_name opening_num closing_name closing_num =
  raise(Syntaxerr.Error(Syntaxerr.Unclosed(rhs_loc opening_num, opening_name,
                                           rhs_loc closing_num, closing_name)))

@






\chapter{Typing}
% Naming and typing

% reput 'type_expr' def from core DS chapter?

% This phase will build an environment, will load .cmi of other files
% Will do naming and typing; interwinded thing.
% You can't do typing if you don't know precisely to which
% entity an identifier refers to.

%different type systems in ocaml:
% - https://github.com/tomprimozic/type-systems
% - https://www.cis.upenn.edu/~bcpierce/tapl/checkers/ from pierce's book TAPL

\section{Resolving names}
%Naming? A special section? nast

% there is 'open' in ocaml, and even if I was forbidding it,
% there will still be the implicit 'open pervasives', so
% you need to resolve identifiers.

% fully qualifying every identifiers!

\subsection{[[Ident]]}

% Can have let x = ... in let x = ... in the same module,
% need to create different identifier each time.
% In the same way can reuse the same identifier in patterns
% in different rules, or have different functions sharing
% parameters. Anyway, convenient to "resolve" names.
% At some point when generate assembly you will need unique names!

<<type [[Ident.t]]>>=
type t = { 
  mutable name: string; 
  mutable stamp: int; 
  <<[[Ident.t]] other fields>>
}
@
% what global is for? it's compiler semantic info, for
% ident that are to be retrieved via Kgetglobal

% for builtins, toplevel things, local let, everything -> <>
<<signature [[Ident.create]]>>=
val create: string -> t
@
<<constant [[Ident.currentstamp]]>>=
(* A stamp of 0 denotes a persistent identifier *)
let currentstamp = ref 0
@
% will see later that a persistent identifier is
<<function [[Ident.create]]>>=
let create s =
  incr currentstamp;
  { name = s; stamp = !currentstamp; global = false }
@
% this is never decremented.
% see also make_global() and create_persistent()
%todo: why need global? stamp not enough?

%ex: unit test?
%let ident_int = Ident.create "int"
% unique!

<<signature [[Ident.name]]>>=
val name: t -> string
@
<<function [[Ident.name]]>>=
let name i = 
  i.name
@

% persistent?? global??


\subsection{[[Path]]}
% qualifier

% path is fully qualified entity.
% once we can fully name identifiers, we can look
% for their type in the symbol table.

<<type [[Path.t]]>>=
(* Access paths *)

type t =
    Pident of Ident.t
  | Pdot of t *  string * int
@
% int? when multiple occurents of same name? like let x = ... in let x = ...?
%  why not simply Pdot of t * Ident.t?
%  the int is a 'pos' see prefix_idents, so is it compiler-oriented?
%  to know some offset? for instance type in .cmi have no associated
%  pos! it's using nopos! and you need that only for external
%  entity, for local entity Ident.t is enough
% vs Longident and Lident and Ldot?

%ex: unit test?
%let path_int = Pident ident_int,  not even Pervasives! higher than that

\section{Resolving types}
%The typed AST

% mainly string -> Ident.t, Longident.t -> Path.t,
% and core_type -> type_expr.

% seen type_expr in core DS chapter.

\subsection{Signatures, the [[.cmi]]}

<<type [[Types.signature]]>>=
and signature = signature_item list
@
% .cmi, that is important! we will load that to know the
% type of entities referenced but defined in other module!
% no .h in ocaml :)

<<type [[Types.signature_item]]>>=
and signature_item =
    Tsig_value of Ident.t * value_description

  | Tsig_type of Ident.t * type_declaration
  | Tsig_exception of Ident.t * exception_declaration
  | Tsig_module of Ident.t * module_type
@
%diff? no open anymore, not needed, have Path now.


%\subsection Types.xxx
<<type [[Types.value_description]]>>=
(* Value descriptions *)

type value_description =
  { val_type: type_expr;                       (* Type of the val *)
    val_prim: Primitive.description option }   (* Is this a primitive? *)
@
% diff? core_type -> type_expr! same in most of what is below.
% also val_prim string list become more precise type
% this is the main thing we want! the type of things!



<<type [[Types.type_declaration]]>>=
type type_declaration =
  { type_params: type_expr list;
    type_arity: int; (* List.length td.type_params *)
    type_kind: type_kind;
    <<[[Types.type_declaration]] other fields>>
  }
@
% diff type_params string list -> type_expr list, 
% but can only be Tvar no? can do type (int, int) myhash = ... ?? 
% does not mean anything no?
%ex: put decl_bool here?


<<type [[Types.type_kind]]>>=
and type_kind =
  | Type_variant of (string * type_expr list) list
  | Type_record of (string * mutable_flag * type_expr) list
  <<[[Types.type_kind]] cases>>
@
% diff? Ptxx->Txx

<<[[Types.type_kind]] cases>>=
| Type_abstract
@
% it's actually useful for some builtin types too! type int;; type float;;
% (type bool is a Type_variant though!)
% because int is neither a variant or a record (or it's very special
% kind of variant ...)

<<type [[Types.exception_declaration]]>>=
type exception_declaration = type_expr list
@
% diff? again, core_type -> type_expr

<<type [[Types.module_type]]>>=
type module_type =
    Tmty_ident of Path.t
  | Tmty_signature of signature
@
%less: remove Tmty_ident


\subsection{Typed expressions}


<<type [[Typedtree.expression]]>>=
type expression =
  { exp_desc: expression_desc;
    exp_loc: Location.t;
    exp_type: type_expr; }
@
%diff = type_expr! again this is the main thing we want!

<<type [[Typedtree.expression_desc]]>>=
and expression_desc =
  | Texp_constant of constant
  | Texp_construct of constructor_description * expression list
  | Texp_record of (label_description * expression) list
  | Texp_tuple of expression list

  | Texp_function of (pattern * expression) list
  | Texp_apply of expression * expression list

  | Texp_field of expression * label_description
  | Texp_setfield of expression * label_description * expression

  | Texp_let of rec_flag * (pattern * expression) list * expression
  | Texp_ident of Path.t * value_description

  | Texp_match of expression * (pattern * expression) list
  | Texp_when of expression * expression

  | Texp_try of expression * (pattern * expression) list
  | Texp_ifthenelse of expression * expression * expression option
  | Texp_sequence of expression * expression
  | Texp_while of expression * expression
  | Texp_for of
      Ident.t * expression * expression * direction_flag * expression

  <<[[Typedtree.expression_desc]] cases>>
@
% diff? resolved Path for ident and value_description!
% and no more Pexp_constraint


<<type [[Types.constructor_description]]>>=
type constructor_description =
  { cstr_res: type_expr;                (* Type of the result *)
    cstr_args: type_expr list;          (* Type of the arguments *)
    cstr_arity: int;                    (* Number of arguments *)

    <<[[Types.constructor_description]] other fields>>
   }
@
% a constructor is kinda like a function, it has args and return a type
% diff with before? from a Longident.t to full information about
% the constructor!

<<type [[Types.label_description]]>>=
type label_description =
  { lbl_res: type_expr;                 (* Type of the result *)
    lbl_arg: type_expr;                 (* Type of the argument *)
    lbl_mut: mutable_flag;              (* Is this a mutable field? *)

    <<[[Types.label_description]] other fields>>
  }
@
% diff with before? from a Longident.t to full information about
% the label!



\subsection{Typed patterns}
% but not the .cmo, the .cmo contain bytecode, very
% different nature.
% it's more the .cmt


%\subsection Typedtree.xxx

% could factorize?

<<type [[Typedtree.pattern]]>>=
type pattern =
  { pat_desc: pattern_desc;
    pat_loc: Location.t;
    pat_type: type_expr }
@
% note that pat_type now!

<<type [[Typedtree.pattern_desc]]>>=
and pattern_desc =
  | Tpat_any
  | Tpat_var of Ident.t

  | Tpat_constant of constant
  | Tpat_construct of constructor_description * pattern list
  | Tpat_record of (label_description * pattern) list

  | Tpat_tuple of pattern list

  | Tpat_alias of pattern * Ident.t
  | Tpat_or of pattern * pattern
@
% diff? for Ppat_constructor from a longident to a full
% resolved and type constructor_description now! see later.
% same for Tpat_record
% no more Ppat_constraint also


\subsection{Typed modules}

<<type [[Typedtree.module_expr]]>>=
type module_expr =
  { mod_desc: module_expr_desc;
    mod_loc: Location.t;
    mod_type: module_type; }
@

<<type [[Typedtree.module_expr_desc]]>>=
and module_expr_desc =
    Tmod_ident of Path.t
  | Tmod_structure of structure
  | Tmod_constraint of module_expr * module_type * module_coercion
@
%todo: module_coercion? need?

<<type [[Typedtree.structure]]>>=
and structure = structure_item list
@

<<type [[Typedtree.structure_item]]>>=
and structure_item =
    Tstr_eval of expression
  | Tstr_value of rec_flag * (pattern * expression) list
  | Tstr_primitive of Ident.t * value_description

  | Tstr_type of (Ident.t * type_declaration) list
  | Tstr_exception of Ident.t * exception_declaration

  | Tstr_module of Ident.t * module_expr
  | Tstr_open of Path.t
@
%less: why keep str_open info in typed tree? everything is resolved
% anyway


\section{Builtins}

% examples!!

\subsection{Builtin types}
% (and exceptions but exceptions are LP splitted and presented later)

%(* Predefined type constructors (with special typing rules in typecore) *)

<<signatures [[Predef.type_xxx]]>>=
val type_int    : type_expr
val type_char   : type_expr
val type_string : type_expr
val type_float  : type_expr
val type_bool   : type_expr
val type_unit   : type_expr

val type_list  : type_expr -> type_expr
@


<<constants [[Predef.type_xxx]]>>=
let type_int     = Tconstr(path_int, [])
and type_char    = Tconstr(path_char, [])
and type_string  = Tconstr(path_string, [])
and type_float   = Tconstr(path_float, [])
and type_bool    = Tconstr(path_bool, [])
and type_unit    = Tconstr(path_unit, [])

and type_list t = Tconstr(path_list, [t])
@




<<signatures [[Predef.path_xxx]]>>=
val path_int: Path.t
val path_char: Path.t
val path_string: Path.t
val path_float: Path.t
val path_bool: Path.t
val path_unit: Path.t

val path_list: Path.t
@

<<constants [[Predef.path_xxx]]>>=
let path_int = Pident ident_int
and path_char = Pident ident_char
and path_string = Pident ident_string
and path_float = Pident ident_float
and path_bool = Pident ident_bool
and path_unit = Pident ident_unit

and path_list = Pident ident_list
@



<<constants [[Predef.ident_xxx]]>>=
let ident_int = Ident.create "int"
and ident_char = Ident.create "char"
and ident_string = Ident.create "string"
and ident_float = Ident.create "float"
and ident_bool = Ident.create "bool"
and ident_unit = Ident.create "unit"

and ident_exn = Ident.create "exn"

and ident_array = Ident.create "array"
and ident_list = Ident.create "list"
@
% no module
% subtle: don't change the order here, otherwise you may
%  have problem in otherlibs/unix, and get error like
%  "type exn is used where expect exn"





<<function [[Typecore.type_constant]]>>=
(* Typing of constants *)

let type_constant = function
    Const_int _ -> Predef.type_int
  | Const_char _ -> Predef.type_char
  | Const_string _ -> Predef.type_string
  | Const_float _ -> Predef.type_float
@


\subsection{Builtin values}
% different from primitives
% different from pervasives

<<signature [[Predef.build_initial_env]]>>=
(* To build the initial environment. Since there is a nasty mutual
   recursion between predef and env, we break it by parameterizing
   over Env.t, Env.add_type and Env.add_exception. *)

val build_initial_env:
  (Ident.t -> type_declaration -> 'a -> 'a) ->      (* add_type *)
  (Ident.t -> exception_declaration -> 'a -> 'a) -> (* add_exception *)
  'a -> 'a
@
% will see add_type and the environment later! 'a is really Env.t here.


<<function [[Predef.build_initial_env]]>>=
let build_initial_env add_type add_exception empty_env =
  let newvar() =
    (* Cannot call the real newvar from ctype here
       because ctype imports predef via env *)
    Tvar{
      tvar_link = None; 
      <<[[Predef.build_initial_env()]] set other fields in local newvar>>
    } 
  in

  <<[[Predef.build_initial_env()]] decls>>
  <<[[Predef.build_initial_env()]] adding exceptions>>

  add_type ident_format decl_format (

  add_type ident_list decl_list (
  add_type ident_array decl_array (

  add_type ident_exn decl_exn (

  add_type ident_unit decl_unit (
  add_type ident_bool decl_bool (

  add_type ident_float decl_abstr (
  add_type ident_string decl_abstr (
  add_type ident_char decl_abstr (
  add_type ident_int decl_abstr (
  empty_env
  )))))))))))))))))))
@

% where all of this is stored? in an environment,
% will see Env.t soon

<<[[Predef.build_initial_env()]] decls>>=
let decl_bool =
  {type_params = [];
   type_arity = 0;
   type_kind = Type_variant["false",[]; "true",[]];
   type_manifest = None}
in
let decl_unit =
  {type_params = []; 
   type_arity = 0;
   type_kind = Type_variant["()",[]];
   type_manifest = None}
in
@


<<[[Predef.build_initial_env()]] decls>>=
let decl_list =
  let tvar = newvar() in
  {type_params = [tvar];
   type_arity = 1;
   type_kind = Type_variant["[]", []; "::", [tvar; type_list tvar]];
   type_manifest = None}
in
@
% newvar? should be a generic type no?


% why decl_abstr for float, string, char, int?
% because not a simple value from a variant or record!
% all the other are
% Abuse Type_abstract for that!

<<[[Predef.build_initial_env()]] decls>>=
let decl_abstr =
  {type_params = [];
   type_arity = 0;
   type_kind = Type_abstract;
   type_manifest = None}
in
@



\subsection{Primitives}

<<type [[Primitive.description]]>>=
(* Description of primitive functions *)

type description =
  { prim_name: string;         (* Name of primitive  or C function *)
    prim_arity: int;           (* Number of arguments *)
    prim_alloc: bool;          (* Does it allocates or raise? *)
    prim_native_name: string;  (* Name of C function for the nat. code gen. *)

    prim_native_float: bool }  (* Does the above operate on unboxed floats? *)
@

% Note that there are 2 kinds of primitives (both declared with external):
%  - primitives recognized by ocamlc (e.g. %raise, %eq)
%  - external calls to C functions

<<signature [[Primitive.parse_declaration]]>>=
val parse_declaration: int -> string list -> description option
@

<<function [[Primitive.parse_declaration]]>>=
let parse_declaration arity decl =
  match decl with
    name :: "noalloc" :: name2 :: "float" :: _ ->
      Some{prim_name = name; prim_arity = arity; prim_alloc = false;
           prim_native_name = name2; prim_native_float = true}
  | name :: "noalloc" :: name2 :: _ ->
      Some{prim_name = name; prim_arity = arity; prim_alloc = false;
           prim_native_name = name2; prim_native_float = false}
  | name :: name2 :: "float" :: _ ->
      Some{prim_name = name; prim_arity = arity; prim_alloc = true;
           prim_native_name = name2; prim_native_float = true}
  | name :: "noalloc" :: _ ->
      Some{prim_name = name; prim_arity = arity; prim_alloc = false;
           prim_native_name = ""; prim_native_float = false}
  | name :: name2 :: _ ->
      Some{prim_name = name; prim_arity = arity; prim_alloc = true;
           prim_native_name = name2; prim_native_float = false}
  | name :: _ ->
      Some{prim_name = name; prim_arity = arity; prim_alloc = true;
           prim_native_name = ""; prim_native_float = false}
  | [] ->
      None
@


\section{The (typed, named) symbol table}
% The typed, resolved symbol table [[Env.t]]

\subsection{[[Env.t]]}

<<signature type Env.t>>=
type t
@
% abstract type!

% Associate to Ident in env in scope the full information about it, that is
% its full path, and it's type.
% This env will evolve as we typecheck a program and recurse on its
% AST.
% but if maps ident to stuff, how get fully qualified like X.y?
% because X itself is an ident! and it will be in module_components
% where then you can look for info about y.

<<type [[Env.t]]>>=
type t = {
  values     : (Path.t * Types.value_description) Ident.tbl;
  <<[[Env.t]] other fields>>
}
@
%recall that 'type value_description =
%  { pval_type: core_type;
%    pval_prim: string list }
% so this is really the typing environment! map an ident to its type.


<<[[Env.t]] other fields>>=
types      : (Path.t * Types.type_declaration)  Ident.tbl;

modules    : (Path.t * Types.module_type)       Ident.tbl;
components : (Path.t * module_components)       Ident.tbl;

constrs    : Types.constructor_description      Ident.tbl;
labels     : Types.label_description            Ident.tbl;
@
%less: no Path for constructor and record?
% not needed?
%less: components?? should rename modules to modtypes, and components to modules
%less: exn? same as types?
%less: diff with components? values/types/constrs/labels are
% for the currently accessible toplevel elts? so after a open
% we populate those tables?
%old:  summary: summary, used by debugger.

<<type [[Env.module_components]]>>=
and module_components =
    Structure_comps of structure_components
@

<<type [[Env.structure_components]]>>=
and structure_components = {
  mutable comp_values     : (string, (Types.value_description * int)) Tbl.t;
  mutable comp_types      : (string, (Types.type_declaration * int))  Tbl.t;

  mutable comp_modules    : (string, (Types.module_type * int))       Tbl.t;
  mutable comp_components : (string, (module_components * int))       Tbl.t;

  mutable comp_constrs    : (string, (constructor_description * int)) Tbl.t;
  mutable comp_labels     : (string, (label_description * int))       Tbl.t;
}
@
%Why need that in typing context? Env.modules not enough?
% because .cmi are also used for separate compilation! to know
% offsets of external entities! this is what probably the int is for above.
%todo: replace by just Env.t itself no?
% no because the purpose is different. The key are string here!
% before they are Ident and they return a pair of Path and the value.
%todo: what is the int above? like in Ident, to handle dupe names in one modul?
%todo: this is also in the .cmi

<<signature [[Env.empty]]>>=
val empty: t
@

<<constant [[Env.empty]]>>=
let empty = {
  values = Ident.empty; 
  constrs = Ident.empty;
  labels = Ident.empty; 
  types = Ident.empty;
  modules = Ident.empty;
  components = Ident.empty; }
@
%old:  summary = Env_empty }

% this will evolve as we go down and introduce more local entities.

<<signature [[Env.initial]]>>=
val initial: t
@

% compile? -> <>
<<constant [[Env.initial]]>>=
(* Make the initial environment *)

let initial = Predef.build_initial_env add_type add_exception empty
@
% bool, int, etc. Even before Pervasives!



\subsection{Example of use, [[open]]}
% naming issue

% good to see an example of the kinda of API
% we need. otherwise just see hundreds of small
% functions without understand why they are needed.

<<signature [[Env.open_signature]]>>=
(* Insertion of all fields of a signature, relative to the given path.
   Used to implement open. *)

val open_signature: Path.t -> signature -> t -> t
@
% when do open X.Y, then all use of entities from module X.Y
% should be fully qualified and resolved when we encouter them.

% sg = signature
<<function [[Env.open_signature]]>>=
(* Open a signature path *)

let open_signature root sg env =
  (* First build the paths and substitution *)
  let (pl, sub) = prefix_idents root 0 Subst.identity sg in

  (* Then enter the components in the environment after substitution *)
  pl |> List.fold_left2 (fun env item p ->
      match item with
      (* boilerplate and overloading *)
      | Tsig_value(id, decl) ->
          store_value (Ident.hide id) p
                      (Subst.value_description sub decl) env

      | Tsig_type(id, decl) ->
          store_type (Ident.hide id) p
                     (Subst.type_declaration sub decl) env
      | Tsig_exception(id, decl) ->
          store_exception (Ident.hide id) p
                          (Subst.exception_declaration sub decl) env
      | Tsig_module(id, mty) ->
          store_module (Ident.hide id) p 
                       (Subst.modtype sub mty) env
    )
    env sg
@
% no need subst the id returned by Ident.hide since it appears
% only on the left. In a .mli there are no recursive things,
% only in the .ml and structures.

<<signature [[Ident.hide]]>>=
val hide: t -> t
        (* Return an identifier with same name as the given identifier,
           but stamp different from any stamp returns by new.
           When put in a 'a tbl, this identifier can only be looked
           up by name. *)
@
<<function [[Ident.hide]]>>=
let hide i =
  { stamp = -1; name = i.name; global = i.global }
@
% ???

<<function [[Env.prefix_idents]]>>=
(* Given a signature and a root path, prefix all idents in the signature
   by the root path and build the corresponding substitution. *)

let rec prefix_idents root pos sub = function
    [] -> ([], sub)
  | Tsig_value(id, decl) :: rem ->
      let p = Pdot(root, Ident.name id, pos) in
      let nextpos = match decl.val_prim with None -> pos+1 | Some _ -> pos in
      let (pl, final_sub) = prefix_idents root nextpos sub rem in
      (p::pl, final_sub)

  | Tsig_type(id, decl) :: rem ->
      let p = Pdot(root, Ident.name id, nopos) in
      let (pl, final_sub) =
        prefix_idents root pos (Subst.add_type id p sub) rem in
      (p::pl, final_sub)
  | Tsig_exception(id, decl) :: rem ->
      let p = Pdot(root, Ident.name id, pos) in
      let (pl, final_sub) = prefix_idents root (pos+1) sub rem in
      (p::pl, final_sub)
  | Tsig_module(id, mty) :: rem ->
      let p = Pdot(root, Ident.name id, pos) in
      let (pl, final_sub) =
        prefix_idents root (pos+1) (Subst.add_module id p sub) rem in
      (p::pl, final_sub)
@
% pos? what for? for primitives??


<<signature [[Path.nopos]]>>=
val nopos: int
@
<<constant [[Path.nopos]]>>=
let nopos = -1
@





\subsection{Populating the environment}

\subsubsection{By [[Ident]] and [[Path]]}

% (* Insertion of bindings by identifier + path *)

<<function [[Env.store_value]]>>=
and store_value id path decl env =
  { values = Ident.add id (path, decl) env.values;
    (* boilerplate, with record *)
    constrs = env.constrs;
    labels = env.labels;
    types = env.types;
    modules = env.modules;
    components = env.components }
@
%todo: env with syntax! will factorize lots of code already

<<function [[Env.store_type]]>>=
and store_type id path info env =
  { types = Ident.add id (path, info) env.types;
    constrs =
      env.constrs |> List.fold_right (fun (name, descr) constrs ->
          Ident.add (Ident.create name) descr constrs
      ) (constructors_of_type path info);
    labels =
      env.labels |> List.fold_right (fun (name, descr) labels ->
          Ident.add (Ident.create name) descr labels
        ) (labels_of_type path info);
    (* boilerplate, with record *)
    values = env.values;
    modules = env.modules;
    components = env.components }
@


<<function [[Env.constructors_of_type]]>>=
(* Compute constructor descriptions *)

let constructors_of_type ty_path decl =
  match decl.type_kind with
    Type_variant cstrs ->
      Datarepr.constructor_descrs (Tconstr(ty_path, decl.type_params)) cstrs
  | _ -> []
@
% Datarep.xxx adds more semantic info to it, but more compiler oriented,
% so we will see it later

<<function [[Env.labels_of_type]]>>=
(* Compute label descriptions *)

let labels_of_type ty_path decl =
  match decl.type_kind with
    Type_record labels ->
      Datarepr.label_descrs (Tconstr(ty_path, decl.type_params)) labels
  | _ -> []
@


<<function [[Env.store_module]]>>=
and store_module id path mty env =
  { modules = Ident.add id (path, mty) env.modules;
    components =
      Ident.add id (path, components_of_module env Subst.identity path mty)
                   env.components;
    (* boilerplate, with record *)
    values = env.values;
    constrs = env.constrs;
    labels = env.labels;
    types = env.types;
}
@

<<function [[Env.store_components]]>>=
and store_components id path comps env =
  { components = Ident.add id (path, comps) env.components;
    (* boilerplate, with record *)
    values = env.values;
    constrs = env.constrs;
    labels = env.labels;
    types = env.types;
    modules = env.modules;
  }
@



<<function [[Env.components_of_module]]>>=
let rec components_of_module env sub path mty =
  match scrape_modtype mty env with
    Tmty_signature sg ->
      let c =
        { comp_values = Tbl.empty; comp_constrs = Tbl.empty;
          comp_labels = Tbl.empty; comp_types = Tbl.empty;
          comp_modules = Tbl.empty; 
          comp_components = Tbl.empty } in
      let (pl, sub) = prefix_idents path 0 sub sg in
      let env = ref env in
      let pos = ref 0 in
      List.iter2 (fun item path ->
        match item with
          Tsig_value(id, decl) ->
            let decl' = Subst.value_description sub decl in
            c.comp_values <-
              Tbl.add (Ident.name id) (decl', !pos) c.comp_values;
            begin match decl.val_prim with
              None -> incr pos | Some _ -> ()
            end
        | Tsig_type(id, decl) ->
            let decl' = Subst.type_declaration sub decl in
            c.comp_types <-
              Tbl.add (Ident.name id) (decl', nopos) c.comp_types;
            List.iter
              (fun (name, descr) ->
                c.comp_constrs <- Tbl.add name (descr, nopos) c.comp_constrs)
              (constructors_of_type path decl');
            List.iter
              (fun (name, descr) ->
                c.comp_labels <- Tbl.add name (descr, nopos) c.comp_labels)
              (labels_of_type path decl')
        | Tsig_exception(id, decl) ->
            let decl' = Subst.exception_declaration sub decl in
            let cstr = Datarepr.exception_descr path decl' in
            c.comp_constrs <-
              Tbl.add (Ident.name id) (cstr, !pos) c.comp_constrs;
            incr pos
        | Tsig_module(id, mty) ->
            let mty' = Subst.modtype sub mty in
            c.comp_modules <-
              Tbl.add (Ident.name id) (mty', !pos) c.comp_modules;
            let comps = components_of_module !env sub path mty in
            c.comp_components <-
              Tbl.add (Ident.name id) (comps, !pos) c.comp_components;
            env := store_components id path comps !env;
            incr pos
        )
        sg pl;
    Structure_comps c
  | Tmty_ident p ->
       Structure_comps {
         comp_values = Tbl.empty; comp_constrs = Tbl.empty;
          comp_labels = Tbl.empty; comp_types = Tbl.empty;
          comp_modules = Tbl.empty;
          comp_components = Tbl.empty }
@

<<function [[Env.scrape_modtype]]>>=
(* Scrape a module type *)

let rec scrape_modtype mty env =
  match mty with
    Tmty_ident path ->
      failwith "Env.scrape_modtype:TODO"
(*
      begin match find_modtype path env with
          Tmodtype_manifest mty -> scrape_modtype mty env
        | Tmodtype_abstract -> mty
      end
*)
  | _ -> mty
@
% dead?


\subsubsection{By [[Ident]]}
% (* Insertion by identifier *)

% why need that too? not enough by Ident and Path?

<<signature [[Env.add_value]]>>=
val add_value: Ident.t -> value_description -> t -> t
@
<<signature [[Env.add_type]]>>=
val add_type: Ident.t -> type_declaration -> t -> t
@
<<signature [[Env.add_module]]>>=
val add_module: Ident.t -> module_type -> t -> t
@
% rename add_module_type?


<<function [[Env.add_value]]>>=
let add_value id desc env =
  store_value id (Pident id) desc env
@
<<function [[Env.add_type]]>>=
and add_type id info env =
  store_type id (Pident id) info env
@
<<function [[Env.add_module]]>>=
and add_module id mty env =
  store_module id (Pident id) mty env
@


\subsubsection{By name}
% (* Insertion by name *)

% why need that too? not enough by Ident and Path?


% Typecore.type_exp (case For, which introduces a local) -> <>
<<signature [[Env.enter_value]]>>=
val enter_value: string -> value_description -> t -> Ident.t * t
@
<<signature [[Env.enter_type]]>>=
val enter_type: string -> type_declaration -> t -> Ident.t * t
@
<<signature [[Env.enter_module]]>>=
val enter_module: string -> module_type -> t -> Ident.t * t
@


<<function [[Env.enter]]>>=
(* Insertion of bindings by name *)

let enter store_fun name data env =
  let id = Ident.create name in 
  (id, store_fun id (Pident id) data env)
@
% ???

<<functions [[Env.enter_xxx]]>>=
let enter_value     = enter store_value
and enter_type      = enter store_type
and enter_module    = enter store_module
@


\subsection{Accessing the environment}

\subsubsection{By [[Longident]]}

% this is used as we process the AST. The AST contains
% Longident, and when we see Foo.x, we need
% to lookup Foo and then its x component. 
% Foo could be a module in the file, or a "persistent" external
% module. In any case we want to return the resolved path of
% this entity (e.g. Foo.x or Current.Foo.x)

% Typecore.type_exp -> <>, when typecheck Pexp_ident, very important!
<<signature [[Env.lookup_value]]>>=
val lookup_value: Longident.t -> t -> Path.t * Types.value_description
@
% Typetexp.transl_simple_type -> <>, when typecheck a Ptyp_constr
<<signature [[Env.lookup_type]]>>=
val lookup_type: Longident.t -> t -> Path.t * Types.type_declaration
@


<<function [[Env.lookup_value]]>>=
let lookup_value =
  lookup (fun env -> env.values) (fun sc -> sc.comp_values)
@
<<function [[Env.lookup_type]]>>=
and lookup_type =
  lookup (fun env -> env.types) (fun sc -> sc.comp_types)
@


<<function [[Env.lookup]]>>=
let lookup proj1 proj2 lid env =
  match lid with
    Lident s ->
      Ident.find_name s (proj1 env)
  | Ldot(l, s) ->
      (match lookup_module_descr l env with
       (p, Structure_comps c) ->
        let (data, pos) = Tbl.find s (proj2 c) in
           (Pdot(p, s, pos), data)
      )
@
% will see lookup_module_descr later




% does not return a Path.t here
<<signature [[Env.lookup_constructor]]>>=
val lookup_constructor: Longident.t -> t -> Types.constructor_description
@
<<signature [[Env.lookup_label]]>>=
val lookup_label: Longident.t -> t -> Types.label_description
@

<<function [[Env.lookup_constructor]]>>=
and lookup_constructor =
  lookup_simple (fun env -> env.constrs) (fun sc -> sc.comp_constrs)
@
<<function [[Env.lookup_label]]>>=
and lookup_label =
  lookup_simple (fun env -> env.labels) (fun sc -> sc.comp_labels)
@

<<function [[Env.lookup_simple]]>>=
let lookup_simple proj1 proj2 lid env =
  match lid with
    Lident s ->
      Ident.find_name s (proj1 env)
  | Ldot(l, s) ->
      (match lookup_module_descr l env with
       (p, Structure_comps c) ->
      let (data, pos) = Tbl.find s (proj2 c) in
      data
      )
@
% diff with lookup? return just data, not Pdot ...
% (why? why no need path for constr and label?)



% used? for functors, but now?
<<signature [[Env.lookup_module]]>>=
val lookup_module: Longident.t -> t -> Path.t * Types.module_type
@
% rename lookup_module_type?

<<function [[Env.lookup_module]]>>=
and lookup_module lid env =
  match lid with
    Lident s ->
      begin try
        Ident.find_name s env.modules
      with Not_found ->
        (Pident(Ident.create_persistent s), 
         Tmty_signature(find_pers_struct s).ps_sig)
      end
  | Ldot(l, s) ->
      let (p, descr) = lookup_module_descr l env in
      begin match descr with
       Structure_comps c ->
          let (data, pos) = Tbl.find s c.comp_modules in
          (Pdot(p, s, pos), data)
      end
@

\subsubsection{By [[Path]]}
% why need that? it's once the naming has been done?

% used when?
<<signature [[Env.find_value]]>>=
val find_value: Path.t -> t -> Types.value_description
@
<<signature [[Env.find_type]]>>=
val find_type: Path.t -> t -> Types.type_declaration
@

<<function [[Env.find]]>>=
let find proj1 proj2 path env =
  match path with
    Pident id ->
      let (_p, data) = Ident.find_same id (proj1 env) in
      data
  | Pdot(p, s, pos) ->
      (match find_module_descr p env with
        Structure_comps c ->
          let (data, _pos) = Tbl.find s (proj2 c) in 
          data
      )
@
% will see find_module_descr later

<<function [[Env.find_value]]>>=
let find_value = 
  find (fun env -> env.values) (fun sc -> sc.comp_values)
@
<<function [[Env.find_type]]>>=
and find_type = 
  find (fun env -> env.types) (fun sc -> sc.comp_types)
@


\subsection{Substitutions}
% It's for naming.

% when we open_signature, we need to add the toplevel elts
% ident in the env, and associate their type, but their type
% may reference elt from their module too, so we must
% qualify all those things. Enter subst, which is just
% to apply the Ident.t -> Path.t for everything added in the Env.

<<type [[Subst.t]]>>=
type t = 
  { types: Path.t Ident.tbl;
    modules: Path.t Ident.tbl;
    modtypes: module_type Ident.tbl }
@
% for naming. to transform ident to path. 
%todo: But why need modules? because different namespace for types and values?
% which is why there is type_path() and module_path() below
%todo: why for modtypes it's not a Path.t?

<<signature [[Subst.identity]]>>=
val identity: t
@
<<constant [[Subst.identity]]>>=
let identity =
  { types = Ident.empty; modules = Ident.empty; modtypes = Ident.empty }
@

\subsubsection{Populating substitutions}

<<signature [[Subst.add_type]]>>=
val add_type: Ident.t -> Path.t -> t -> t
@
<<signature [[Subst.add_module]]>>=
val add_module: Ident.t -> Path.t -> t -> t
@
<<signature [[Subst.add_modtype]]>>=
val add_modtype: Ident.t -> module_type -> t -> t
@

% boilerplate mostly

<<function [[Subst.add_type]]>>=
let add_type id p s =
  { types = Ident.add id p s.types;
    (* boilerplate, with record *)
    modules = s.modules;
    modtypes = s.modtypes }
@

<<function [[Subst.add_module]]>>=
let add_module id p s =
  { modules = Ident.add id p s.modules;
    (* boilerplate, with record *)
    types = s.types;
    modtypes = s.modtypes }
@

<<function [[Subst.add_modtype]]>>=
let add_modtype id ty s =
  { modtypes = Ident.add id ty s.modtypes;
    (* boilerplate, with record *)
    modules = s.modules;
    types = s.types;
  }
@

\subsubsection{Applying substitutions}

<<signature [[Subst.type_expr]]>>=
val type_expr: t -> type_expr -> type_expr
@
<<signature [[Subst.value_description]]>>=
val value_description: t -> value_description -> value_description
@
<<signature [[Subst.type_declaration]]>>=
val type_declaration: t -> type_declaration -> type_declaration
@
<<signature [[Subst.modtype]]>>=
val modtype: t -> module_type -> module_type
@
<<signature [[Subst.signature]]>>=
val signature: t -> signature -> signature
@



<<function [[Subst.type_expr]]>>=
let rec type_expr s = function
    Tvar{tvar_link = None} as ty -> ty
  | Tvar{tvar_link = Some ty} -> type_expr s ty
  | Tconstr(p, tl) -> Tconstr(type_path s p, List.map (type_expr s) tl)
  (* boilerplate mapper *)
  | Tarrow(t1, t2) -> Tarrow(type_expr s t1, type_expr s t2)
  | Ttuple tl -> Ttuple(List.map (type_expr s) tl)
@
% follow link!
%old:  | Tconstr(p, []) -> Tconstr(type_path s p, [])

<<function [[Subst.type_path]]>>=
let type_path s = function
    Pident id as p ->
      begin try Ident.find_same id s.types with Not_found -> p end
  | Pdot(p, n, pos) ->
      Pdot(module_path s p, n, pos)
@
<<function [[Subst.module_path]]>>=
let rec module_path s = function
    Pident id as p ->
      begin try Ident.find_same id s.modules with Not_found -> p end
  | Pdot(p, n, pos) ->
      Pdot(module_path s p, n, pos)
@

%less: could do modtype_path here, and use it below

% boilerplate
<<function [[Subst.value_description]]>>=
let value_description s descr =
  { val_type = type_expr s descr.val_type;
    val_prim = descr.val_prim }
@

<<function [[Subst.type_declaration]]>>=
let type_declaration s decl =
  { type_params = decl.type_params;
    type_arity = decl.type_arity;
    type_kind =
      begin match decl.type_kind with 
       (* boilerplate mapper *)
        Type_abstract -> Type_abstract
      | Type_variant cstrs ->
          Type_variant(cstrs |> List.map (fun (n, args) -> 
                          (n, List.map (type_expr s) args)))
      | Type_record lbls ->
          Type_record(lbls |> List.map (fun (n, mut, arg) -> 
                          (n, mut, type_expr s arg)))
      end;
    type_manifest =
      begin match decl.type_manifest with
        None -> None
      | Some ty -> Some(type_expr s ty)
      end
  }
@


<<function [[Subst.modtype]]>>=
let rec modtype s = function
    Tmty_ident p as mty ->
      begin match p with
        Pident id ->
          begin try Ident.find_same id s.modtypes with Not_found -> mty end
      | Pdot(p, n, pos) ->
          Tmty_ident(Pdot(module_path s p, n, pos))
      end
  | Tmty_signature sg ->
      Tmty_signature(signature s sg)

and signature s sg = List.map (signature_item s) sg

and signature_item s = function
    Tsig_value(id, d) -> Tsig_value(id, value_description s d)
  | Tsig_type(id, d) -> Tsig_type(id, type_declaration s d)
  | Tsig_exception(id, d) -> Tsig_exception(id, exception_declaration s d)
  | Tsig_module(id, mty) -> Tsig_module(id, modtype s mty)
@


\section{Reading typed [[.cmi]] interface files}

% X.Y.z -> Ldot(Ldot(X, "Y", 0), "z", 42)?

% Env.lookup -> <>
<<function [[Env.lookup_module_descr]]>>=
let rec lookup_module_descr lid env =
  match lid with
    Lident s ->
      begin try
        Ident.find_name s env.components
      with Not_found ->
        (Pident(Ident.create_persistent s), (find_pers_struct s).ps_comps)
      end
  | Ldot(l, s) ->
      let (p, descr) = lookup_module_descr l env in
      (match descr with
       Structure_comps c ->
      let (descr, pos) = Tbl.find s c.comp_components in
          (Pdot(p, s, pos), descr)
      )
@



% Env.find -> <>
<<function [[Env.find_module_descr]]>>=
(* Lookup by identifier *)

let rec find_module_descr path env =
  match path with
    Pident id ->
      begin try
        let (_p, desc) = Ident.find_same id env.components in
        desc
      with Not_found ->
        if Ident.persistent id
        then (find_pers_struct (Ident.name id)).ps_comps
        else raise Not_found
      end
  | Pdot(p, s, pos) ->
      begin match find_module_descr p env with
       Structure_comps c ->
          let (descr, pos) = Tbl.find s c.comp_components in
          descr
      end
@



\subsection{Persistent identifiers}

% toplevel modules e.g. List.map 
% are not in the initial environment. One can
% add them via open, but it's not the only way, one
% can also qualify in which case the signature is loaded.

% toplevel identifiers refering to files are called
% persistent identifiers!

<<signature [[Ident.persistent]]>>=
val persistent: t -> bool
@
<<function [[Ident.persistent]]>>=
let persistent i = 
  (i.stamp = 0)
@
%todo: ugly again, to abuse ints for everything
% why not Local of int | Persistent | Global ... ?
% also sometimes stamp = -1 for some special value again.
% ugly all those int abuse

% ??? -> <>
<<signature [[Ident.create_persistent]]>>=
val create_persistent: string -> t
@
<<function [[Ident.create_persistent]]>>=
let create_persistent s =
  { name = s; stamp = 0; global = true }
@
% why global = true?

\subsection{Persistent structures}

<<type [[Env.pers_struct]]>>=
(* Persistent structure descriptions *)

type pers_struct =
  { ps_name: string;
    ps_sig: signature;
    ps_comps: module_components }
@
% Have module_components in a .cmi? redundant with signature?
% Just a hashed version of ps_sig? 
% No! because for separate compilation we need to know not just the type
%  of an external entity but also possibly its offset, its shape, etc.




% memoization
<<constant [[Env.persistent_structures]]>>=
let persistent_structures =
  (Hashtbl.create 17 : (string, pers_struct) Hashtbl.t)
@
% string is toplevel modname (which should lead to a unique file.cmi)

% opti, memoize
% less: could rewrite with Common.memoize or something?
% Env.find -> Env.find_module_descr -> <>
<<function [[Env.find_pers_struct]]>>=
let find_pers_struct name =
  try
    Hashtbl.find persistent_structures name
  with Not_found ->
    let (ps, crc) =
      read_pers_struct name
        (find_in_path_uncap !load_path (name ^ ".cmi")) in
    Hashtbl.add persistent_structures name ps;
    <<[[Env.find_pers_struct()]] hook when read Name.cmi and its crc>>
    ps
@





<<signature [[Env.read_signature]]>>=
(* Read, save a signature to/from a file *)

val read_signature: string -> string -> Types.signature * Digest.t
        (* Arguments: module name, file name.
           Results: signature, CRC. *)
@
% Compile.implementation | -> <>
<<function [[Env.read_signature]]>>=
(* Read a signature from a file *)

let read_signature modname filename =
  let (ps, crc) = read_pers_struct modname filename in 
  (ps.ps_sig, crc)
@


<<signature [[Env.save_signature]]>>=
val save_signature: signature -> string -> string -> Digest.t
        (* Arguments: signature, module name, file name.
           Result: CRC. *)
@
% Compile.implementation | Compile.interface -> <>
<<function [[Env.save_signature]]>>=
(* Save a signature to a file *)

let save_signature sg modname filename =
  let ps =
    { ps_name = modname;
      ps_sig = sg;
      ps_comps =
        components_of_module empty Subst.identity
            (Pident(Ident.create_persistent modname)) (Tmty_signature sg) } 
  in
  let oc = open_out filename in
  output_string oc cmi_magic_number;
  output_value oc ps;
  flush oc;
  let crc = Digest.file filename in
  Digest.output oc crc;
  close_out oc;
  crc
@

\subsection{[[Env.read_pers_struct()]]}

% find_pers_struct -> <>
<<function [[Env.read_pers_struct]]>>=
let read_pers_struct modname filename =
  let ic = open_in filename in
  try
    let buffer = Bytes.create (String.length cmi_magic_number) in
    really_input ic buffer 0 (String.length cmi_magic_number);
    if Bytes.to_string buffer <> cmi_magic_number then begin
      close_in ic;
      raise(Error(Not_an_interface filename))
    end;

    let ps = (input_value ic : pers_struct) in
    let crc = Digest.input ic in
    close_in ic;

    if ps.ps_name <> modname then
      raise(Error(Illegal_renaming(ps.ps_name, filename)));
    (ps, crc)
  with End_of_file | Failure _ ->
    close_in ic;
    raise(Error(Corrupted_interface(filename)))
@
% marshall! ocaml power! factorize lots of code using Marshall.
% no read reader/writer like in 5a/5c/5l

<<signature [[Config.cmi_magic_number]]>>=
val cmi_magic_number: string
        (* Magic number for compiled interface files *)
@






\section{Type operations}


\subsection{Unification}

% core to type inference mechanism and type checking,
% unification! if have 'a -> 'a can we pass an int? yes!
%  (and we should also know now that 'a should be substituted to
%   an int everywhere it occurs)
% if have bool -> int, can we pass an int? no!
% unify() will answer those questions.

<<signature [[Ctype.unify]]>>=
val unify: Env.t -> type_expr -> type_expr -> unit
        (* Unify the two types given. Raise [Unify] if not possible. *)
@


<<exception [[Ctype.Unify]]>>=
exception Unify
@
%new: exception Unify of (type_expr * type_expr) list



<<function [[Ctype.unify]]>>=
let rec unify env t1 t2 =
  if t1 == t2 
  then () 
  else begin
    let t1 = repr t1 in
    let t2 = repr t2 in
    if t1 == t2 
    then () 
    else begin
      match (t1, t2) with
        (Tvar v, _) ->
          occur v t2; 
          v.tvar_link <- Some t2
      | (_, Tvar v) ->
          occur v t1; 
          v.tvar_link <- Some t1
      | (Tarrow(t1, u1), Tarrow(t2, u2)) ->
          unify env t1 t2; unify env u1 u2
      | (Ttuple tl1, Ttuple tl2) ->
          unify_list env tl1 tl2
      | (Tconstr(p1, tl1), Tconstr(p2, tl2)) ->
          if Path.same p1 p2 
          then unify_list env tl1 tl2
          else begin
            <<[[Ctype.unify()]] if p1 or p2 are abbreviation type paths>>
                raise Unify
          end
      <<[[Ctype.unify()]] match t1 t2 other cases>>
      | (_, _) ->
          raise Unify
    end
  end

and unify_list env tl1 tl2 =
  match (tl1, tl2) with
    ([], []) -> ()
  | (t1::r1, t2::r2) -> 
      unify env t1 t2; 
      unify_list env r1 r2
  | (_, _) -> raise Unify
@


<<function [[Ctype.occur]]>>=
let rec occur tvar ty =
  match repr ty with
    Tvar v ->
      if v == tvar 
      then raise Unify; (* occur check fail *)
      <<[[Ctype.occur()]] in Tvar case, adjust levels if needed>>
  (* boilerplate visitor *)
  | Tarrow(t1, t2) ->
      occur tvar t1; occur tvar t2
  | Ttuple tl ->
      List.iter (occur tvar) tl
  | Tconstr(_p, tl) ->
      List.iter (occur tvar) tl
@
% ==, physical equality
%old: but useless I think
%  | Tconstr(p, []) ->
%      ()



<<signature [[Path.same]]>>=
val same: t -> t -> bool
@
<<function [[Path.same]]>>=
let rec same p1 p2 =
  match (p1, p2) with
    (Pident id1, Pident id2) -> Ident.same id1 id2
  | (Pdot(p1, s1, _pos1), Pdot(p2, s2, _pos2)) -> s1 = s2 && same p1 p2
  | (_, _) -> false
@

<<signature [[Ident.same]]>>=
val same: t -> t -> bool
        (* Compare identifiers by binding location.
           Two identifiers are the same either if they are both
           non-persistent and have been created by the same call to
           [new], or if they are both persistent and have the same
           name. *)
@
<<function [[Ident.same]]>>=
let same i1 i2 = 
  i1 = i2
@
%  (* Possibly more efficient version (with a real compiler, at least):
%       if i1.stamp <> 0
%       then i1.stamp = i2.stamp
%       else i2.stamp = 0 & i1.name = i2.name *)


\subsection{Canonical types, links}

%todo? put earlier? in header of the chapter?
%todo? the code of the dumper helps to understand things?

<<signature [[Ctype.repr]]>>=
val repr: type_expr -> type_expr
        (* Return the canonical representative of a type. *)
@
% actually it just does one level no?

<<function [[Ctype.repr]]>>=
let rec repr = function
    Tvar({tvar_link = Some ty} as v) ->
      let r = repr ty in
      if r != ty 
      then v.tvar_link <- Some r;
      r
  | t -> t
@
% stores the end of the chain each time when can.
% so further calls to repr with the same var will go faster.

% so must take care to use Ctype.repr each time you want
% to pattern match on a type! to follow the tvar if
% it has been unified already!

\subsection{Generalization}
% will see later

\subsection{Instantiation}
% type scheme? see later too?

\section{Typing expressions}
% and patterns?

% string -> Ident.t -> Path.t
% Longident.t -> Path.t
% Parsetree.xxx -> Types.xxx or Typedtree.xxx, P -> T

<<signature [[Typecore.type_expression]]>>=
val type_expression:
        Env.t -> Parsetree.expression -> Typedtree.expression
@
%less: rename type_toplevel_expression

% for toplevel one! those are specials!
<<function [[Typecore.type_expression]]>>=
(* Typing of toplevel expressions *)

let type_expression env sexp =
  <<[[Typecore.type_expression()]] before [[type_exp]]>>
  let exp = type_exp env sexp in
  <<[[Typecore.type_expression()]] after [[type_exp]]>>
  <<[[Typecore.type_expression()]] after [[type_exp]], generalize or not>>

  exp
@

<<function [[Typecore.type_exp]]>>=
let rec type_exp env sexp =
  match sexp.pexp_desc with
  <<[[Typecore.type_exp()]] match cases>>
@
% not just toplevel


<<signature [[Ctype.newvar]]>>=
val newvar: unit -> type_expr
        (* Return a fresh variable *)
@
<<function [[Ctype.newvar]]>>=
let newvar () =
  Tvar { tvar_link = None; 
         <<[[Ctype.newvar()]] set other fields>>
       }
@
% this allocates a new cell with a new mutable field tvar_link!



\subsection{Constants}

<<[[Typecore.type_exp()]] match cases>>=
| Pexp_constant cst ->
    { exp_desc = Texp_constant cst;
      exp_loc = sexp.pexp_loc;
      exp_type = type_constant cst }
@

% P -> T
% saw type_constant() before

\subsection{Constructors}

<<[[Typecore.type_exp()]] match cases>>=
| Pexp_construct(lid, sarg) ->
    let constr =
      try
        Env.lookup_constructor lid env
      with Not_found ->
        raise(Error(sexp.pexp_loc, Unbound_constructor lid)) 
    in
    let sargs =
      match sarg with
        None -> []
      | Some {pexp_desc = Pexp_tuple sel} when constr.cstr_arity > 1 -> sel
      | Some se -> [se] 
    in
    <<[[Typecore.type_exp()]] constructor case, sanity check>>

    let (ty_args, ty_res) = instance_constructor constr in
    let args = List.map2 (type_expect env) sargs ty_args in
    { exp_desc = Texp_construct(constr, args);
      exp_loc = sexp.pexp_loc;
      exp_type = ty_res }
@
% will talk about instance_constructor later!

%note: list has been desugard in constructor already.

<<[[Typecore.type_exp()]] constructor case, sanity check>>=
if List.length sargs <> constr.cstr_arity 
then
  raise(Error(sexp.pexp_loc, Constructor_arity_mismatch(lid,
                                 constr.cstr_arity, List.length sargs)));
@



<<function [[Typecode.type_expect]]>>=
(* Typing of an expression with an expected type.
   Some constructs are treated specially to provide better error messages. *)

and type_expect env sexp ty_expected =
  match sexp.pexp_desc with
  <<[[Typecode.type_expect()]] match cases>>
  | Pexp_function caselist ->
      let (ty_arg, ty_res) =
        try filter_arrow env ty_expected with Unify ->
          raise(Error(sexp.pexp_loc, Too_many_arguments))
      in
      let cases =
        List.map
          (fun (spat, sexp) ->
             let (pat, ext_env) = type_pattern env spat in
             unify_pat env pat ty_arg;
             let exp = type_expect ext_env sexp ty_res in
             (pat, exp))
          caselist
      in
      Parmatch.check_unused cases;
      Parmatch.check_partial sexp.pexp_loc cases;
      { exp_desc = Texp_function cases;
        exp_loc = sexp.pexp_loc;
        exp_type = Tarrow(ty_arg, ty_res);
      }
  | _ ->
      let exp = type_exp env sexp in
      unify_exp env exp ty_expected;
      exp
@


<<function [[Typecore.unify_exp]]>>=
(* Typing of expressions *)

let unify_exp env exp expected_ty =
  try
    unify env exp.exp_type expected_ty
  with Unify ->
    raise(Error(exp.exp_loc, Expr_type_clash(exp.exp_type, expected_ty)))
@
% better error message than just Unify failure




\subsection{Records}

<<[[Typecore.type_exp()]] match cases>>=
| Pexp_record lid_sexp_list ->
    let ty = newvar() in
    let num_fields = ref 0 in
    let type_label_exp (lid, sarg) =
      let label =
        try
          Env.lookup_label lid env
        with Not_found ->
          raise(Error(sexp.pexp_loc, Unbound_label lid)) 
      in
      let (ty_arg, ty_res) = instance_label label in
      (try
        unify env ty_res ty
      with Unify ->
        raise(Error(sexp.pexp_loc, Label_mismatch(lid, ty_res, ty)))
      );
      let arg = type_expect env sarg ty_arg in
      num_fields := Array.length label.lbl_all;
      (label, arg) 
    in
    let lbl_exp_list = List.map type_label_exp lid_sexp_list in
    <<[[Typecore.type_exp()]] record case, sanity check duplicates and missing>>
    { exp_desc = Texp_record lbl_exp_list;
      exp_loc = sexp.pexp_loc;
      exp_type = ty }
@
% again will talk about instance_label later


<<[[Typecore.type_exp()]] record case, sanity check duplicates and missing>>=
let rec check_duplicates = function
  [] -> ()
| (lid, _sarg) :: remainder ->
    if List.mem_assoc lid remainder
    then raise(Error(sexp.pexp_loc, Label_multiply_defined lid))
    else check_duplicates remainder 
in
check_duplicates lid_sexp_list;

if List.length lid_sexp_list <> !num_fields 
then raise(Error(sexp.pexp_loc, Label_missing));
@
%todo: hmm would be nice to explain which one are missing ...

<<[[Typecore.type_exp()]] match cases>>=
| Pexp_field(sarg, lid) ->
    let arg = type_exp env sarg in
    let label =
      try
        Env.lookup_label lid env
      with Not_found ->
        raise(Error(sexp.pexp_loc, Unbound_label lid)) 
    in
    let (ty_arg, ty_res) = instance_label label in
    unify_exp env arg ty_res;
    { exp_desc = Texp_field(arg, label);
      exp_loc = sexp.pexp_loc;
      exp_type = ty_arg }
@

<<[[Typecore.type_exp()]] match cases>>=
| Pexp_setfield(srecord, lid, snewval) ->
    let record = type_exp env srecord in
    let label =
      try
        Env.lookup_label lid env
      with Not_found ->
        raise(Error(sexp.pexp_loc, Unbound_label lid)) 
    in
    if label.lbl_mut = Immutable 
    then raise(Error(sexp.pexp_loc, Label_not_mutable lid));
    let (ty_arg, ty_res) = instance_label label in
    unify_exp env record ty_res;
    let newval = type_expect env snewval ty_arg in
    { exp_desc = Texp_setfield(record, label, newval);
      exp_loc = sexp.pexp_loc;
      exp_type = Predef.type_unit }
@


\subsection{Tuples}

<<[[Typecore.type_exp()]] match cases>>=
| Pexp_tuple sexpl ->
    let expl = List.map (type_exp env) sexpl in
    { exp_desc = Texp_tuple expl;
      exp_loc = sexp.pexp_loc;
      exp_type = Ttuple(List.map (fun exp -> exp.exp_type) expl) }
@

\subsection{Statements}

<<[[Typecore.type_exp()]] match cases>>=
| Pexp_sequence(sexp1, sexp2) ->
    let exp1 = type_statement env sexp1 in
    let exp2 = type_exp env sexp2 in
    { exp_desc = Texp_sequence(exp1, exp2);
      exp_loc = sexp.pexp_loc;
      exp_type = exp2.exp_type }
@


<<[[Typecode.type_expect()]] match cases>>=
| Pexp_sequence(sexp1, sexp2) ->
    let exp1 = type_statement env sexp1 in
    let exp2 = type_expect env sexp2 ty_expected in
    { exp_desc = Texp_sequence(exp1, exp2);
      exp_loc = sexp.pexp_loc;
      exp_type = exp2.exp_type }
@
% how this is better than the default case of type_Expect
% because it distributes type_expect! so the unify_exp 
% will happen for sexp2 and the error message il be clearer


<<function [[Typecore.type_statement]]>>=
(* Typing of statements (expressions whose values are discarded) *)

and type_statement env sexp =
    let exp = type_exp env sexp in
    match Ctype.repr exp.exp_type with
      Tarrow(_, _) ->
        Location.print_warning sexp.pexp_loc
          "this function application is partial,\n\
           maybe some arguments are missing.";
        exp
    | _ -> exp
@
% nice check!
%less: could also check that the type is unit!


<<[[Typecore.type_exp()]] match cases>>=
| Pexp_ifthenelse(scond, sifso, sifnot) ->
    let cond = type_expect env scond Predef.type_bool in
    (match sifnot with
    | None ->
        let ifso = type_expect env sifso Predef.type_unit in
        { exp_desc = Texp_ifthenelse(cond, ifso, None);
          exp_loc = sexp.pexp_loc;
          exp_type = Predef.type_unit }
    | Some sexp ->
        let ifso = type_exp env sifso in
        let ifnot = type_expect env sexp ifso.exp_type in
        { exp_desc = Texp_ifthenelse(cond, ifso, Some ifnot);
          exp_loc = sexp.pexp_loc;
          exp_type = ifso.exp_type }
    )
@


<<[[Typecore.type_exp()]] match cases>>=
| Pexp_while(scond, sbody) ->
    let cond = type_expect env scond Predef.type_bool in
    let body = type_statement env sbody in
    { exp_desc = Texp_while(cond, body);
      exp_loc = sexp.pexp_loc;
      exp_type = Predef.type_unit }
@

<<[[Typecore.type_exp()]] match cases>>=
| Pexp_for(param, slow, shigh, dir, sbody) ->
    let low = type_expect env slow Predef.type_int in
    let high = type_expect env shigh Predef.type_int in
    let (id, new_env) =
      Env.enter_value param {val_type = Predef.type_int;
                              val_prim = None} env 
    in
    let body = type_statement new_env sbody in
    { exp_desc = Texp_for(id, low, high, dir, body);
      exp_loc = sexp.pexp_loc;
      exp_type = Predef.type_unit }
@




\subsection{Patterns}

<<[[Typecore.type_exp()]] match cases>>=
| Pexp_match(sarg, caselist) ->
    let arg = type_exp env sarg in
    let ty_res = newvar() in
    let cases = type_cases env arg.exp_type ty_res caselist in
    <<[[Typecore.type_exp()]] match case, sanity check unused or partial>>
    { exp_desc = Texp_match(arg, cases);
      exp_loc = sexp.pexp_loc;
      exp_type = ty_res }
@

<<function [[Typecore.type_cases]]>>=
(* Typing of match cases *)

and type_cases env ty_arg ty_res caselist =
  List.map (fun (spat, sexp) ->
      let (pat, ext_env) = type_pattern env spat in
      unify_pat env pat ty_arg;
      let exp = type_expect ext_env sexp ty_res in
      (pat, exp)
  ) caselist
@

<<[[Typecore.type_exp()]] match case, sanity check unused or partial>>=
Parmatch.check_unused cases;
Parmatch.check_partial sexp.pexp_loc cases;
@
% see in next chapter


<<[[Typecore.type_exp()]] match cases>>=
| Pexp_when(scond, sbody) ->
    let cond = type_expect env scond Predef.type_bool in
    let body = type_exp env sbody in
    { exp_desc = Texp_when(cond, body);
      exp_loc = sexp.pexp_loc;
      exp_type = body.exp_type }
@


\subsection{Functions}
% better to be put after pattern case as function is taking
% some patterns

<<[[Typecore.type_exp()]] match cases>>=
| Pexp_function caselist ->
    let ty_arg = newvar() in
    let ty_res = newvar() in
    let cases = type_cases env ty_arg ty_res caselist in
    <<[[Typecore.type_exp()]] match case, sanity check unused or partial>>
    { exp_desc = Texp_function cases;
      exp_loc = sexp.pexp_loc;
      exp_type = Tarrow(ty_arg, ty_res) }
@

<<[[Typecore.type_exp()]] match cases>>=
| Pexp_apply(sfunct, sargs) ->
    let funct = type_exp env sfunct in

    let rec type_args ty_fun = function
    | [] ->
        ([], ty_fun)
    | sarg1 :: sargl ->
        let (ty1, ty2) =
          try
            filter_arrow env ty_fun
          with Unify ->
            raise(Error(sfunct.pexp_loc,
                        Apply_non_function funct.exp_type)) 
        in
        let arg1 = type_expect env sarg1 ty1 in
        let (argl, ty_res) = type_args ty2 sargl in
        (arg1 :: argl, ty_res) 
    in

    let (args, ty_res) = type_args funct.exp_type sargs in
    { exp_desc = Texp_apply(funct, args);
      exp_loc = sexp.pexp_loc;
      exp_type = ty_res }
@

<<signature [[Ctype.filter_arrow]]>>=
val filter_arrow: Env.t -> type_expr -> type_expr * type_expr
        (* A special case of unification (with 'a -> 'b). *)
@

% why not using newvar?
<<function [[Ctype.filter_arrow]]>>=
let rec filter_arrow env t =
  match repr t with
    Tvar v ->
      let t1 = Tvar { tvar_level = v.tvar_level; tvar_link = None } in
      let t2 = Tvar { tvar_level = v.tvar_level; tvar_link = None } in
      v.tvar_link <- Some(Tarrow(t1, t2));
      (t1, t2)
  | Tarrow(t1, t2) ->
      (t1, t2)
  <<[[Ctype.filter_arrow()]] other cases>>
  | _ ->
      raise Unify
@

\subsection{Casts}

<<[[Typecore.type_exp()]] match cases>>=
| Pexp_constraint(sarg, sty) ->
    let ty = Typetexp.transl_simple_type env false sty in
    let arg = type_expect env sarg ty in
    { exp_desc = arg.exp_desc;
      exp_loc = arg.exp_loc;
      exp_type = ty }
@

% link with next section where type types ...

<<[[Typetexp.transl_simple_type()]] when not fixed and [[Not_found]]>>=
else begin
  let v = new_global_var() in
  type_variables := Tbl.add name v !type_variables;
  v
end
@

\section{Typing [[let]]}

% Def

% complex, new_env again! like for For, because introduce new
% entities
<<[[Typecore.type_exp()]] match cases>>=
| Pexp_let(rec_flag, spat_sexp_list, sbody) ->
    let (pat_exp_list, new_env) = type_let env rec_flag spat_sexp_list in
    let body = type_exp new_env sbody in
    { exp_desc = Texp_let(rec_flag, pat_exp_list, body);
      exp_loc = sexp.pexp_loc;
      exp_type = body.exp_type }
@

<<[[Typecode.type_expect()]] match cases>>=
| Pexp_let(rec_flag, spat_sexp_list, sbody) ->
    let (pat_exp_list, new_env) = type_let env rec_flag spat_sexp_list in
    let body = type_expect new_env sbody ty_expected in
    { exp_desc = Texp_let(rec_flag, pat_exp_list, body);
      exp_loc = sexp.pexp_loc;
      exp_type = body.exp_type }
@
% how this is better than the default case of type_Expect?
% again because distribute the expected type error message!
% instead of having the error at the let level, we will have it
% at the body level


% let x = e and y = f in ... [x=2; y=f]
% where x can actually be a pattern and so be like let 1 = 1
% so the type of the pattern must match the type of the expression
<<function [[Typecode.type_let]]>>=
(* Typing of let bindings *)

and type_let env rec_flag spat_sexp_list =

  <<[[Typecode.type_let()]] before typing>>
  let (pat_list, new_env) =
    spat_sexp_list 
    |> List.map (fun (spat, _sexp) -> spat)
    |> type_pattern_list env 
  in
  let exp_env =
    match rec_flag with 
    | Nonrecursive -> env 
    | Recursive -> new_env 
  in
  let exp_list =
    List.map2
      (fun (_spat, sexp) pat -> type_expect exp_env sexp pat.pat_type)
      spat_sexp_list pat_list in
  <<[[Typecode.type_let()]] sanity check partial patterns>>
  <<[[Typecode.type_let()]] after typing>>
  <<[[Typecode.type_let()]] after typing, generalize or not>>

  (List.combine pat_list exp_list, new_env)
@

<<[[Typecode.type_let()]] sanity check partial patterns>>=
List.iter2
  (fun pat exp -> Parmatch.check_partial pat.pat_loc [pat, exp])
  pat_list exp_list;
@

% Use

<<[[Typecore.type_exp()]] match cases>>=
|  Pexp_ident lid ->
    begin try
      let (path, desc) = Env.lookup_value lid env in
      { exp_desc = Texp_ident(path, desc);
        exp_loc = sexp.pexp_loc;
        exp_type = instance desc.val_type }
    with Not_found ->
      raise(Error(sexp.pexp_loc, Unbound_value lid))
    end
@
% instance!
% have seen already instance_constructor, instance_label
% will explain a bit more below




\subsection{Generalizations and type schemas}

% see http://okmij.org/ftp/ML/generalization.html ! the first part.

% we want this code:
%  let f x = x in 
%  f 1, f "foo"
% to work, but if we do the naive type inference,
% f will have first type 'a -> 'a, but at the first call
% to f 1, then 'a will be bound to an int, and we then will not
% be able to apply it to foo. 
% In the same way entities defined in a module as polymorphic should
% be used in different context with different types!

% To have polymorphism, we need each time we lookup for 'f' in the environment
% to generate a fresh 'a -> 'a, and so to make the original type 'a -> 'a
% a type "schema" that will generate fresh instances.
% we want forall a. 'a -> 'a.
% hence the call to instance instance decl.val_type for
% the Ident case and the call to generalize below.

% after typing, and also after end_def()
<<[[Typecode.type_let()]] after typing, generalize or not>>=
<<[[Typecode.type_let()]] generalization criteria action>>
exp_list |> List.iter (fun exp -> 
  generalize exp.exp_type);
@

% and after end_def() too
<<[[Typecore.type_expression()]] after [[type_exp]], generalize or not>>=
if 
  <<[[Typecore.type_expression()]] generalization criteria>>
then generalize exp.exp_type;
@


<<signature [[Ctype.generalize]]>>=
val generalize: type_expr -> unit
        (* Generalize in-place the given type *)
@


<<function [[Ctype.generalize]]>>=
(* Type generalization *)

let rec generalize ty =
  match repr ty with
    Tvar v ->
      if 
        <<[[Ctype.generalize()]] generalization criteria>>
      then v.tvar_level <- generic_level
  (* boilerplate visitor *)
  | Tarrow(t1, t2) ->
      generalize t1; generalize t2
  | Ttuple tl ->
      List.iter generalize tl
  | Tconstr(_p, tl) ->
      List.iter generalize tl
@
% why special [] case? List.iter will work ...
%old:  | Tconstr(p, []) ->
%      ()


<<constant [[Ctype.generic_level]]>>=
let generic_level = (-1)
@
% kinda forall, it's for type schema
% a special mark in the type
%todo: could have instead a tvar_is_type_schema? instead
% of abusing tval_level for everything no? a bit
% ugly to abuse int like that
% or use is_quantified_tvar? or like in oleg's article have
% Tvar and QVar


%"The current nesting level of lets" that's the comment in caml light
<<constant [[Ctype.current_level]]>>=
let current_level = ref 0
@

<<[[Types.type_variable]] other fields>>=
mutable tvar_level: int;
@

<<[[Ctype.newvar()]] set other fields>>=
tvar_level = !current_level;  
@




<<[[Predef.build_initial_env()]] set other fields in local newvar>>=
tvar_level = -1 (*generic_level*); 
@
% builtin types like 'a list, are of course generic! want generalization
% for them




\subsection{Instanciations}

% now that have the special generic_level mark,
% when lookup for type of ident in env, can
% create a fresh copy for all universally quantified
% type variables!

<<signature [[Ctype.instance]]>>=
val instance: type_expr -> type_expr
        (* Take an instance of a type scheme *)
@

<<signature [[Ctype.instance_constructor]]>>=
val instance_constructor: constructor_description -> type_expr list * type_expr
        (* Same, for a constructor *)
@

<<signature [[Ctype.instance_label]]>>=
val instance_label: label_description -> type_expr * type_expr
        (* Same, for a label *)
@



<<function [[Ctype.instance]]>>=
let instance sch =
  inst_subst := [];
  let ty = copy sch in
  inst_subst := [];
  ty
@

<<constant [[Ctype.inst_subst]]>>=
(* Taking instances of type schemes *)

let inst_subst = ref ([] : (type_expr * type_expr) list)
@


<<function [[Ctype.copy]]>>=
let rec copy ty =
  match repr ty with
    Tvar v as t ->
      (* generic mark, let's create a new var then *)
      if v.tvar_level = generic_level then begin
        try
          List.assq t !inst_subst
        with Not_found ->
          let t' = newvar() in
          inst_subst := (t, t') :: !inst_subst;
          t'
      end else t
  (* boilerplate mapper *)
  | Tarrow(t1, t2) ->
      Tarrow(copy t1, copy t2)
  | Ttuple tl ->
      Ttuple(List.map copy tl)
  | Tconstr(p, tl) ->
      Tconstr(p, List.map copy tl)
@
% newvar() call! fresh new var!
%old:
%  | Tconstr(p, []) as t ->
%      t




<<function [[Ctype.instance_constructor]]>>=
let instance_constructor cstr =
  inst_subst := [];
  let ty_res = copy cstr.cstr_res in
  let ty_args = List.map copy cstr.cstr_args in
  inst_subst := [];
  (ty_args, ty_res)
@

<<function [[Ctype.instance_label]]>>=
let instance_label lbl =
  inst_subst := [];
  let ty_res = copy lbl.lbl_res in
  let ty_arg = copy lbl.lbl_arg in
  inst_subst := [];
  (ty_arg, ty_res)
@


\subsection{Generalization criterias}
% criterias!

% complicated,
% again see http://okmij.org/ftp/ML/generalization.html

% fun x -> let y = x in y
% don't want to generalize, don't want infer 'a -> 'b, because hole
% in the type system! someone writes this function and
% no guarantee! (ok Obj.magic does that but we want to avoid it actually)

% so regular test is to look if type variables in x are
% free in the environment, but takes time to do so.
% enter type levels tricks.


\subsubsection{Type levels}


<<[[Ctype.generalize()]] generalization criteria>>=
v.tvar_level > !current_level
@
% means this type variable has been created when processing
% the let, not before in the context of the let

%"The current nesting level of lets" that's the comment in caml light
%<<constant Ctype.current_level>>=
%let current_level = ref 0
%@

<<[[Typecode.type_let()]] before typing>>=
begin_def();
@

<<[[Typecode.type_let()]] after typing>>=
end_def();
@

<<signature [[Ctype.begin_def]]>>=
val begin_def: unit -> unit
        (* Raise the variable level by one at the beginning of a definition. *)
@
<<function [[Ctype.begin_def]]>>=
let begin_def () = 
  incr current_level
@

<<signature [[Ctype.end_def]]>>=
val end_def: unit -> unit
        (* Lower the variable level by one at the end of a definition *)
@
<<function [[Ctype.end_def]]>>=
let end_def () = 
  decr current_level
@
% why need that? quite tricky
% see http://okmij.org/ftp/ML/generalization.html !



<<[[Typecore.type_expression()]] before [[type_exp]]>>=
<<[[Typecore.type_expression()]] before [[begin_def]], reset>>
begin_def();
@

<<[[Typecore.type_expression()]] after [[type_exp]]>>=
end_def();
@



<<[[Ctype.occur()]] in Tvar case, adjust levels if needed>>=
if v.tvar_level > tvar.tvar_level 
then v.tvar_level <- tvar.tvar_level
@
% when test if v occurs in t, it's because we want to unify
% v to t, and so v should get the minimum level of any
% type variables in t




\subsubsection{[[reset_xxx()]]}

% note that type_expressions is for toplevel expressions
<<[[Typecore.type_expression()]] before [[begin_def]], reset>>=
reset_def();
Typetexp.reset_type_variables();
@
% need reset_def? should be fine no without?

<<signature [[Ctype.reset_def]]>>=
val reset_def: unit -> unit
        (* Reset (to 0) the variable level *)
@
<<function [[Ctype.reset_def]]>>=
let reset_def () = 
  current_level := 0
@



<<signature [[Typecore.type_binding]]>>=
val type_binding:
        Env.t -> rec_flag ->
          (Parsetree.pattern * Parsetree.expression) list -> 
            (Typedtree.pattern * Typedtree.expression) list * Env.t
@

<<function [[Typecore.type_binding]]>>=
(* Typing of toplevel bindings *)

let type_binding env rec_flag spat_sexp_list =
  reset_def();
  Typetexp.reset_type_variables();

  type_let env rec_flag spat_sexp_list
@


\subsubsection{Value restriction, [[is_nonexpansive()]]}

% again see http://okmij.org/ftp/ML/generalization.html !
% too subtle to explain here. Type theory! ensure
% soundness in the presence of side effects.
% see thesis of Leroy?

<<[[Typecore.type_expression()]] generalization criteria>>=
is_nonexpansive exp 
@

% mv later? with the _a advanced typing issue?

<<function [[Typecore.is_nonexpansive]]>>=
(* Generalization criterion for expressions *)

let rec is_nonexpansive exp =
  match exp.exp_desc with
  | Texp_record lbl_exp_list ->
      lbl_exp_list |> List.for_all (fun (lbl, exp) -> 
        lbl.lbl_mut = Immutable && is_nonexpansive exp
       )
  | Texp_ident(_,_) -> true
  | Texp_constant _ -> true
  | Texp_let(_rec_flag, pat_exp_list, body) ->
      List.for_all (fun (_pat, exp) -> is_nonexpansive exp) pat_exp_list &&
      is_nonexpansive body
  | Texp_function _ -> true
  | Texp_tuple el ->
      List.for_all is_nonexpansive el
  | Texp_construct(_, el) ->
      List.for_all is_nonexpansive el
              
  | Texp_field(exp, _lbl) -> is_nonexpansive exp
  | Texp_array [] -> true

  <<[[Typecore.is_nonexpansive()]] extra cases>>

  | _ -> false
@
% immutable check! reference have a mutable field! that's
% how you get side effects! 'a ref = { mutable x: 'a }


<<[[Typecode.type_let()]] generalization criteria action>>=
exp_list |> List.iter (fun exp -> 
  if not (is_nonexpansive exp) 
  then Ctype.make_nongen exp.exp_type
);
@
% nonexpansive means has not mutable, so not nonexpansive
% means it has some mutable! and so we should not generalize!

<<signature [[Ctype.make_nongen]]>>=
val make_nongen: type_expr -> unit
        (* Make non-generalizable the given type *)
@
% why need that? can't just precondition the call to generalize
% with is_nonexpansive instead of transforming the level
% so that the call to generalize later will fail?
% need to change the level? so faster at the upper level?
% todo: rewrite to be like for type_expression, and
% see if significantly slower!

<<function [[Ctype.make_nongen]]>>=
let rec make_nongen ty =
  match repr ty with
    Tvar v ->
      if v.tvar_level > !current_level 
      then v.tvar_level <- !current_level
  (* boilerplate visitor *)
  | Tarrow(t1, t2) ->
      make_nongen t1; make_nongen t2
  | Ttuple tl ->
      List.iter make_nongen tl
  | Tconstr(_p, tl) ->
      List.iter make_nongen tl
@
%old:  | Tconstr(p, []) ->
%      ()

\subsection{Toplevel entities}

% val is a form of let, so we want generalization too!

% val x: ...
<<signature [[Typedecl.transl_value_decl]]>>=
val transl_value_decl:
        Env.t -> Parsetree.value_description -> Types.value_description
@
<<function [[Typedecl.transl_value_decl]]>>=
(* Translate a value declaration *)

let transl_value_decl env valdecl =
  let ty = Typetexp.transl_type_scheme env valdecl.pval_type in
  { val_type = ty;
    val_prim = Primitive.parse_declaration (Ctype.arity ty) valdecl.pval_prim }
@
%old: Ctype.reset_def();


<<signature [[Typetexp.transl_type_scheme]]>>=
val transl_type_scheme:
        Env.t -> Parsetree.core_type -> Types.type_expr
@
% transl_value_decl -> <>
<<function [[Typetexp.transl_type_scheme]]>>=
let transl_type_scheme env styp =
  Ctype.reset_def();
  reset_type_variables();

  begin_def();
  let typ = transl_simple_type env false styp in
  end_def();

  generalize typ;
  typ
@
% generalize! again
%old: reset_def() was in the caller, in transl_value_decl
% but I prefer to put it closer to reset_type_variables;
% more symetric with the other functions.

\section{Typing other elements}

\subsection{Typing type expressions}
% this is mostly to build the environment that will then
% be used when typing expressions!


<<constant [[Typetexp.type_variables]]>>=
(* Translation of type expressions *)

let type_variables = ref (Tbl.empty : (string, Types.type_expr) Tbl.t)
@
% type_expr should always be a Tvar

<<signature [[Typetexp.transl_simple_type]]>>=
(* Typechecking of type expressions for the core language *)

val transl_simple_type:
        Env.t -> bool -> Parsetree.core_type -> Types.type_expr
@
% fixed? false when called fro Pexp_constraint, true when called
%  from type definitions
<<function [[Typetexp.transl_simple_type]]>>=
let rec transl_simple_type env fixed styp =
  match styp.ptyp_desc with
  | Ptyp_var name ->
      begin try
        Tbl.find name !type_variables
      with Not_found ->
        if fixed 
        then raise(Error(styp.ptyp_loc, Unbound_type_variable name))
        <<[[Typetexp.transl_simple_type()]] when not fixed and [[Not_found]]>>
      end
  | Ptyp_constr(lid, stl) ->
      let (path, decl) =
        try
          Env.lookup_type lid env
        with Not_found ->
          raise(Error(styp.ptyp_loc, Unbound_type_constructor lid)) in
      <<[[Typetexp.transl_simple_type()]] sanity check arity stl>>
      Tconstr(path, List.map (transl_simple_type env fixed) stl)
  (* boilerplate mapper *)
  | Ptyp_arrow(st1, st2) ->
      Tarrow(transl_simple_type env fixed st1,
             transl_simple_type env fixed st2)
  | Ptyp_tuple stl ->
      Ttuple(List.map (transl_simple_type env fixed) stl)
@

<<[[Typetexp.transl_simple_type()]] sanity check arity stl>>=
if List.length stl <> decl.type_arity 
then
  raise(Error(styp.ptyp_loc, Type_arity_mismatch(lid, decl.type_arity,
                                                     List.length stl)));
@


\subsection{Typing type declarations}

<<signature [[Typedecl.transl_type_decl]]>>=
val transl_type_decl:
        Env.t -> (string * Parsetree.type_declaration) list ->
                         (Ident.t * Types.type_declaration) list * Env.t
@
<<function [[Typedecl.transl_type_decl]]>>=
(* Translate a set of mutually recursive type declarations *)

let transl_type_decl env name_sdecl_list =
  Ctype.reset_def();
  let decls =
    match name_sdecl_list with
      [(name, {ptype_kind = Ptype_abstract}) as name_sdecl] ->
        (* No recursion involved, use original env for translation *)
        let id = Ident.create name in
        [transl_declaration env name_sdecl id]
    | _ ->
        (* Enter the types as abstract *)
        let (id_list, temp_env) = enter_types env name_sdecl_list in
        (* Translate each declaration *)
        List.map2 (transl_declaration temp_env) name_sdecl_list id_list 
  in
  (* Build the final env *)
  let newenv =
    List.fold_right
      (fun (id, decl) env -> Env.add_type id decl env)
      decls env in
  <<[[Typedecl.transl_type_decl()]] check recursive abbrevs>>
  (decls, newenv)
@
% why reset_def?




% called for one of the decl possiblty of a type x = ... and type y = ...
<<function [[Typedecl.transl_declaration]]>>=
let transl_declaration env (name, sdecl) id =
  Ctype.begin_def();
  reset_type_variables();

  let params =
    try
      List.map enter_type_variable sdecl.ptype_params
    with Already_bound ->
      raise(Error(sdecl.ptype_loc, Repeated_parameter)) in

  let decl =
    { type_params = params;
      type_arity = List.length params;
      type_kind =
        (match sdecl.ptype_kind with
        (* boilerplate mapper Pxxx -> Xxx *)
          Ptype_abstract ->
            Type_abstract
        | Ptype_variant cstrs ->
            <<[[Typedecl.transl_declaration()]] sanity check when variant case>>
            Type_variant(List.map
              (fun (name, args) ->
                      (name, List.map (transl_simple_type env true) args))
              cstrs)
        | Ptype_record lbls ->
            <<[[Typedecl.transl_declaration()]] sanity check when record case>>
            Type_record(List.map
              (fun (name, mut, arg) ->
                      (name, mut, transl_simple_type env true arg))
              lbls)
        );
      type_manifest =
        (match sdecl.ptype_manifest with
        | None -> None
        | Some sty -> Some(transl_simple_type env true sty)
        ); 
  } in
  Ctype.end_def();

  List.iter Ctype.generalize params;

  <<[[Typedecl.transl_declaration()]] sanity check decl>>
  (id, decl)
@


% exported because used in typedecl too
<<signature [[Typetexp.reset_type_variables]]>>=
val reset_type_variables: unit -> unit
@
% ??? -> <>
<<function [[Typetexp.reset_type_variables]]>>=
let reset_type_variables () =
  type_variables := Tbl.empty
@
% a bit ugly to use those globals, could
% be instead passed in a second environment



<<exception [[Typetexp.Already_bound]]>>=
exception Already_bound
@

<<signature [[Typetexp.enter_type_variable]]>>=
val enter_type_variable: string -> Types.type_expr
@
<<function [[Typetexp.enter_type_variable]]>>=
let enter_type_variable name =
  try
    ignore (Tbl.find name !type_variables); 
    raise Already_bound
  with Not_found ->
    let v = new_global_var() in
    type_variables := Tbl.add name v !type_variables;
    v
@
%todo: boilerplate again? could factorize code?



<<signature [[Ctype.new_global_var]]>>=
val new_global_var: unit -> type_expr
        (* Return a fresh variable, bound at toplevel
           (as type variables ['a] in type constraints). *)
@
<<function [[Ctype.new_global_var]]>>=
let new_global_var () =
  Tvar { tvar_level = 1; tvar_link = None }
@
% newvar not enough? anyway have no begin_def when
% processing type declarations no?




<<function [[Typedecl.enter_types]]>>=
(* Enter all declared types in the environment as abstract types *)

let rec enter_types env = function
    [] ->
      ([], env)
  | (name, sdecl) :: srem ->
      let decl =
        { type_params = []; (*this field is unused when kind = Type_abstract*)
          type_arity = List.length sdecl.ptype_params;
          type_kind = Type_abstract;
          type_manifest = None } in
      let (id, extenv) = Env.enter_type name decl env in
      let (rem_id, final_env) = enter_types extenv srem in
      (id :: rem_id, final_env)
@

% generalize???

\subsubsection{Sanity checks}

<<[[Typedecl.transl_declaration()]] sanity check when variant case>>=
let all_constrs = ref StringSet.empty in
cstrs |> List.iter (fun (name, args) ->
    if StringSet.mem name !all_constrs then
      raise(Error(sdecl.ptype_loc, Duplicate_constructor name));
    all_constrs := StringSet.add name !all_constrs
);
if List.length cstrs > Config.max_tag then
  raise(Error(sdecl.ptype_loc, Too_many_constructors));
@

<<[[Typedecl.transl_declaration()]] sanity check when record case>>=
let all_labels = ref StringSet.empty in
lbls |> List.iter (fun (name, mut, arg) ->
    if StringSet.mem name !all_labels then
      raise(Error(sdecl.ptype_loc, Duplicate_label name));
    all_labels := StringSet.add name !all_labels
);
@

<<[[Typedecl.transl_declaration()]] sanity check decl>>=
(* If both a variant/record definition and a type equation are given,
   need to check that the equation refers to a type of the same kind
   with the same constructors and labels *)
(match decl with
  {type_kind = (Type_variant _ | Type_record _); type_manifest = Some ty} ->
    (match ty with
     | Tconstr(path, args) ->
        begin try
          let decl' = Env.find_type path env in
          if args = params & Includecore.type_declarations env id decl decl'
          then ()
          else raise(Error(sdecl.ptype_loc, Definition_mismatch ty))
        with Not_found ->
          raise(Error(sdecl.ptype_loc, Definition_mismatch ty))
        end
    | _ -> raise(Error(sdecl.ptype_loc, Definition_mismatch ty))
    )
| _ -> ()
);
@



\subsection{Typing modules}

<<signature [[Typemod.transl_signature]]>>=
val transl_signature:
        Env.t -> Parsetree.signature -> Types.signature
@

<<signature [[Typemod.type_structure]]>>=
val type_structure:
        Env.t -> Parsetree.structure -> 
          Typedtree.structure * Types.signature * Env.t
@





\section{Advanced typing issues}

% those are the reasons the typechecker got so complicated?

\subsection{References, [['_a]]}
% _a

% because do not generalize! so the type stays
% a 'a but not a forall.'a! so throughout the
% whole file it will get more instantiated!
% it will not be copy!


%todo: then there is a check_nongen somewhere?
% to make sure the _a does not escape the module?
% anyway it does not have a syntax?

\subsection{Exceptions, [[exn]]}

% exn are really like an open variant, a variant that
% can be extended in different files.

% builtin exceptions

<<signatures [[Predef.type_xxx]]>>=
val type_exn: type_expr
@
<<constants [[Predef.type_xxx]]>>=
and type_exn = Tconstr(path_exn, [])
@

<<signatures [[Predef.path_xxx]]>>=
val path_exn: Path.t
@
<<constants [[Predef.path_xxx]]>>=
and path_exn = Pident ident_exn
@


<<[[Predef.build_initial_env()]] decls>>=
let decl_exn =
  {type_params = [];
   type_arity = 0;
   type_kind = Type_variant [];
   type_manifest = None}
in
@
% variant with no cases, but really it's more a variant
% with many cases, added in a cross-cutting way in different
% files. 


<<[[Typecore.type_exp()]] match cases>>=
| Pexp_try(sbody, caselist) ->
    let body = type_exp env sbody in
    let cases = type_cases env Predef.type_exn body.exp_type caselist in
    Parmatch.check_unused cases;
    { exp_desc = Texp_try(body, cases);
      exp_loc = sexp.pexp_loc;
      exp_type = body.exp_type }
@
% no check_partial here!








<<signature [[Predef.path_match_failure]]>>=
val path_match_failure: Path.t
@
% why a path for this one?
<<constant [[Predef.path_match_failure]]>>=
let path_match_failure = Pident ident_match_failure
@

<<constants [[Predef.ident_exn_xxx]]>>=
let ident_match_failure    = Ident.create "Match_failure"
and ident_out_of_memory    = Ident.create "Out_of_memory"
and ident_invalid_argument = Ident.create "Invalid_argument"
and ident_failure          = Ident.create "Failure"
and ident_not_found        = Ident.create "Not_found"
and ident_sys_error        = Ident.create "Sys_error"
and ident_end_of_file      = Ident.create "End_of_file"
and ident_division_by_zero = Ident.create "Division_by_zero"
and ident_stack_overflow   = Ident.create "Stack_overflow"
@
% why not in pervasives? because used in the compiler itself?


<<[[Predef.build_initial_env()]] adding exceptions>>=
add_exception ident_match_failure [Ttuple[type_string; type_int; type_int]] (
add_exception ident_out_of_memory [] (
add_exception ident_stack_overflow [] (
add_exception ident_invalid_argument [type_string] (
add_exception ident_failure [type_string] (
add_exception ident_not_found [] (
add_exception ident_sys_error [type_string] (
add_exception ident_end_of_file [] (
add_exception ident_division_by_zero [] (
@




<<signature [[Env.add_exception]]>>=
val add_exception: Ident.t -> exception_declaration -> t -> t
@
<<function [[Env.add_exception]]>>=
and add_exception id decl env =
  store_exception id (Pident id) decl env
@

<<function [[Env.store_exceptions]]>>=
and store_exception id path decl env =
  { constrs = Ident.add id (Datarepr.exception_descr path decl) env.constrs;
    (* boilerplate, with record *)
    values = env.values;
    labels = env.labels;
    types = env.types;
    modules = env.modules;
    components = env.components }
@




<<signature [[Predef.builtin_values]]>>=
(* To initialize linker tables *)

val builtin_values: (string * Ident.t) list
@

<<constant [[Predef.builtin_values]]>>=
let builtin_values =
  List.map (fun id -> Ident.make_global id; (Ident.name id, id))
      [ident_match_failure; ident_out_of_memory; ident_stack_overflow;
       ident_invalid_argument;
       ident_failure; ident_not_found; ident_sys_error; ident_end_of_file;
       ident_division_by_zero]
@

<<signature [[Ident.make_global]]>>=
val make_global: t -> unit
@
<<function [[Ident.make_global]]>>=
let make_global i =
  i.global <- true
@

<<[[Ident.t]] other fields>>=
mutable global: bool 
@
% what is it for? for Ident.name! to create something really unique.
% make sure they don't interface with names defined by user?
% but need that? the stamp in ident is not enough?
% create_persistent() not enough?




<<signature [[Typedecl.transl_exception]]>>=
val transl_exception:
        Env.t -> Parsetree.exception_declaration -> Types.exception_declaration
@

<<function [[Typedecl.transl_exception]]>>=
(* Translate an exception declaration *)

let transl_exception env excdecl =
  Ctype.reset_def();
  reset_type_variables();

  List.map (transl_simple_type env true) excdecl
@



<<signature [[Env.enter_exception]]>>=
val enter_exception: string -> exception_declaration -> t -> Ident.t * t
@

<<functions [[Env.enter_xxx]]>>=
and enter_exception = enter store_exception
@

<<signature [[Subst.exception_declaration]]>>=
val exception_declaration: t -> exception_declaration -> exception_declaration
@
<<function [[Subst.exception_declaration]]>>=
let exception_declaration s tyl =
  List.map (type_expr s) tyl
@



\subsection{Abstract types}

<<[[Parsetree.type_kind]] cases>>=
| Ptype_abstract
@
% int/float/array are actually neither a variant or a record,
% they are kinda builtin, so could have a Ptype_builtin of string,
% but instead they use Ptype_abstract for that too!
% less: could move that later because even Type_abstract
%  need to be presented early for builtin types, but the user
%  can not define builtin types, so really Ptype_abstract is
%  just for user defined abstract data type!


% type t (in .mli, and no = after)
% but also for builtins, because int, float, ...
% are not really variants or records, they are more
% type int;; type float;;

<<rule [[type_kind]] cases>>=
|  /*empty*/
    { (Ptype_abstract, None) }
@


\subsection{Type abbreviations}
% Manifest types
% ("Type aliases" is actually used for something else in ocaml)

% it's also for type x = y = z, not sure it's very useful

<<rule [[type_kind]] cases>>=
| EQUAL core_type %prec prec_type_def
    { (Ptype_abstract, Some $2) }
@
%$
% use abstract, why? because not a variant, not a record, but
% could have picked a Ptype_abbrev

<<[[Parsetree.type_declaration]] other fields>>=
ptype_manifest: core_type option;
@
<<[[Types.type_declaration]] other fields>>=
type_manifest: type_expr option 
@



<<exception [[Ctype.Cannot_expand]]>>=
(* Unification *)

exception Cannot_expand
@


% in ctype.ml before unify()

%   1. When unifying two non-abbreviated types, one type is made a link
%      to the other. When unifying an abbreviated type with a
%      non-abbreviated type, the non-abbreviated type is made a link to
%      the other one. When unifying to abbreviated types, these two
%      types are kept distincts, but they are made to (temporally)
%      expand to the same type.
%   2. Abbreviations with at least one parameter are systematically
%      expanded. The overhead does not seem to high, and that way
%      abbreviations where some parameters does not appear in the
%      expansion, such as ['a t = int], are correctly handled. In
%      particular, for this example, unifying ['a t] with ['b t] keeps
%      ['a] and ['b] distincts. (Is it really important ?)
%   3. Unifying an abbreviation ['a t = 'a] with ['a] should not yield
%      ['a t as 'a]. Indeed, the type variable would otherwise be lost.
%      This problem occurs for abbreviations expanding to a type
%      variable, but also to many other constrained abbreviations (for
%      instance, [(< x : 'a > -> unit) t = <x : 'a>]). The solution is
%      that, if an abbreviation is unified with some subpart of its
%      parameters, then the parameter actually does not get
%      abbreviated.  It would be possible to check whether some
%      information is indeed lost, but it probably does not worth it.


% p1 or p2 are possible paths to abbreviation types
<<[[Ctype.unify()]] match t1 t2 other cases>>=
| (Tconstr(p1, tl1), _) ->
    begin try
      unify env (expand_abbrev env p1 tl1) t2
    with Cannot_expand ->
      raise Unify
    end
| (_, Tconstr(p2, tl2)) ->
    begin try
      unify env t1 (expand_abbrev env p2 tl2)
    with Cannot_expand ->
      raise Unify
    end
@

<<[[Ctype.unify()]] if p1 or p2 are abbreviation type paths>>=
try
  unify env (expand_abbrev env p1 tl1) t2
with Cannot_expand ->
  try
    unify env t1 (expand_abbrev env p2 tl2)
  with Cannot_expand ->
@
% then will raise unify



<<function [[Ctype.expand_abbrev]]>>=
let expand_abbrev env path args =
  try
    let decl = Env.find_type path env in
    match decl.type_manifest with
      Some body -> substitute decl.type_params args body
    | None -> raise Cannot_expand
  with Not_found ->
    raise Cannot_expand
@

<<signature [[Ctype.substitute]]>>=
val substitute:
        type_expr list -> type_expr list -> type_expr -> type_expr
        (* [substitute [v1...vN] [t1...tN] t]
           returns a copy of [t] where the [vi] are replaced
           by the [ti]. *)
@

<<function [[Ctype.substitute]]>>=
let substitute params args body =
  inst_subst := List.combine params args;
  let ty = copy body in
  inst_subst := [];
  ty
@




<<[[Ctype.filter_arrow()]] other cases>>=
| Tconstr(p, tl) ->
    begin try
      filter_arrow env (expand_abbrev env p tl)
    with Cannot_expand ->
      raise Unify
    end
@




<<[[Typedecl.transl_type_decl()]] check recursive abbrevs>>=
(* Check for recursive abbrevs *)
List.iter2 (check_recursive_abbrev newenv) name_sdecl_list decls;
(* Done *)
@

<<function [[Typedecl.check_recursive_abbrev]]>>=
(* Check for recursive abbrevs *)

let check_recursive_abbrev env (name, sdecl) (id, decl) =
  match decl.type_manifest with
    Some ty ->
      if Ctype.free_type_ident env [id] ty
      then raise(Error(sdecl.ptype_loc, Recursive_abbrev name))
  | _ -> ()
@

<<signature [[Ctype.free_type_ident]]>>=
val free_type_ident: Env.t -> Ident.t list -> type_expr -> bool
        (* Test whether one of the given type identifiers occur free
           in the given type expression. *)
@


<<function [[Ctype.free_type_ident]]>>=
let rec free_type_ident env ids ty =
  match repr ty with
    Tvar _ -> false
  | Tconstr((Pident id as p), tl) ->
      List.exists (Ident.same id) ids || begin
        try
          free_type_ident env (id::ids) (expand_abbrev env p tl)
        with Cannot_expand ->
          List.exists (free_type_ident env ids) tl
      end
  | Tconstr(p, tl) ->
      begin try
        free_type_ident env ids (expand_abbrev env p tl)
      with Cannot_expand ->
        List.exists (free_type_ident env ids) tl
      end
  (* boilerplate folder *)
  | Tarrow(t1, t2) ->
      free_type_ident env ids t1 || free_type_ident env ids t2
  | Ttuple tl ->
      List.exists (free_type_ident env ids) tl
@




%there is also this, but is it useful?
<<rule [[type_kind]] cases>>=
| EQUAL core_type EQUAL opt_bar constructor_declarations %prec prec_type_def
    { (Ptype_variant(List.rev $5), Some $2) }
| EQUAL core_type EQUAL LBRACE label_declarations opt_semi RBRACE
  %prec prec_type_def
    { (Ptype_record(List.rev $5), Some $2) }
@
%todo: delete?


\subsection{[[printf()]] and [[format]]}

<<constants [[Predef.ident_xxx]]>>=
and ident_format = Ident.create "format"
@
<<signatures [[Predef.path_xxx]]>>=
val path_format: Path.t
@
<<constants [[Predef.path_xxx]]>>=
and path_format = Pident ident_format
@


% ('a, 'b, 'c) format
<<[[Predef.build_initial_env()]] decls>>=
let decl_format =
  {type_params = [newvar(); newvar(); newvar()];
   type_arity = 3;
   type_kind = Type_abstract;
   type_manifest = None} 
in
@

% special format typechecking


<<function [[Typecore.type_format]]>>=
(* Typing of printf formats *)

let type_format loc fmt =
  let len = String.length fmt in
  let ty_input = newvar() in
  let ty_result = newvar() in
  let rec skip_args j =
    if j >= len then j else
      match fmt.[j] with
        '0' .. '9' | ' ' | '.' | '-' -> skip_args (j+1)
      | _ -> j in
  let rec scan_format i =
    if i >= len 
    then ty_result 
    else
     match fmt.[i] with
      '%' ->
        let j = skip_args(i+1) in
        (match String.unsafe_get fmt j with
        (* We're using unsafe_get here so that if j = String.length fmt,
           we'll fall in the catch-all case of the match *)
          '%' | '!' ->
            scan_format (j+1)
        | 's' ->
            Tarrow(Predef.type_string, scan_format (j+1))
        | 'c' ->
            Tarrow(Predef.type_char, scan_format (j+1))
        | 'd' | 'o' | 'x' | 'X' | 'u' ->
            Tarrow(Predef.type_int, scan_format (j+1))
        | 'f' | 'e' | 'E' | 'g' | 'G' ->
            Tarrow(Predef.type_float, scan_format (j+1))
        | 'b' ->
            Tarrow(Predef.type_bool, scan_format (j+1))
        | 'a' ->
            let ty_arg = newvar() in
            Tarrow (Tarrow(ty_input, Tarrow (ty_arg, ty_result)),
                    Tarrow (ty_arg, scan_format (j+1)))
        | 't' ->
            Tarrow(Tarrow(ty_input, ty_result), scan_format (j+1))
        | _c ->
            raise(Error(loc, Bad_format(String.sub fmt i (j-i))))
        )
    | _ -> scan_format (i+1) in
  Tconstr(Predef.path_format, [scan_format 0; ty_input; ty_result])
@


<<[[Typecode.type_expect()]] match cases>>=
|  Pexp_constant(Const_string s as cst) ->
    let exp =
      { exp_desc = Texp_constant cst;
        exp_loc = sexp.pexp_loc;
        exp_type =
          (* Terrible hack for format strings *)
          match Ctype.repr ty_expected with
            Tconstr(path, _) when Path.same path Predef.path_format ->
              type_format sexp.pexp_loc s
          | _ -> Predef.type_string } in
    unify_exp env exp ty_expected;
    exp
@

\subsection{[[Obj.magic()]]}

\subsection{Module types and functors}

% things got more complicated also with functors ...

\subsection{Objects}

% things got so much more complicated with objects ...
% huge change in the typechecker, ctype.ml from 400LOC to 1200LOC
% and actually should also count the new btype.ml

% there was
%  'constraints' in type declarations



%\subsection{Type any}
%% '_' in types, but not that useful.
%%It was actually never matched ... probably because backported raw
% typing/ and didn't forward ported this feature
%
%<<[[Parsetree.core_type_desc]] cases>>=
%| Ptyp_any
%@
%
%<<rule simple_core_type cases>>=
%| UNDERSCORE
%    { mktyp(Ptyp_any) }
%@

%\subsection{Type aliases}
%% type t = x as 'a ????
%
%<<[[Parsetree.core_type_desc]] cases>>=
%| Ptyp_alias of core_type * string
%@
%% not what you think ...
%
%<<rule core_type cases>>=
%| core_type AS type_parameter
%    { mktyp(Ptyp_alias($1, $3)) }
%@


\chapter{Checking}

% have seen lots of checking done already, 
%  - naming (e.g. label not defined, Unbound_xxx),
%  - typing (e.g. was expecting an int, also arity checks)
% but there are other sanity checks done on the program
% (see sanity check chunknames before):
%  - dangerous partial application in a sequence (probably bug)
%  - ???

%todo: add the -warn-error!

\section{Interface/Implementation agreement}
% agreement?

%(* All functions "blah env x1 x2" check that x1 is included in x2,
%   i.e. that x1 is the type of an implementation that fulfills the
%   specification x2. If not, Error is raised with a backtrace of the error. *)

% for type declarations it's equivalence (e.g. 'a -> 'a =~ 'b -> 'b)
% for value it's more general ('a -> 'a more general than int -> int)
% for modules it's inclusion (it's ok to define more than what is exported)

<<exception [[Includecore.Dont_match]]>>=
exception Dont_match
@

\subsection{More general implementation}

<<signature [[Includecore.value_descriptions]]>>=
val value_descriptions:
        Env.t -> value_description -> value_description -> module_coercion
@

% vd1 = implem, vd2 = interface
% implem must be more general, so if interface says int -> int
% and implem is 'a -> 'a, then it's ok. If reverse then it's not!
<<function [[Includecore.value_descriptions]]>>=
let value_descriptions env vd1 vd2 =
  if Ctype.moregeneral env vd1.val_type vd2.val_type then begin
    match (vd1.val_prim, vd2.val_prim) with
        (Some p1, Some p2) ->
          if p1 = p2 
          then Tcoerce_none 
          else raise Dont_match
      | (Some p, None) -> Tcoerce_primitive p
      | (None, Some _p) -> raise Dont_match
      | (None, None) -> Tcoerce_none
  end else
    raise Dont_match
@

<<type [[Typedtree.module_coercion]]>>=
and module_coercion =
    Tcoerce_none
  | Tcoerce_structure of (int * module_coercion) list
  | Tcoerce_primitive of Primitive.description
@
%todo: delete?



<<function [[Ctype.moregeneral]]>>=
let moregeneral env sch1 sch2 =
  begin_def();
  try
    moregen env (instance sch1) sch2;
    end_def();
    true
  with Unify ->
    end_def();
    false
@


<<function [[Ctype.moregen]]>>=
let rec moregen env t1 t2 =
  if t1 == t2 
  then () 
  else 
   begin
    let t1 = repr t1 in
    let t2 = repr t2 in
    if t1 == t2 
    then () 
    else 
     begin
      match (t1, t2) with
        (Tvar v, _) ->
          if v.tvar_level = generic_level 
          then raise Unify;
          moregen_occur v t2;
          v.tvar_link <- Some t2
      | (Tarrow(t1, u1), Tarrow(t2, u2)) ->
          moregen env t1 t2; moregen env u1 u2
      | (Ttuple tl1, Ttuple tl2) ->
          moregen_list env tl1 tl2
      | (Tconstr(p1, tl1), Tconstr(p2, tl2)) ->
          if Path.same p1 p2 then
            moregen_list env tl1 tl2
          else begin
            try
              moregen env (expand_abbrev env p1 tl1) t2
            with Cannot_expand ->
            try
              moregen env t1 (expand_abbrev env p2 tl2)
            with Cannot_expand ->
              raise Unify
          end
      | (Tconstr(p1, tl1), _) ->
          begin try
            moregen env (expand_abbrev env p1 tl1) t2
          with Cannot_expand ->
            raise Unify
          end
      | (_, Tconstr(p2, tl2)) ->
          begin try
            moregen env t1 (expand_abbrev env p2 tl2)
          with Cannot_expand ->
            raise Unify
          end
      | (_, _) ->
          raise Unify
    end
  end

and moregen_list env tl1 tl2 =
  match (tl1, tl2) with
    ([], []) -> ()
  | (t1::r1, t2::r2) -> moregen env t1 t2; moregen_list env r1 r2
  | (_, _) -> raise Unify
@
% some abbrevs here too

% moregen -> <>
<<function [[Ctype.moregen_occur]]>>=
(* Matching between type schemes *)

let rec moregen_occur tvar ty =
  match repr ty with
    Tvar v ->
      if v == tvar then raise Unify;
      (* tvar has level = !current_level iff it is generic
         in the original type scheme. In this case, it can be freely
         instantiated. Otherwise, tvar is not generic
         and cannot be instantiated by a type that contains
         generic variables. *)
      if v.tvar_level = generic_level && tvar.tvar_level < !current_level
      then raise Unify
  (* boilerplate iterator *)
  | Tarrow(t1, t2) ->
      moregen_occur tvar t1; moregen_occur tvar t2
  | Ttuple tl ->
      List.iter (moregen_occur tvar) tl
  | Tconstr(_p, tl) ->
      List.iter (moregen_occur tvar) tl
@
%  | Tconstr(p, []) ->
%      ()




\subsection{Type equivalences}

%includecore.ml

<<signature [[Includecore.type_declarations]]>>=
val type_declarations:
        Env.t -> Ident.t -> type_declaration -> type_declaration -> bool
@
<<signature [[Includecore.exception_declarations]]>>=
val exception_declarations:
        Env.t -> exception_declaration -> exception_declaration -> bool
@
% return a bool here, does not thrown an exn


<<function [[Includecore.type_declarations]]>>=
(* Inclusion between type declarations *)

let type_declarations env id decl1 decl2 =
  decl1.type_arity = decl2.type_arity &&
  begin match (decl1.type_kind, decl2.type_kind) with
      (_, Type_abstract) -> true
    | (Type_variant cstrs1, Type_variant cstrs2) ->
        for_all2
          (fun (cstr1, arg1) (cstr2, arg2) ->
            cstr1 = cstr2 &&
            for_all2
              (fun ty1 ty2 ->
                Ctype.equal env decl1.type_params ty1 decl2.type_params ty2)
              arg1 arg2)
          cstrs1 cstrs2
    | (Type_record labels1, Type_record labels2) ->
        for_all2
          (fun (lbl1, mut1, ty1) (lbl2, mut2, ty2) ->
            lbl1 = lbl2 && mut1 = mut2 &&
            Ctype.equal env decl1.type_params ty1 decl2.type_params ty2)
          labels1 labels2
    | (_, _) -> false
  end &&
  begin match (decl1.type_manifest, decl2.type_manifest) with
      (_, None) -> true
    | (Some ty1, Some ty2) ->
        Ctype.equal env decl1.type_params ty1 decl2.type_params ty2
    | (None, Some ty2) ->
        let ty1 = Tconstr(Pident id, decl2.type_params) in
        Ctype.equal env [] ty1 [] ty2
  end
@

<<function [[Includecore.exception_declarations]]>>=
(* Inclusion between exception declarations *)

let exception_declarations env ed1 ed2 =
  for_all2 (fun ty1 ty2 -> Ctype.equal env [] ty1 [] ty2) ed1 ed2
@



<<function [[Ctype.equal]]>>=
(* Equivalence between parameterized types *)

let equal env params1 ty1 params2 ty2 =
  let subst = List.combine params1 params2 in
  let rec eqtype t1 t2 =
    let t1 = repr t1 in
    let t2 = repr t2 in
    match (t1, t2) with
      (Tvar _, Tvar _) ->
        begin try
          List.assq t1 subst == t2
        with Not_found ->
          fatal_error "Ctype.equal"
        end
    | (Tarrow(t1, u1), Tarrow(t2, u2)) ->
        eqtype t1 t2 && eqtype u1 u2
    | (Ttuple tl1, Ttuple tl2) ->
        eqtype_list tl1 tl2
    | (Tconstr(p1, tl1), Tconstr(p2, tl2)) ->
        if Path.same p1 p2 then
          eqtype_list tl1 tl2
        else begin
          try
            eqtype (expand_abbrev env p1 tl1) t2
          with Cannot_expand ->
          try
            eqtype t1 (expand_abbrev env p2 tl2)
          with Cannot_expand ->
            false
        end
    | (Tconstr(p1, tl1), _) ->
        begin try
          eqtype (expand_abbrev env p1 tl1) t2
        with Cannot_expand ->
          false
        end
    | (_, Tconstr(p2, tl2)) ->
        begin try
          eqtype t1 (expand_abbrev env p2 tl2)
        with Cannot_expand ->
          false
        end
    | (_, _) ->
        false
  and eqtype_list tl1 tl2 =
    match (tl1, tl2) with
      ([], []) -> true
    | (t1::r1, t2::r2) -> eqtype t1 t2 && eqtype_list r1 r2
    | (_, _) -> false
  in
    eqtype ty1 ty2
@





\subsection{Module inclusion}
%includemod.ml

% implem sig vs interface sig
<<signature [[Includemod.compunit]]>>=
val compunit: string -> signature -> string -> signature -> module_coercion
@




<<function [[Includemod.compunit]]>>=
(* Check that an implementation of a compilation unit meets its
   interface. *)

let compunit impl_name impl_sig intf_name intf_sig =
  try
    signatures Env.initial impl_sig intf_sig
  with Error reasons ->
    raise(Error(Interface_mismatch(impl_name, intf_name) :: reasons))
@



<<signature [[Includemod.signatures]]>>=
val signatures: Env.t -> signature -> signature -> module_coercion
@
<<signature [[Includemod.modtypes]]>>=
val modtypes: Env.t -> module_type -> module_type -> module_coercion
@

<<function [[Includemod.signatures]]>>=
(* Inclusion between signatures *)

and signatures env sig1 sig2 =
  (* Environment used to check inclusion of components *)
  let new_env =
    Env.add_signature sig1 env in
  (* Build a table of the components of sig1, along with their positions.
     The table is indexed by kind and name of component *)
  let rec build_component_table pos tbl = function
      [] -> tbl
    | item :: rem ->
        let (id, name) = item_ident_name item in
        let nextpos =
          match item with
            Tsig_value(_,{val_prim = None})
          | Tsig_exception(_,_)
          | Tsig_module(_,_) -> pos+1
          | Tsig_value(_,{val_prim = Some _})
          | Tsig_type(_,_)
          -> pos in
        build_component_table nextpos
                              (Tbl.add name (id, item, pos) tbl) rem in
  let comps1 =
    build_component_table 0 Tbl.empty sig1 in
  (* Pair each component of sig2 with a component of sig1,
     identifying the names along the way.
     Return a coercion list indicating, for all run-time components
     of sig2, the position of the matching run-time components of sig1
     and the coercion to be applied to it. *)
  let rec pair_components paired unpaired = function
      [] ->
        begin match unpaired with
            [] -> signature_components new_env (List.rev paired)
          | _  -> raise(Error unpaired)
        end
    | item2 :: rem ->
        let (id2, name2) = item_ident_name item2 in
        begin try
          let (id1, item1, pos1) = Tbl.find name2 comps1 in
          Ident.identify id1 id2
            (fun () ->
              pair_components ((item1, item2, pos1) :: paired) unpaired rem)
        with Not_found ->
          pair_components paired (Missing_field id2 :: unpaired) rem
        end in

  (* Do the pairing and checking, and return the final coercion *)
  simplify_structure_coercion(pair_components [] [] sig2)
@

<<function [[Includemod.signature_components]]>>=
(* Inclusion between signature components *)

and signature_components env = function
    [] -> []
  | (Tsig_value(id1, valdecl1), Tsig_value(id2, valdecl2), pos) :: rem ->
      let cc = value_descriptions env id1 valdecl1 valdecl2 in
      (match valdecl2.val_prim with
      | None -> (pos, cc) :: signature_components env rem
      | Some p -> signature_components env rem
      )
  | (Tsig_type(id1, tydecl1), Tsig_type(id2, tydecl2), pos) :: rem ->
      type_declarations env id1 tydecl1 tydecl2;
      signature_components env rem
  | (Tsig_exception(id1, excdecl1), Tsig_exception(id2, excdecl2), pos)
    :: rem ->
      exception_declarations env id1 excdecl1 excdecl2;
      (pos, Tcoerce_none) :: signature_components env rem

  | (Tsig_module(id1, mty1), Tsig_module(id2, mty2), pos) :: rem ->
      let cc = modtypes env mty1 mty2 in
      (pos, cc) :: signature_components env rem
  | _ ->
      fatal_error "Includemod.signature_components"
@

% mostly rewrap the error message
<<function [[Includemod.value_descriptions]]>>=
(* Inclusion between value descriptions *)

let value_descriptions env id vd1 vd2 =
  try
    Includecore.value_descriptions env vd1 vd2
  with Includecore.Dont_match ->
    raise(Error[Value_descriptions(id, vd1, vd2)])
@

<<function [[Includemod.type_declarations]]>>=
(* Inclusion between type declarations *)

let type_declarations env id decl1 decl2 =
  if Includecore.type_declarations env id decl1 decl2
  then ()
  else raise(Error[Type_declarations(id, decl1, decl2)])
@

<<function [[Includemod.exception_declarations]]>>=
(* Inclusion between exception declarations *)

let exception_declarations env id decl1 decl2 =
  if Includecore.exception_declarations env decl1 decl2
  then ()
  else raise(Error[Exception_declarations(id, decl1, decl2)])
@





<<signature [[Env.add_signature]]>>=
(* Insertion of all fields of a signature. *)

val add_signature: signature -> t -> t
@
<<function [[Env.add_signature]]>>=
let add_signature sg env =
  List.fold_left add_signature_component env sg
@

<<function [[Env.add_signature_component]]>>=
(* Insertion of all components of a signature *)

let add_signature_component env comp =
  match comp with
    Tsig_value(id, decl) -> add_value id decl env
  | Tsig_type(id, decl) -> add_type id decl env
  | Tsig_exception(id, decl) -> add_exception id decl env
  | Tsig_module(id, mty) -> add_module id mty env
@




<<signature [[Ident.identify]]>>=
val identify: t -> t -> (unit -> 'a) -> 'a
        (* [identify id1 id2 f] temporarily makes [id1] and [id2] the same
           during the evaluation of [f ()]. *)
@
<<function [[Ident.identify]]>>=
let identify i1 i2 f =
  let name1 = i1.name and stamp1 = i1.stamp in
  try
    i1.name <- i2.name;
    i1.stamp <- i2.stamp;
    let res = f () in
    i1.name <- name1;
    i1.stamp <- stamp1;
    res
  with x ->
    i1.name <- name1;
    i1.stamp <- stamp1;
    raise x
@




<<signature [[Env.check_modtype_inclusion]]>>=
(* Forward declaration to break mutual recursion with includemod. *)

val check_modtype_inclusion: (t -> module_type -> module_type -> unit) ref
@
<<constant [[Env.check_modtype_inclusion]]>>=
let check_modtype_inclusion =
  (* to be filled with includemod.check_modtype_inclusion *)
  ref ((fun env mty1 mty2 -> fatal_error "Env.include_modtypes") :
       t -> module_type -> module_type -> unit)
@

<<function [[Includemod.check_modtype_inclusion]]>>=
(* Simplified inclusion check between module types *)

let check_modtype_inclusion env mty1 mty2 =
  try
    ignore (modtypes env mty1 mty2)
  with Error reasons ->
    raise Not_found
@

<<toplevel [[Includemod._1]]>>=
let _ = Env.check_modtype_inclusion := check_modtype_inclusion
@

\section{Partial pattern matches (exhaustive check)}
% parmatch.ml

% very very useful! especially in refactoring context!

<<signature [[Parmatch.check_partial]]>>=
val check_partial: 
  Location.t -> (Typedtree.pattern * Typedtree.expression) list -> unit
@

\section{Dead code}

% Surprisingly effective at finding bugs! 
% If it's dead, it's probably not what you meant!

\subsection{Dead variables}

\subsection{Dead functions}

% (easier to detect when not exported in .cmi)

\subsection{Dead statements}

%port check added in 2.01:
% "also check when do a; b  that a returns unit indeed
%catches silly mistake such as
%    "record.lbl = newval; ..." instead of "record.lbl <- newval; ...".

\subsection{Dead patterns}
%was \section{Unused pattern matches (dead code)}

<<signature [[Parmatch.check_unused]]>>=
val check_unused: 
  (Typedtree.pattern * Typedtree.expression) list -> unit
@



% other? dead???








\chapter{Compiling}
% Generating

<<constant [[Clflags.compile_only]]>>=
let compile_only = ref false            (* -c *)
@


% source (.ml) -> 
% typed AST -> untyped lambda -> bytecode assembly -> 
% bytecode object (.cmo)

\section{Descriptions and representations}
% this is very compiler oriented no? not really typing.

<<[[Types.constructor_description]] other fields>>=
cstr_tag: constructor_tag;          (* Tag for heap blocks *)
cstr_consts: int;                   (* Number of constant constructors *)
cstr_nonconsts: int;               (* Number of non-const constructors *)
@

<<type [[Types.constructor_tag]]>>=
and constructor_tag =
    Cstr_constant of int                (* Constant constructor (an int) *)
  | Cstr_block of int                   (* Regular constructor (a block) *)
  | Cstr_exception of Path.t            (* Exception constructor *)
@



<<[[Types.label_description]] other fields>>=
lbl_pos: int;                       (* Position in block *)
lbl_all: label_description array;   (* All the labels in this type *)
lbl_repres: record_representation;  (* Representation for this record *)
@
% this is a form of compilation already no?

<<type [[Types.record_representation]]>>=
and record_representation =
    Record_regular                      (* All fields are boxed / tagged *)
  | Record_float                        (* All fields are floats *)
@

% also have seen many *int in module_components, useful
% in compilation context too.




<<signature [[Datarepr.constructor_descrs]]>>=
val constructor_descrs:
  type_expr -> (string * type_expr list) list ->
    (string * constructor_description) list
@
<<signature [[Datarepr.exception_descr]]>>=
val exception_descr:
  Path.t -> type_expr list -> constructor_description
@
<<signature [[Datarepr.label_descrs]]>>=
val label_descrs:
  type_expr -> (string * mutable_flag * type_expr) list ->
    (string * label_description) list
@





<<function [[Datarepr.constructor_descrs]]>>=
let constructor_descrs ty_res cstrs =
  let num_consts = ref 0 in
  let num_nonconsts = ref 0 in
  cstrs |> List.iter (function 
    | (_name, []) -> incr num_consts
    | (_name, _)  -> incr num_nonconsts
  );
  let rec describe_constructors idx_const idx_nonconst = function
      [] -> []
    | (name, ty_args) :: rem ->
        let (tag, descr_rem) =
          match ty_args with
            [] -> (Cstr_constant idx_const,
                   describe_constructors (idx_const+1) idx_nonconst rem)
          | _  -> (Cstr_block idx_nonconst,
                   describe_constructors idx_const (idx_nonconst+1) rem) 
        in
        let cstr =
          { cstr_res = ty_res;
            cstr_args = ty_args;
            cstr_arity = List.length ty_args;
            cstr_tag = tag;
            cstr_consts = !num_consts;
            cstr_nonconsts = !num_nonconsts } 
        in
        (name, cstr) :: descr_rem in
  describe_constructors 0 0 cstrs
@

<<function [[Datarepr.exception_descr]]>>=
let exception_descr path_exc decl =
  { cstr_res = Predef.type_exn;
    cstr_args = decl;
    cstr_arity = List.length decl;
    cstr_tag = Cstr_exception path_exc;
    cstr_consts = -1;
    cstr_nonconsts = -1 }
@

<<constant [[Datarepr.dummy_label]]>>=
let dummy_label =
  { lbl_res = Ttuple []; lbl_arg = Ttuple []; lbl_mut = Immutable;
    lbl_pos = (-1); lbl_all = [||]; lbl_repres = Record_regular }
@

<<function [[Datarepr.is_float]]>>=
(* Cannot call ctype.repres here *)

let rec is_float = function
    Tvar {tvar_link = Some ty} -> is_float ty
  | Tconstr(p, _) -> Path.same p Predef.path_float
  | _ -> false
@

<<function [[Datarepr.label_descrs]]>>=
let label_descrs ty_res lbls =
  let all_labels = Array.create (List.length lbls) dummy_label in
  let repres =
    if List.for_all (fun (_name, _flag, ty) -> is_float ty) lbls
    then Record_float
    else Record_regular in
  let rec describe_labels num = function
      [] -> []
    | (name, mut_flag, ty_arg) :: rest ->
        let lbl =
          { lbl_res = ty_res;
            lbl_arg = ty_arg;
            lbl_mut = mut_flag;
            lbl_pos = num;
            lbl_all = all_labels;
            lbl_repres = repres } in
        all_labels.(num) <- lbl;
        (name, lbl) :: describe_labels (num+1) rest in
  describe_labels 0 lbls
@


\section{Typed AST to untyped [[Lambda]] calcul}


%(* Translation from typed abstract syntax to lambda terms,
%   for the core language *)

%<<signature Translcore.transl_exp>>=
%val transl_exp: expression -> lambda
%@


\subsection{[[Lambda]]}

<<type [[Lambda.lambda]]>>=
type lambda =
    Lvar of Ident.t
  | Lconst of structured_constant

  | Lapply of lambda * lambda list
  | Lfunction of function_kind * Ident.t list * lambda

  | Llet of let_kind * Ident.t * lambda * lambda
  | Lletrec of (Ident.t * lambda) list * lambda

  | Lprim of primitive * lambda list

  | Lswitch of lambda * lambda_switch
  | Lstaticfail

  | Lcatch of lambda * lambda
  | Ltrywith of lambda * Ident.t * lambda

  | Lifthenelse of lambda * lambda * lambda
  | Lsequence of lambda * lambda
  | Lwhile of lambda * lambda
  | Lfor of Ident.t * lambda * lambda * direction_flag * lambda
  | Lassign of Ident.t * lambda

  <<[[Lambda.lambda]] other cases>>
@

% what is missing except the types? Did some simplifications?
% pattern matching is simpler?

<<type [[Lambda.lambda_switch]]>>=
and lambda_switch =
  { sw_numconsts: int;                  (* Number of integer cases *)
    sw_consts: (int * lambda) list;     (* Integer cases *)
    sw_numblocks: int;                  (* Number of tag block cases *)
    sw_blocks: (int * lambda) list;     (* Tag block cases *)
    sw_checked: bool }                  (* True if bound checks needed *)
@


<<type [[Lambda.function_kind]]>>=
type function_kind = Curried | Tupled
@

<<type [[Lambda.let_kind]]>>=
type let_kind = Strict | Alias | StrictOpt
@
% ??

<<type [[Lambda.shared_code]]>>=
type shared_code = (int * int) list     (* stack size -> code label *)
@
% ???

\subsubsection{Structured constants}

<<type [[Lambda.structured_constant]]>>=
type structured_constant =
    Const_base of Asttypes.constant
  | Const_pointer of int
  | Const_block of int * structured_constant list
  <<[[Lambda.structured_constant]] other cases>>
@


\subsubsection{Primitives}

% primitives? good name? but then there is Pccall, so there
% is lambda/bytecode primitives (%xxx) and then C primitives (caml_xxx)
<<type [[Lambda.primitive]]>>=
type primitive =
    Pidentity

  (* Globals *)
  | Pgetglobal of Ident.t
  | Psetglobal of Ident.t

  (* Operations on heap blocks *)
  | Pmakeblock of int * mutable_flag

  | Pfield of int
  | Psetfield of int * bool

  <<[[Lambda.primitive]] operations on heap blocks other cases>>

  (* External call *)
  | Pccall of Primitive.description

  (* Exceptions *)
  | Praise

  (* Boolean operations *)
  | Psequand | Psequor | Pnot

  (* Integer operations *)
  | Pnegint | Paddint | Psubint | Pmulint | Pdivint | Pmodint
  | Pandint | Porint | Pxorint
  | Plslint | Plsrint | Pasrint

  | Pintcomp of comparison

  | Poffsetint of int
  | Poffsetref of int

  (* Float operations *)
  <<[[Lambda.primitive]] float operations cases>>
  (* String operations *)
  <<[[Lambda.primitive]] string operations cases>>
  (* Array operations *)
  <<[[Lambda.primitive]] array operations cases>>

  (* Test if the argument is a block or an immediate integer *)
  | Pisint

  (* Bitvect operations *)
  | Pbittest
@
% very close to bytecode instruction set

<<type [[Lambda.comparison]]>>=
and comparison =
    Ceq | Cneq | Clt | Cgt | Cle | Cge
@


\subsection{Primitives, [[Translcore.transl_primitive()]]}

<<signature [[Translcore.transl_primitive]]>>=
val transl_primitive: Primitive.description -> lambda
@



<<constant [[Translcore.primitives_table]]>>=
let primitives_table = create_hashtable 31 [
  "%identity", Pidentity;

  "%field0", Pfield 0;
  "%field1", Pfield 1;
  "%setfield0", Psetfield(0, true);
  "%makeblock", Pmakeblock(0, Immutable);
  "%makemutable", Pmakeblock(0, Mutable);

  "%raise", Praise;

  "%sequand", Psequand;
  "%sequor", Psequor;
  "%boolnot", Pnot;

  "%negint", Pnegint;
  "%succint", Poffsetint 1;
  "%predint", Poffsetint(-1);
  "%addint", Paddint;
  "%subint", Psubint;
  "%mulint", Pmulint;
  "%divint", Pdivint;
  "%modint", Pmodint;
  "%andint", Pandint;
  "%orint", Porint;
  "%xorint", Pxorint;
  "%lslint", Plslint;
  "%lsrint", Plsrint;
  "%asrint", Pasrint;

  "%eq", Pintcomp Ceq;
  "%noteq", Pintcomp Cneq;
  "%ltint", Pintcomp Clt;
  "%leint", Pintcomp Cle;
  "%gtint", Pintcomp Cgt;
  "%geint", Pintcomp Cge;

  "%incr", Poffsetref(1);
  "%decr", Poffsetref(-1);

  "%intoffloat", Pintoffloat;
  "%floatofint", Pfloatofint;
  "%negfloat", Pnegfloat;
  "%absfloat", Pabsfloat;
  "%addfloat", Paddfloat;
  "%subfloat", Psubfloat;
  "%mulfloat", Pmulfloat;
  "%divfloat", Pdivfloat;
  "%eqfloat", Pfloatcomp Ceq;
  "%noteqfloat", Pfloatcomp Cneq;
  "%ltfloat", Pfloatcomp Clt;
  "%lefloat", Pfloatcomp Cle;
  "%gtfloat", Pfloatcomp Cgt;
  "%gefloat", Pfloatcomp Cge;

  "%string_length", Pstringlength;
  "%string_safe_get", Pstringrefs;
  "%string_safe_set", Pstringsets;
  "%string_unsafe_get", Pstringrefu;
  "%string_unsafe_set", Pstringsetu;

  "%array_length", Parraylength Pgenarray;
  "%array_safe_get", Parrayrefs Pgenarray;
  "%array_safe_set", Parraysets Pgenarray;
  "%array_unsafe_get", Parrayrefu Pgenarray;
  "%array_unsafe_set", Parraysetu Pgenarray;
  "%obj_size", Parraylength Paddrarray;
  "%obj_field", Parrayrefu Paddrarray;
  "%obj_set_field", Parraysetu Paddrarray;
  "%obj_is_int", Pisint;
]
@

% type? it's for overloaded operators? 
% - general, 
% - int, 
% - float, 
% - string



<<signature [[Translmod.primitive_declarations]]>>=
val primitive_declarations: string list ref
@
<<constant [[Translmod.primitive_declarations]]>>=
(* Record the primitive declarations occuring in the module compiled *)

let primitive_declarations = ref ([] : string list)
@

\subsection{Generic comparisons}
% was "overloaded" but it's the wrong term. As opposed to haskell
% ocaml comparisons are not overloaded unfortunately.

% - general, 
% - int, 
% - float, 
% - string

<<constant [[Translcore.comparisons_table]]>>=
(* Translation of primitives *)

let comparisons_table = create_hashtable 11 [
  "%equal",
      (Pccall{prim_name = "equal"; prim_arity = 2; prim_alloc = false;
              prim_native_name = ""; prim_native_float = false},
       Pintcomp Ceq,
       Pfloatcomp Ceq,
       Pccall{prim_name = "string_equal"; prim_arity = 2; prim_alloc = false;
              prim_native_name = ""; prim_native_float = false});
  "%notequal",
      (Pccall{prim_name = "notequal"; prim_arity = 2; prim_alloc = false;
              prim_native_name = ""; prim_native_float = false},
       Pintcomp Cneq,
       Pfloatcomp Cneq,
       Pccall{prim_name = "string_notequal"; prim_arity = 2;
              prim_alloc = false; prim_native_name = ""; 
              prim_native_float = false});
  "%lessthan",
      (Pccall{prim_name = "lessthan"; prim_arity = 2; prim_alloc = false; 
              prim_native_name = ""; prim_native_float = false},
       Pintcomp Clt,
       Pfloatcomp Clt,
       Pccall{prim_name = "lessthan"; prim_arity = 2; prim_alloc = false;
              prim_native_name = ""; prim_native_float = false});
  "%greaterthan",
      (Pccall{prim_name = "greaterthan"; prim_arity = 2; prim_alloc = false;
              prim_native_name = ""; prim_native_float = false},
       Pintcomp Cgt,
       Pfloatcomp Cgt,
       Pccall{prim_name = "greaterthan"; prim_arity = 2; prim_alloc = false;
              prim_native_name = ""; prim_native_float = false});
  "%lessequal",
      (Pccall{prim_name = "lessequal"; prim_arity = 2; prim_alloc = false;
              prim_native_name = ""; prim_native_float = false},
       Pintcomp Cle,
       Pfloatcomp Cle,
       Pccall{prim_name = "lessequal"; prim_arity = 2; prim_alloc = false;
              prim_native_name = ""; prim_native_float = false});
  "%greaterequal",
      (Pccall{prim_name = "greaterequal"; prim_arity = 2; prim_alloc = false;
              prim_native_name = ""; prim_native_float = false},
       Pintcomp Cge,
       Pfloatcomp Cge,
       Pccall{prim_name = "greaterequal"; prim_arity = 2; prim_alloc = false;
              prim_native_name = ""; prim_native_float = false})
]
@




\subsection{Expressions, [[Translcore.transl_exp()]]}


<<signature [[Translcore.transl_exp]]>>=
val transl_exp: Typedtree.expression -> lambda
@



<<signature [[Translcore.transl_let]]>>=
val transl_let:
      rec_flag -> (Typedtree.pattern * Typedtree.expression) list -> 
        lambda -> lambda
@


<<function [[Translcore.transl_exp]]>>=
let rec transl_exp e =
  match e.exp_desc with
  <<[[Translcore.transl_exp()]] cases>>
  | _ ->
      fatal_error "Translcore.transl"
@
%todo: remove the _ case! so can get exhaustive checks warnings

<<[[Translcore.transl_exp()]] cases>>=
    Texp_ident(path, {val_prim = Some p}) ->
      transl_primitive p
  | Texp_ident(path, desc) ->
      transl_path path
  | Texp_constant cst ->
      Lconst(Const_base cst)
  | Texp_let(rec_flag, pat_expr_list, body) ->
      transl_let rec_flag pat_expr_list (event_before body (transl_exp body))
  | Texp_function pat_expr_list ->
      let ((kind, params), body) =
        event_function e
          (function repr ->
             transl_function e.exp_loc !Clflags.native_code repr pat_expr_list)
      in
      Lfunction(kind, params, body)
  | Texp_apply({exp_desc = Texp_ident(path, {val_prim = Some p})}, args)
    when List.length args = p.prim_arity ->
      let prim = transl_prim p args in
      let lam = Lprim(prim, transl_list args) in
      begin match prim with Pccall _ -> event_after e lam | _ -> lam end
  | Texp_apply(funct, args) ->
      let lam =
        match transl_exp funct with
         lexp ->
            Lapply(lexp, transl_list args) in
      event_after e lam
  | Texp_match({exp_desc = Texp_tuple argl} as arg, pat_expr_list) ->
      Matching.for_multiple_match e.exp_loc
        (transl_list argl) (transl_cases pat_expr_list)
  | Texp_match(arg, pat_expr_list) ->
      Matching.for_function e.exp_loc None
        (transl_exp arg) (transl_cases pat_expr_list)
  | Texp_try(body, pat_expr_list) ->
      let id = name_pattern "exn" pat_expr_list in
      Ltrywith(transl_exp body, id,
               Matching.for_trywith (Lvar id) (transl_cases pat_expr_list))
  | Texp_tuple el ->
      let ll = transl_list el in
      begin try
        Lconst(Const_block(0, List.map extract_constant ll))
      with Not_constant ->
        Lprim(Pmakeblock(0, Immutable), ll)
      end
  | Texp_construct(cstr, args) ->
      let ll = transl_list args in
      begin match cstr.cstr_tag with
        Cstr_constant n ->
          Lconst(Const_pointer n)
      | Cstr_block n ->
          begin try
            Lconst(Const_block(n, List.map extract_constant ll))
          with Not_constant ->
            Lprim(Pmakeblock(n, Immutable), ll)
          end
      | Cstr_exception path ->
          Lprim(Pmakeblock(0, Immutable), transl_path path :: ll)
      end
  | Texp_record ((lbl1, _) :: _ as lbl_expr_list) ->
      let lv = Array.create (Array.length lbl1.lbl_all) Lstaticfail in
      List.iter
        (fun (lbl, expr) -> lv.(lbl.lbl_pos) <- transl_exp expr)
        lbl_expr_list;
      let ll = Array.to_list lv in
      if List.exists (fun (lbl, expr) -> lbl.lbl_mut = Mutable) lbl_expr_list
      then begin
        match lbl1.lbl_repres with
          Record_regular -> Lprim(Pmakeblock(0, Mutable), ll)
        | Record_float -> Lprim(Pmakearray Pfloatarray, ll)
      end else begin
        try
          let cl = List.map extract_constant ll in
          match lbl1.lbl_repres with
            Record_regular -> Lconst(Const_block(0, cl))
          | Record_float ->
              Lconst(Const_float_array(List.map extract_float cl))
        with Not_constant ->
          match lbl1.lbl_repres with
            Record_regular -> Lprim(Pmakeblock(0, Immutable), ll)
          | Record_float -> Lprim(Pmakearray Pfloatarray, ll)
      end
  | Texp_field(arg, lbl) ->
      let access =
        match lbl.lbl_repres with
          Record_regular -> Pfield lbl.lbl_pos
        | Record_float -> Pfloatfield lbl.lbl_pos in
      Lprim(access, [transl_exp arg])
  | Texp_setfield(arg, lbl, newval) ->
      let access =
        match lbl.lbl_repres with
          Record_regular -> Psetfield(lbl.lbl_pos, maybe_pointer newval)
        | Record_float -> Psetfloatfield lbl.lbl_pos in
      Lprim(access, [transl_exp arg; transl_exp newval])
  | Texp_array expr_list ->
      let kind = array_kind e in
      let len = List.length expr_list in
      if len <= Config.max_young_wosize then
        Lprim(Pmakearray kind, transl_list expr_list)
      else begin
        let v = Ident.create "makearray" in
        let rec fill_fields pos = function
          [] ->
            Lvar v
        | arg :: rem ->
            Lsequence(Lprim(Parraysetu kind,
                            [Lvar v;
                             Lconst(Const_base(Const_int pos));
                             transl_exp arg]),
                      fill_fields (pos+1) rem) in
        Llet(Strict, v,
             Lprim(Pccall prim_makearray,
                   [Lconst(Const_base(Const_int len));
                    transl_exp (List.hd expr_list)]),
             fill_fields 1 (List.tl expr_list))
      end
  | Texp_ifthenelse(cond, ifso, Some ifnot) ->
      Lifthenelse(transl_exp cond,
                  event_before ifso (transl_exp ifso),
                  event_before ifnot (transl_exp ifnot))
  | Texp_ifthenelse(cond, ifso, None) ->
      Lifthenelse(transl_exp cond,
                  event_before ifso (transl_exp ifso),
                  lambda_unit)
  | Texp_sequence(expr1, expr2) ->
      Lsequence(transl_exp expr1, event_before expr2 (transl_exp expr2))
  | Texp_while(cond, body) ->
      Lwhile(transl_exp cond, event_before body (transl_exp body))
  | Texp_for(param, low, high, dir, body) ->
      Lfor(param, transl_exp low, transl_exp high, dir,
           event_before body (transl_exp body))
  | Texp_when(cond, body) ->
      event_before cond
        (Lifthenelse(transl_exp cond, event_before body (transl_exp body),
                     Lstaticfail))
@


<<function [[Translcore.transl_function]]>>=
and transl_function loc untuplify_fn repr pat_expr_list =
  match pat_expr_list with
    [pat, ({exp_desc = Texp_function pl} as exp)] ->
      let param = name_pattern "param" pat_expr_list in
      let ((_, params), body) = transl_function exp.exp_loc false repr pl in
      ((Curried, param :: params),
       Matching.for_function loc None (Lvar param) [pat, body])
  | ({pat_desc = Tpat_tuple pl}, _) :: _ when untuplify_fn ->
      begin try
        let size = List.length pl in
        let pats_expr_list =
          List.map
            (fun (pat, expr) -> (Matching.flatten_pattern size pat, expr))
            pat_expr_list in
        let params = List.map (fun p -> Ident.create "param") pl in
        ((Tupled, params),
         Matching.for_tupled_function loc params
                                      (transl_tupled_cases pats_expr_list))
      with Matching.Cannot_flatten ->
        let param = name_pattern "param" pat_expr_list in
        ((Curried, [param]),
         Matching.for_function loc repr (Lvar param)
           (transl_cases pat_expr_list))
      end
  | _ ->
      let param = name_pattern "param" pat_expr_list in
      ((Curried, [param]),
       Matching.for_function loc repr (Lvar param)
         (transl_cases pat_expr_list))
@

<<function [[Translcore.transl_let]]>>=
and transl_let rec_flag pat_expr_list body =
  match rec_flag with
    Nonrecursive ->
      let rec transl = function
        [] ->
          body
      | (pat, expr) :: rem ->
          Matching.for_let pat.pat_loc (transl_exp expr) pat (transl rem)
      in transl pat_expr_list
  | Recursive ->
      let idlist =
        List.map
          (fun (pat, expr) -> 
            match pat.pat_desc with
              Tpat_var id -> id
            | _ -> raise(Error(pat.pat_loc, Illegal_letrec_pat)))
        pat_expr_list in
      let transl_case (pat, expr) id =
        let lam = transl_exp expr in
        if not (check_recursive_lambda idlist lam) then
          raise(Error(expr.exp_loc, Illegal_letrec_expr));
        (id, lam) in
      Lletrec(List.map2 transl_case pat_expr_list idlist, body)

@

\subsubsection{Closures}

<<function [[Closure.close]]>>=
let rec close fenv cenv = function
    Lvar id ->
      (close_var cenv id, approx_var fenv id)
  | Lconst cst ->
      (Uconst cst, Value_unknown)
  | Lfunction(kind, params, body) as funct ->
      close_one_function fenv cenv (Ident.create "fun") funct
  | Lapply(funct, args) ->
      let nargs = List.length args in
      begin match (close fenv cenv funct, close_list fenv cenv args) with
        ((ufunct, Value_closure(fundesc, approx_res)),
         [Uprim(Pmakeblock(_, _), uargs)])
        when List.length uargs = - fundesc.fun_arity ->
          (direct_apply fundesc funct ufunct uargs, approx_res)
      | ((ufunct, Value_closure(fundesc, approx_res)), uargs)
        when nargs = fundesc.fun_arity ->
          (direct_apply fundesc funct ufunct uargs, approx_res)
      | ((ufunct, Value_closure(fundesc, approx_res)), uargs)
        when fundesc.fun_arity > 0 && nargs > fundesc.fun_arity ->
          let (first_args, rem_args) = split_list fundesc.fun_arity uargs in
          (Ugeneric_apply(direct_apply fundesc funct ufunct first_args,
                          rem_args),
           Value_unknown)
      | ((ufunct, _), uargs) ->
          (Ugeneric_apply(ufunct, uargs), Value_unknown)
      end
  | Llet(str, id, lam, body) ->
      let (ulam, alam) = close_named fenv cenv id lam in
      let (ubody, abody) = close (Tbl.add id alam fenv) cenv body in
      (Ulet(id, ulam, ubody), abody)
  | Lletrec(defs, body) ->
      if List.for_all
           (function (id, Lfunction(_, _, _)) -> true | _ -> false)
           defs
      then begin
        (* Simple case: only function definitions *)
        let (clos, infos) = close_functions fenv cenv defs in
        let clos_ident = Ident.create "clos" in
        let fenv_body =
          List.fold_right
            (fun (id, pos, approx) fenv -> Tbl.add id approx fenv)
            infos fenv in
        let (ubody, approx) = close fenv_body cenv body in
        (Ulet(clos_ident, clos,
              List.fold_right
                (fun (id, pos, approx) body ->
                    Ulet(id, Uoffset(Uvar clos_ident, pos), body))
                infos ubody),
         approx)
      end else begin
        (* General case: recursive definition of values *)
        let rec clos_defs = function
          [] -> ([], fenv)
        | (id, lam) :: rem ->
            let (udefs, fenv_body) = clos_defs rem in
            let (ulam, approx) = close fenv cenv lam in
            ((id, ulam) :: udefs, Tbl.add id approx fenv_body) in
        let (udefs, fenv_body) = clos_defs defs in
        let (ubody, approx) = close fenv_body cenv body in
        (Uletrec(udefs, ubody), approx)
      end
  | Lprim(Pgetglobal id, []) ->
      (Uprim(Pgetglobal id, []), Compilenv.global_approx id)
  | Lprim(Pmakeblock(tag, mut) as prim, lams) ->
      let (ulams, approxs) = List.split (List.map (close fenv cenv) lams) in
      (Uprim(prim, ulams),
       begin match mut with
           Immutable -> Value_tuple(Array.of_list approxs)
         | Mutable -> Value_unknown
       end)
  | Lprim(Pfield n, [lam]) ->
      let (ulam, approx) = close fenv cenv lam in
      (Uprim(Pfield n, [ulam]),
       match approx with
           Value_tuple a when n < Array.length a -> a.(n)
         | _ -> Value_unknown)
  | Lprim(Psetfield(n, _), [Lprim(Pgetglobal id, []); lam]) ->
      let (ulam, approx) = close fenv cenv lam in
      (!global_approx).(n) <- approx;
      (Uprim(Psetfield(n, false), [Uprim(Pgetglobal id, []); ulam]),
       Value_unknown)
  | Lprim(p, args) ->
      (Uprim(p, close_list fenv cenv args), Value_unknown)
  | Lswitch(arg, sw) ->
      let (uarg, _) = close fenv cenv arg in
      let (const_index, const_cases) =
        close_switch fenv cenv sw.sw_numconsts sw.sw_consts in
      let (block_index, block_cases) =
        close_switch fenv cenv sw.sw_numblocks sw.sw_blocks in
      (Uswitch(uarg, 
               {us_index_consts = const_index;
                us_cases_consts = const_cases;
                us_index_blocks = block_index;
                us_cases_blocks = block_cases;
                us_checked = sw.sw_checked}),
       Value_unknown)
  | Lstaticfail ->
      (Ustaticfail, Value_unknown)
  | Lcatch(body, handler) ->
      let (ubody, _) = close fenv cenv body in
      let (uhandler, _) = close fenv cenv handler in
      (Ucatch(ubody, uhandler), Value_unknown)
  | Ltrywith(body, id, handler) ->
      let (ubody, _) = close fenv cenv body in
      let (uhandler, _) = close fenv cenv handler in
      (Utrywith(ubody, id, uhandler), Value_unknown)
  | Lifthenelse(arg, ifso, ifnot) ->
      let (uarg, _) = close fenv cenv arg in
      let (uifso, _) = close fenv cenv ifso in
      let (uifnot, _) = close fenv cenv ifnot in
      (Uifthenelse(uarg, uifso, uifnot), Value_unknown)
  | Lsequence(lam1, lam2) ->
      let (ulam1, _) = close fenv cenv lam1 in
      let (ulam2, approx) = close fenv cenv lam2 in
      (Usequence(ulam1, ulam2), approx)
  | Lwhile(cond, body) ->
      let (ucond, _) = close fenv cenv cond in
      let (ubody, _) = close fenv cenv body in
      (Uwhile(ucond, ubody), Value_unknown)
  | Lfor(id, lo, hi, dir, body) ->
      let (ulo, _) = close fenv cenv lo in
      let (uhi, _) = close fenv cenv hi in
      let (ubody, _) = close fenv cenv body in
      (Ufor(id, ulo, uhi, dir, ubody), Value_unknown)
  | Lassign(id, lam) ->
      let (ulam, _) = close fenv cenv lam in
      (Uassign(id, ulam), Value_unknown)
  | Levent _ -> assert false

and close_list fenv cenv = function
    [] -> []
  | lam :: rem ->
      let (ulam, _) = close fenv cenv lam in
      ulam :: close_list fenv cenv rem

and close_named fenv cenv id = function
    Lfunction(kind, params, body) as funct ->
      close_one_function fenv cenv id funct
  | lam ->
      close fenv cenv lam

(* Build a shared closure for a set of mutually recursive functions *)

and close_functions fenv cenv fun_defs =
  (* Determine the free variables of the functions *)
  let fv =
    IdentSet.elements (free_variables (Lletrec(fun_defs, lambda_unit))) in
  (* Build the function descriptors for the functions.
     Initially all functions are assumed not to need their environment
     parameter. *)
  let uncurried_defs =
    List.map
      (function
          (id, (Lfunction(kind, params, body) as def)) ->
            let label =
              Compilenv.current_unit_name() ^ "_" ^ Ident.unique_name id in
            let arity = List.length params in
            let fundesc =
              {fun_label = label;
               fun_arity = (if kind = Tupled then -arity else arity);
               fun_closed = true;
               fun_inline = None } in
            (id, params, body, fundesc)
        | (_, _) -> fatal_error "Closure.close_functions")
      fun_defs in
  (* Build an approximate fenv for compiling the functions *)
  let fenv_rec =
    List.fold_right
      (fun (id, params, body, fundesc) fenv ->
        Tbl.add id (Value_closure(fundesc, Value_unknown)) fenv)
      uncurried_defs fenv in
  (* Determine the offsets of each function's closure in the shared block *)
  let env_pos = ref (-1) in
  let clos_offsets =
    List.map
      (fun (id, params, body, fundesc) ->
        let pos = !env_pos + 1 in
        env_pos := !env_pos + 1 + (if fundesc.fun_arity <> 1 then 3 else 2);
        pos)
      uncurried_defs in
  let fv_pos = !env_pos in
  (* This reference will be set to false if the hypothesis that a function
     does not use its environment parameter is invalidated. *)
  let useless_env = ref true in
  (* Translate each function definition *)
  let clos_fundef (id, params, body, fundesc) env_pos =
    let env_param = Ident.create "env" in
    let cenv_fv =
      build_closure_env env_param (fv_pos - env_pos) fv in
    let cenv_body =
      List.fold_right2
        (fun (id, params, arity, body) pos env ->
          Tbl.add id (Uoffset(Uvar env_param, pos - env_pos)) env)
        uncurried_defs clos_offsets cenv_fv in
    let (ubody, approx) = close fenv_rec cenv_body body in
    if !useless_env & occurs_var env_param ubody then useless_env := false;
    let fun_params = if !useless_env then params else params @ [env_param] in
    ((fundesc.fun_label, fundesc.fun_arity, fun_params, ubody),
     (id, env_pos, Value_closure(fundesc, approx))) in
  (* Translate all function definitions. *)
  let clos_info_list = 
    let cl = List.map2 clos_fundef uncurried_defs clos_offsets in
    (* If the hypothesis that the environment parameters are useless has been
       invalidated, then set [fun_closed] to false in all descriptions and
       recompile *)
    if !useless_env then cl else begin
      List.iter
        (fun (id, params, body, fundesc) -> fundesc.fun_closed <- false)
        uncurried_defs;
      List.map2 clos_fundef uncurried_defs clos_offsets
    end in
  (* Return the Uclosure node and the list of all identifiers defined,
     with offsets and approximations. *)
  let (clos, infos) = List.split clos_info_list in
  (Uclosure(clos, List.map (close_var cenv) fv), infos)

(* Same, for one non-recursive function *)

and close_one_function fenv cenv id funct =
  match close_functions fenv cenv [id, funct] with
      ((Uclosure([_, _, params, body], _) as clos),
       [_, _, (Value_closure(fundesc, _) as approx)]) ->
        (* See if the function can be inlined *)
        if lambda_smaller body (!Clflags.inline_threshold + List.length params)
        then fundesc.fun_inline <- Some(params, body);
        (clos, approx)
    | _ -> fatal_error "Closure.close_one_function"

(* Close a switch *)

and close_switch fenv cenv num_keys cases =
  let index = Array.create num_keys 0 in
  let ucases = ref []
  and num_cases = ref 0 in
  if List.length cases < num_keys then begin
    num_cases := 1;
    ucases := [Ustaticfail]
  end;
  List.iter
    (function (key, lam) ->
        let (ulam, _) = close fenv cenv lam in
        ucases := ulam :: !ucases;
        index.(key) <- !num_cases;
        incr num_cases)
    cases;
  (index, Array.of_list(List.rev !ucases))
@
% lots of boilerplate? deriving would help? factorize code?

<<signature [[Ident.unique_name]]>>=
val unique_name: t -> string
@
<<function [[Ident.unique_name]]>>=
let unique_name i = 
  i.name ^ "_" ^ string_of_int i.stamp
@


\subsection{Modules, [[transl_implementation()]]}
%Translmod

<<signature [[Translmod.transl_implementation]]>>=
val transl_implementation: 
  string -> Typedtree.structure -> module_coercion -> lambda
@

<<signature [[Translmod.transl_store_implementation]]>>=
val transl_store_implementation:
      string -> Typedtree.structure -> module_coercion -> int * lambda
@
%? variant?


\subsection{Other elements}

<<signature [[Translcore.transl_exception]]>>=
val transl_exception: Ident.t -> exception_declaration -> lambda
@

\section{Lambda simplifications}

<<signature [[Simplif.simplify_lambda]]>>=
val simplify_lambda: lambda -> lambda
@

%(* Elimination of useless Llet(Alias) bindings.
%   Also transform let-bound references into variables. *)

\section{Pattern matching compilation}

%(*  See Peyton-Jones, "The Implementation of functional programming
%    languages", chapter 5. *)


<<signature [[Matching.for_multiple_match]]>>=
val for_multiple_match:
        Location.t -> lambda list -> (pattern * lambda) list -> lambda
@
% main one no?


<<signature [[Matching.for_function]]>>=
val for_function:
        Location.t -> int ref option -> lambda -> (pattern * lambda) list ->
        lambda
@

<<signature [[Matching.for_trywith]]>>=
val for_trywith:
        lambda -> (pattern * lambda) list -> lambda
@

<<signature [[Matching.for_let]]>>=
val for_let:
        Location.t -> lambda -> pattern -> lambda -> lambda
@


<<signature [[Matching.for_tupled_function]]>>=
val for_tupled_function:
        Location.t -> Ident.t list -> (pattern list * lambda) list -> lambda
@




\section{[[Lambda]] calcul to bytecode [[Instruction]] assembly}

\subsection{[[Instruction]]}
% bytecode assembly?

<<type [[Instruct.label]]>>=
(* Abstract machine instructions *)

type label = int                        (* Symbolic code labels *)
@
% = label like in asm. So now we are closer to Assembler.nw
% than Machine.nw

% =~ Assembly of instruction set in instruct.h
<<type [[Instruct.instruction]]>>=
type instruction =
    Klabel of label

  | Kacc of int
  | Kenvacc of int
  | Kpush
  | Kpop of int
  | Kassign of int

  | Kpush_retaddr of label
  | Kapply of int                       (* number of arguments *)
  | Kappterm of int * int               (* number of arguments, slot size *)
  | Kreturn of int                      (* slot size *)
  | Krestart
  | Kgrab of int                        (* number of arguments *)
  | Kclosure of label * int
  | Kclosurerec of label * int

  | Kgetglobal of Ident.t
  | Ksetglobal of Ident.t

  | Kconst of structured_constant
  | Kmakeblock of int * int             (* size, tag *)
  | Kgetfield of int
  | Ksetfield of int

  | Kdummy of int                       (* block size *)
  | Kupdate of int                      (* block size *)

  | Kvectlength
  | Kgetvectitem
  | Ksetvectitem

  | Kgetstringchar
  | Ksetstringchar

  | Kbranch of label
  | Kbranchif of label
  | Kbranchifnot of label
  | Kstrictbranchif of label
  | Kstrictbranchifnot of label
  | Kswitch of label array * label array
  | Kboolnot

  | Kpushtrap of label
  | Kpoptrap
  | Kraise
  | Kcheck_signals

  | Kccall of string * int

  | Knegint | Kaddint | Ksubint | Kmulint | Kdivint | Kmodint
  | Kandint | Korint | Kxorint | Klslint | Klsrint | Kasrint
  | Kintcomp of comparison

  | Koffsetint of int
  | Koffsetref of int

  | Kisint

  | Kevent of debug_event
  | Kstop
@

<<signature [[Instruct.immed_min]]>>=
val immed_min: int
@
% ?
<<signature [[Instruct.immed_max]]>>=
val immed_max: int
@
% ?

\subsection{[[Bytegen.compile_implementation()]]}

<<signature [[Bytegen.compile_implementation]]>>=
val compile_implementation: string -> lambda -> instruction list
@

\section{Bytecode assembly to bytecode object}

\subsection{Bytecode object format, [[.cmo]]}
% there is also Bytecode binary format which is very different

%(* Format of a .cmo file:
%     magic number (Config.cmo_magic_number)
%     absolute offset of compilation unit descriptor
%     block of relocatable bytecode
%     compilation unit descriptor *)

<<type [[Emitcode.compilation_unit]]>>=
(* Descriptor for compilation units *)

type compilation_unit =
  { cu_name: string;                    (* Name of compilation unit *)
    mutable cu_pos: int;                (* Absolute position in file *)
    cu_codesize: int;                   (* Size of code block *)
    cu_reloc: (reloc_info * int) list;  (* Relocation information *)
    cu_imports: (string * Digest.t) list; (* Names and CRC of intfs imported *)
    cu_primitives: string list;         (* Primitives declared inside *)

    mutable cu_force_link: bool;        (* Must be linked even if unref'ed *)

    mutable cu_debug: int;              (* Position of debugging info, or 0 *)
    cu_debugsize: int;                  (* Length of debugging info *)
 }
@
%todo: LP split

<<type [[Emitcode.reloc_info]]>>=
(* Relocation information *)

type reloc_info =
    Reloc_literal of structured_constant    (* structured constant *)
  | Reloc_getglobal of Ident.t              (* reference to a global *)
  | Reloc_setglobal of Ident.t              (* definition of a global *)
  | Reloc_primitive of string               (* C primitive number *)
@

% relocation! just like in a regular assembler/linker



\subsection{[[Emitcode.to_file()]]}

<<signature [[Emitcode.to_file]]>>=
(* Format of a .cmo file:
     magic number (Config.cmo_magic_number)
     absolute offset of compilation unit descriptor
     block of relocatable bytecode
     compilation unit descriptor *)

val to_file: out_channel -> string -> instruction list -> unit
        (* Arguments:
             channel on output file
             name of compilation unit implemented
             list of instructions to emit *)
@


<<function [[Emitcode.to_file]]>>=
(* Emission to a file *)

let to_file outchan unit_name code =
  init();

  output_string outchan cmo_magic_number;
  let pos_depl = pos_out outchan in
  output_binary_int outchan 0;
  let pos_code = pos_out outchan in
  emit code;
  output outchan !out_buffer 0 !out_position;
  let (pos_debug, size_debug) =
    if !Clflags.debug then begin
      let p = pos_out outchan in
      output_value outchan !events;
      (p, pos_out outchan - p)
    end else
      (0, 0) 
  in
  let compunit =
    { cu_name = unit_name;
      cu_pos = pos_code;
      cu_codesize = !out_position;
      cu_reloc = List.rev !reloc_info;
      cu_imports = Env.imported_units();
      cu_primitives = !Translmod.primitive_declarations;
      cu_force_link = false;
      cu_debug = pos_debug;
      cu_debugsize = size_debug } in
  init();                               (* Free out_buffer and reloc_info *)
(*  Btype.cleanup_abbrev ();*)              (* Remove any cached abbreviation
                                           expansion before saving *)
  let pos_compunit = pos_out outchan in
  output_value outchan compunit;
  seek_out outchan pos_depl;
  output_binary_int outchan pos_compunit
@

<<signature [[Config.cmo_magic_number]]>>=
val cmo_magic_number: string
        (* Magic number for object bytecode files *)
@



<<function [[Emitcode.init]]>>=
(* Initialization *)

let init () =
  out_position := 0;
  label_table := Array.create 16 (Label_undefined []);
  reloc_info := [];
  events := []
@

<<constant [[Emitcode.label_table]]>>=
let label_table  = ref ([| |] : label_definition array)
@

<<constant [[Emitcode.reloc_info]]>>=
(* Relocation information *)

let reloc_info = ref ([] : (reloc_info * int) list)
@


<<signature [[Env.imported_units]]>>=
(* Return the set of compilation units imported, with their CRC *)

val imported_units: unit -> (string * Digest.t) list
@
% it's for the linker, this will be saved in the .cmo, so one
% can know all the .cmi that were required to typecheck and produce
% this .cmo
<<constant [[Env.imported_units]]>>=
let imported_units = ref ([] : (string * Digest.t) list)
@
<<function [[Env.imported_units]]>>=
(* Return the list of imported interfaces with their CRCs *)
let imported_units() = !imported_units
@

<<[[Env.find_pers_struct()]] hook when read Name.cmi and its crc>>=
imported_units := (name, crc) :: !imported_units;
@




\chapter{Linking}

<<[[Main.process_file()]] cases>>=
| _ when Filename.check_suffix name ".cmo" 
      or Filename.check_suffix name ".cma" ->
    objfiles := name :: !objfiles
@


% reput section on linking in the main() chapter
% and the call to bytelink.link()

% linking principles: aggregate the bytecodes in the different .cmo
% (load and put next to each other), link use to def and relocate
% jmps.

<<type [[Bytelink.link_action]]>>=
type link_action =
    Link_object of string * Emitcode.compilation_unit
      (* Name of .cmo file and descriptor of the unit *)
  | Link_archive of string * Emitcode.compilation_unit list
      (* Name of .cma file and descriptors of the units to be linked. *)
@


\section{Bytecode executable format [[.byte]]}

<<exec.h toplevel comment>>=
/*  offset 0 --->  initial junk

                   code block
                   names of primitives
                   data block
                   symbol table
                   debug infos

                   trailer
 end of file --->
*/
@

<<struct [[exec_trailer]]>>=
struct exec_trailer {
  unsigned int code_size;      /* Size of the code block (in bytes) */
  unsigned int prim_size;      /* Size of the primitive table (in bytes) */
  unsigned int data_size;      /* Size of the global data table (bytes) */
  unsigned int symbol_size;    /* Size of the symbol table (bytes) */
  unsigned int debug_size;     /* Size of the debug infos (bytes) */
  char magic[12];              /* A magic string */
};
@
% will talk later about debug infos table

<<constant [[TRAILER_SIZE]]>>=
/* Structure of the trailer.
   Sizes are 32-bit unsigned integers, big endian */

#define TRAILER_SIZE (5*4+12)
@

<<constant [[EXEC_MAGIC]]>>=
/* Magic number for this release */

#define EXEC_MAGIC "Caml1999X002"
@


% opcode.opXxx generated automatically from instruct.h?

\section{Basic linking}

<<signature [[Bytelink.link]]>>=
(* Link .cmo/.cma files and produce a bytecode executable. *)

val link: string list -> unit
@

% main -> <>
<<function [[Bytelink.link]]>>=
(* Main entry point (build a custom runtime if needed) *)

let link objfiles =
  let objfiles = "stdlib.cma" :: (objfiles @ ["std_exit.cmo"]) in
  (match () with
  | _ when !Clflags.output_c -> 
      let c_file =
        Filename.chop_suffix !Clflags.object_name Config.ext_obj ^ ".c" in
      (try
        link_bytecode_as_c_bis objfiles c_file;
      with x ->
        remove_file c_file;
        raise x
      )

  | _ when not !Clflags.custom_runtime && not !Clflags.output_c_object  ->
      link_bytecode objfiles !Clflags.exec_name (*copy_header*)true
  | _ when not !Clflags.output_c_object ->
      <<[[Bytelink.link()]] if custom runtime>>
  | _ ->
      <<[[Bytelink.link()]] if output obj>>
  )
@
% I added the not output_c_object in the first case. I think it's needed


<<function [[Bytelink.link_bytecode]]>>=
(* Create a bytecode executable file *)

let link_bytecode objfiles exec_name copy_header =
  let tolink = List.fold_right scan_file objfiles [] in
  let outchan = open_out_gen [Open_wronly; Open_trunc; Open_creat]
                             0o777 exec_name in
  try
    (* Copy the header *)
    <<[[link_bytecode()]] copy header>>

    (* The bytecode *)
    <<[[link_bytecode()]] set pos1 and generate bytecode>>

    (* The names of all primitives *)
    <<[[link_bytecode()]] set pos2 and generate primitives>>

    (* The table of global data *)
    <<[[link_bytecode()]] set pos3 and generate global data>>

    (* The map of global identifiers *)
    <<[[link_bytecode()]] set pos4 and generate symbol table>>

    (* Debug info *)
    <<[[link_bytecode()]] set pos5 and generate debug infos>>

    (* The trailer *)
    let pos6 = pos_out outchan in
    output_binary_int outchan (pos2 - pos1);
    output_binary_int outchan (pos3 - pos2);
    output_binary_int outchan (pos4 - pos3);
    output_binary_int outchan (pos5 - pos4);
    output_binary_int outchan (pos6 - pos5);
    output_string outchan exec_magic_number;
    close_out outchan

  with x ->
    close_out outchan;
    remove_file exec_name;
    raise x
@

<<signature [[Config.exec_magic_number]]>>=
val exec_magic_number: string
        (* Magic number for bytecode executable files *)
@


<<function [[Bytelink.scan_file]]>>=
let scan_file obj_name tolink =
  let file_name =
    try
      find_in_path !load_path obj_name
    with Not_found ->
      raise(Error(File_not_found obj_name)) in
  let ic = open_in file_name in
  try
    let buffer = Bytes.create (String.length Config.cmo_magic_number) in
    really_input ic buffer 0 (String.length Config.cmo_magic_number);
    match buffer with
    | _ when Bytes.to_string buffer = Config.cmo_magic_number ->
      (* This is a .cmo file. It must be linked in any case.
         Read the relocation information to see which modules it
         requires. *)
      let compunit_pos = input_binary_int ic in  (* Go to descriptor *)
      seek_in ic compunit_pos;
      let compunit = (input_value ic : compilation_unit) in
      close_in ic;
      List.iter add_required compunit.cu_reloc;
      Link_object(file_name, compunit) :: tolink

    | _ when Bytes.to_string buffer = cma_magic_number ->
      (* This is an archive file. Each unit contained in it will be linked
         in only if needed. *)
      let pos_toc = input_binary_int ic in    (* Go to table of contents *)
      seek_in ic pos_toc;
      let toc = (input_value ic : compilation_unit list) in
      close_in ic;
      let required =
        List.fold_right
          (fun compunit reqd ->
            if compunit.cu_force_link
            <<[[Bytelink.scan_file()]] in archive case, linking condition>>
            || List.exists is_required compunit.cu_reloc
            then begin
              List.iter remove_required compunit.cu_reloc;
              List.iter add_required compunit.cu_reloc;
              compunit :: reqd
            end else
              reqd)
          toc [] 
      in
      Link_archive(file_name, required) :: tolink
    | _ -> raise(Error(Not_an_object_file file_name))
  with x ->
    close_in ic; raise x
@
%todo: aspectize cma

\subsection{Bytecode}

<<[[link_bytecode()]] set pos1 and generate bytecode>>=
let pos1 = pos_out outchan in
Symtable.init();
Hashtbl.clear crc_interfaces;

let output_fun = output_string outchan
and currpos_fun () = pos_out outchan - pos1 in

tolink |> List.iter (link_file output_fun currpos_fun);

(* The final STOP instruction *)
output_byte outchan Opcodes.opSTOP;
output_byte outchan 0; output_byte outchan 0; output_byte outchan 0;
@
% Symtable.init() will also initialize c_prim_table using Runtimedef

<<function [[Bytelink.link_file]]>>=
(* Link in a .cmo or .cma file *)

let link_file output_fun currpos_fun = function
    Link_object(file_name, unit) ->
      link_object output_fun currpos_fun file_name unit
  | Link_archive(file_name, units) ->
      link_archive output_fun currpos_fun file_name units
@
%todo: aspectize cma

<<function [[Bytelink.link_object]]>>=
(* Link in a .cmo file *)

let link_object output_fun currpos_fun file_name compunit =
  let inchan = open_in file_name in
  try
    link_compunit output_fun currpos_fun inchan file_name compunit;
    close_in inchan
  with
    Symtable.Error msg ->
      close_in inchan; raise(Error(Symbol_error(file_name, msg)))
  | x ->
      close_in inchan; raise x
@

% link_object -> <>
<<function [[Bytelink.link_compunit]]>>=
(* Link in a compilation unit *)
(* pad: todo? was bytes -> unit in original 4.02 code *)
let link_compunit (output_fun : string -> unit) currpos_fun inchan file_name compunit =
  check_consistency file_name compunit;
  seek_in inchan compunit.cu_pos;
  let code_block = Bytes.create compunit.cu_codesize in
  really_input inchan code_block 0 compunit.cu_codesize;
  Symtable.patch_object code_block compunit.cu_reloc;

  if !Clflags.debug && compunit.cu_debug > 0 then begin
    seek_in inchan compunit.cu_debug;
    let buffer = Bytes.create compunit.cu_debugsize in
    really_input inchan buffer 0 compunit.cu_debugsize;
    debug_info := (currpos_fun(), Bytes.to_string buffer) :: !debug_info
  end;
  output_fun (Bytes.to_string code_block);
  <<[[Bytelink.link_compunit()]] if link everything require primitives>>
@

% Patch object! relocation

\subsection{Primitives table}

% Set first in Symtable.init above.
% Augmented when reading object files???

<<[[link_bytecode()]] set pos2 and generate primitives>>=
let pos2 = pos_out outchan in
Symtable.output_primitive_names outchan;
@

% we let the host linker to do the work when building ocamlrun.
% we only need to agree on the primitive table, and the
% file prims.c

<<signature [[Symtable.output_primitive_names]]>>=
val output_primitive_names: out_channel -> unit
@


<<function [[Symtable.output_primitive_names]]>>=
let output_primitive_names outchan =
  let prim = all_primitives() in
  for i = 0 to Array.length prim - 1 do
    output_string outchan prim.(i); output_char outchan '\000'
  done
@
% This is just for debugging? 



\subsection{Globals table}

<<[[link_bytecode()]] set pos3 and generate global data>>=
let pos3 = pos_out outchan in
output_value outchan (Symtable.initial_global_table());
@

<<signature [[Symtable.initial_global_table]]>>=
val initial_global_table: unit -> Obj.t array
@

<<function [[Symtable.initial_global_table]]>>=
(* Build the initial table of globals *)

let initial_global_table () =
  let glob = Array.create !global_table.num_cnt (Obj.repr 0) in
  List.iter
    (fun (slot, cst) -> glob.(slot) <- transl_const cst)
    !literal_table;
  literal_table := [];
  glob
@


\subsection{Symbols table}

<<[[link_bytecode()]] set pos4 and generate symbol table>>=
let pos4 = pos_out outchan in
Symtable.output_global_map outchan;
@

<<function [[Symtable.output_global_map]]>>=
(* Save the table of globals *)

let output_global_map oc =
  output_value oc !global_table
@


%\subsection{Debug infos}
% later


\section{Safe linking}

<<signature [[Bytelink.check_consistency]]>>=
val check_consistency: string -> Emitcode.compilation_unit -> unit
@

<<constant [[Bytelink.crc_interfaces]]>>=
(* Consistency check between interfaces *)

let crc_interfaces =
  (Hashtbl.create 17 : (string, string * Digest.t) Hashtbl.t)
@

<<function [[Bytelink.check_consistency]]>>=
let check_consistency file_name cu =
  List.iter
    (fun (name, crc) ->
      if name = cu.cu_name then begin
        Hashtbl.add crc_interfaces name (file_name, crc)
      end else begin
        try
          let (auth_name, auth_crc) = Hashtbl.find crc_interfaces name in
          if crc <> auth_crc then
            raise(Error(Inconsistent_import(name, file_name, auth_name)))
        with Not_found ->
          (* Can only happen for unit for which only a .cmi file was used,
             but no .cmo is provided *)
          Hashtbl.add crc_interfaces name (file_name, crc)
      end)
    cu.cu_imports
@

\section{Archives}


<<constant [[Clflags.include_dirs]]>>=
let include_dirs = ref ([] : string list)(* -I *)
@
<<[[Main.main()]] command line options>>=
"-I", Arg.String(fun dir -> include_dirs := dir :: !include_dirs),
      "<dir>  Add <dir> to the list of include directories";
@
% to find the .cma









\subsection{Archive format, [[.cma]]}

%(* Format of a library file:
%      magic number (Config.cma_magic_number)
%      absolute offset of content table
%      blocks of relocatable bytecode
%      content table = list of compilation units
%*)

<<signature [[Config.cma_magic_number]]>>=
val cma_magic_number: string
        (* Magic number for archive files *)
@

\subsection{Creating an archive}

<<constant [[Clflags.make_archive]]>>=
let make_archive = ref false            (* -a *)
@
<<[[Main.main()]] command line options>>=
"-a", Arg.Set make_archive, " Build a library";
@

<<constant [[Clflags.archive_name]]>>=
let archive_name = ref "library.cma"    (* -o *)
@


<<[[Main.main()]] if make archive case>>=
| _ when !make_archive ->
    Compile.init_path();
    Bytelibrarian.create_archive (List.rev !objfiles) !archive_name
@


<<signature [[Bytelibrarian.create_archive]]>>=
(* Format of a library file:
      magic number (Config.cma_magic_number)
      absolute offset of content table
      blocks of relocatable bytecode
      content table = list of compilation units
*)
val create_archive: string list -> string -> unit
@


<<function [[Bytelibrarian.create_archive]]>>=
let create_archive file_list lib_name =
  let outchan = open_out lib_name in
  try
    output_string outchan cma_magic_number;
    let ofs_pos_toc = pos_out outchan in
    output_binary_int outchan 0;
    let toc = List.flatten(List.map (copy_object_file outchan) file_list) in
    let pos_toc = pos_out outchan in
    output_value outchan toc;
    seek_out outchan ofs_pos_toc;
    output_binary_int outchan pos_toc;
    close_out outchan
  with x ->
    close_out outchan;
    remove_file lib_name;
    raise x
@


% create_archive -> <>
<<function [[Bytelibrarian.copy_object_file]]>>=
let copy_object_file oc name =
  let file_name =
    try
      find_in_path !load_path name
    with Not_found ->
      raise(Error(File_not_found name)) in
  let ic = open_in file_name in
  try
    let buffer = Bytes.create (String.length cmo_magic_number) in
    really_input ic buffer 0 (String.length cmo_magic_number);
    if Bytes.to_string buffer = cmo_magic_number then begin
      let compunit_pos = input_binary_int ic in
      seek_in ic compunit_pos;
      let compunit = (input_value ic : compilation_unit) in
      copy_compunit ic oc compunit;
      close_in ic;
      [compunit]
    end else
    if Bytes.to_string buffer = cma_magic_number then begin
      let toc_pos = input_binary_int ic in
      seek_in ic toc_pos;
      let toc = (input_value ic : compilation_unit list) in
      List.iter (copy_compunit ic oc) toc;
      close_in ic;
      toc
    end else
      raise(Error(Not_an_object_file file_name))
  with x ->
    close_in ic;
    raise x
@

% copy_object_file -> <>
<<function [[Bytelibrarian.copy_compunit]]>>=
let copy_compunit ic oc compunit =
  seek_in ic compunit.cu_pos;
  compunit.cu_pos <- pos_out oc;
  <<[[Bytelibrarian.copy_compunit()]] set [[cu_force_link]] if link everything>>
  copy_file_chunk ic oc compunit.cu_codesize;
  if compunit.cu_debug > 0 then begin
    seek_in ic compunit.cu_debug;
    compunit.cu_debug <- pos_out oc;
    copy_file_chunk ic oc compunit.cu_debugsize
  end
@



\subsection{Linking an archive}

<<function [[Bytelink.link_archive]]>>=
(* Link in a .cma file *)

let link_archive output_fun currpos_fun file_name units_required =
  let inchan = open_in file_name in
  try
    units_required |> List.iter (fun cu ->
      let name = file_name ^ "(" ^ cu.cu_name ^ ")" in
      try
        link_compunit output_fun currpos_fun inchan name cu
      with Symtable.Error msg ->
        raise(Error(Symbol_error(name, msg)))
    );
    close_in inchan
  with x -> close_in inchan; raise x
@
%less: with_open_in

\section{Linking with C}

%Chapter 19  Interfacing C with OCaml
%http://caml.inria.fr/pub/docs/manual-ocaml-4.00/manual033.html#c:intf-c

<<constant [[Clflags.ccobjs]]>>=
let ccobjs = ref ([] : string list)     (* .o, .a and -lxxx files *)
@

<<[[Main.process_file()]] cases>>=
| _ when Filename.check_suffix name Config.ext_obj
      or Filename.check_suffix name Config.ext_lib ->
    ccobjs := name :: !ccobjs
@


<<signature [[Config.ext_obj]]>>=
val ext_obj: string
        (* Extension for object files, e.g. [.o] under Unix. *)
@
<<signature [[Config.ext_lib]]>>=
val ext_lib: string
        (* Extension for library files, e.g. [.a] under Unix. *)
@



<<[[Main.main()]] command line options>>=
"-cclib", Arg.String(fun s -> ccobjs := s :: !ccobjs),
      "<opt>  Pass option <opt> to the C linker";
@


\subsection{Foreign function interface}
% ffi

% dont forget  CAMLreturn0;!!
% otherwise local_roots is not restored and so point to
% a local frame that actually has been deallocated.

\subsection{[[-custom]]}

% I put in section about linking with C and not in advanced
% link because you can't really statically link with C and
% not use -custom

%note: it also adds the .so in it no? no, it adds the .a (well
% it calls the linker to build a custom runtime with the standard
% runtime primitives + your new C functions.

<<constant [[Clflags.custom_runtime]]>>=
let custom_runtime = ref false          (* -custom *)
@
<<[[Main.main()]] command line options>>=
"-custom", Arg.Set custom_runtime, " Link in custom mode";
@


<<[[Bytelink.link()]] if custom runtime>>=
let bytecode_name = Filename.temp_file "camlcode" "" in
let prim_name = Filename.temp_file "camlprim" ".c" in
(try
  link_bytecode objfiles bytecode_name (*copy_header*)false;
  let poc = open_out prim_name in
  Symtable.output_primitive_table poc;
  close_out poc;
  let exec_name = fix_exec_name !Clflags.exec_name in
  if build_custom_runtime prim_name exec_name <> 0
  then raise(Error Custom_runtime);
  append_bytecode_and_cleanup bytecode_name exec_name prim_name
with x ->
  remove_file bytecode_name;
  remove_file prim_name;
  raise x
)
@

<<function [[Bytelink.fix_exec_name]]>>=
(* Fix the name of the output file, if the C compiler changes it behind
   our back. *)
let fix_exec_name name =
  match Sys.os_type with
  | _ -> name
@


<<function [[Bytelink.append_bytecode_and_cleanup]]>>=
let append_bytecode_and_cleanup bytecode_name exec_name prim_name =
  match Sys.os_type with
  | _ ->
      let oc = open_out_gen [Open_wronly; Open_append] 0 !Clflags.exec_name in
      let ic = open_in bytecode_name in
      copy_file ic oc;
      close_in ic;
      close_out oc;
      remove_file bytecode_name;
      remove_file prim_name
@


\subsection{Custom primitives table}

\subsection{Calling host command}

\subsection{Calling host linker}


<<function [[Bytelink.build_custom_runtime]]>>=
let build_custom_runtime prim_name exec_name =
  let libname = "libcamlrun" ^ ext_lib in
  let runtime_lib =
    try
      find_in_path !load_path libname
    with Not_found ->
      raise(Error(File_not_found libname)) in
  match Sys.os_type with
    "Unix" ->
      Ccomp.command
       (Printf.sprintf
          "%s -o %s -I%s %s %s -L%s %s %s %s"
          Config.bytecomp_c_compiler
          exec_name
          Config.standard_library
          (String.concat " " (List.rev !Clflags.ccopts))
          prim_name
          Config.standard_library
          (String.concat " " (List.rev !Clflags.ccobjs))
          runtime_lib
          Config.c_libraries)
  | _ ->
    fatal_error "Bytelink.build_custom_runtime"
@

<<signature [[Config.c_libraries]]>>=
val c_libraries: string
        (* The C libraries to link with custom runtimes *)
@



<<signature [[Ccomp.command]]>>=
val command: string -> int
@
% =~ Sys.command + -verbose handling. See appendix.
% Sys.command capture stderr? no.

\subsection{C compilation}


<<[[Main.process_file()]] cases>>=
| _ when Filename.check_suffix name ".c" ->
    Compile.c_file name;
    ccobjs := (Filename.chop_suffix (Filename.basename name) ".c" ^ ext_obj)
     :: !ccobjs
@

<<constant [[Clflags.ccopts]]>>=
let ccopts = ref ([] : string list)     (* -ccopt *)
@

<<[[Main.main()]] command line options>>=
"-ccopt", Arg.String(fun s -> ccopts := s :: !ccopts),
      "<opt>  Pass option <opt> to the C compiler and linker";
@



<<signature [[Compile.c_file]]>>=
val c_file: string -> unit
@

<<function [[Compile.c_file]]>>=
let c_file name =
  if Ccomp.compile_file_bytecode name <> 0 
  then exit 2
@









\subsection{Calling host compiler}

<<signature [[Ccomp.compile_file_bytecode]]>>=
val compile_file_bytecode: string -> int
@

<<function [[Ccomp.compile_file_bytecode]]>>=
let compile_file_bytecode name =
  command
   (Printf.sprintf
     "%s -c %s %s -I%s %s"
     Config.bytecomp_c_compiler
     (String.concat " " (List.rev !Clflags.ccopts))
     (String.concat " "
       (List.map (fun dir -> "-I" ^ dir) 
                 (List.rev !Clflags.include_dirs)))
     Config.standard_library
     name)
@

<<signature [[Config.bytecomp_c_compiler]]>>=
val bytecomp_c_compiler: string
        (* The C compiler to use for the custom runtime mode of the
           bytecode compiler *)
@




<<signature [[Ccomp.compile_file_native]]>>=
val compile_file_native: string -> int
@

<<function [[Ccomp.compile_file_native]]>>=
let compile_file_native name =
  command
   (Printf.sprintf
     "%s -c %s %s -I%s %s"
     Config.native_c_compiler
     (String.concat " " (List.rev !Clflags.ccopts))
     (String.concat " "
       (List.map (fun dir -> "-I" ^ dir) 
                 (List.rev !Clflags.include_dirs)))
     Config.standard_library
     name)
@

<<signature [[Config.native_c_compiler]]>>=
val native_c_compiler: string
        (* The C compiler to use for the native code compiler *)
@


\subsection{Calling host librarian}

<<signature [[Ccomp.create_archive]]>>=
val create_archive: string -> string list -> int
@

% -> <>
<<function [[Ccomp.create_archive]]>>=
let create_archive archive file_list =
  Misc.remove_file archive;
  match Config.system with
  | _ ->
      let r1 =
        command(Printf.sprintf "ar rc %s %s"
                                   archive (String.concat " " file_list)) in
      if r1 <> 0 || String.length Config.ranlib = 0
      then r1
      else command(Config.ranlib ^ " " ^ archive)
@

<<signature [[Config.ranlib]]>>=
val ranlib: string
        (* Command to randomize a library, or "" if not needed *)
@



\section{Advanced linking issues}


\subsection{[[-linkall]]}

<<constant [[Clflags.link_everything]]>>=
let link_everything = ref false         (* -linkall *)
@
<<[[Main.main()]] command line options>>=
"-linkall", Arg.Set link_everything,
      " Link all modules, even unused ones";
@

% useful for modules that are plugins, like mmm/Viewers/plain.ml,
% or efuns/prog_modes/caml_mode.ml
% that just add some of its functions to some globals.
% The module may appear unused from the outside, but it has some
% important side effects!


<<[[Bytelink.scan_file()]] in archive case, linking condition>>=
|| !Clflags.link_everything
@
% just for archive.
% hmm I though that that in recent ocaml it was also doing that for .cmo


<<[[Bytelibrarian.copy_compunit()]] set [[cu_force_link]] if link everything>>=
compunit.cu_force_link <- !Clflags.link_everything;
@
% if compile library with -linkall itself, then it will propagate

<<[[Bytelink.link_compunit()]] if link everything require primitives>>=
if !Clflags.link_everything 
then compunit.cu_primitives |> List.iter Symtable.require_primitive
@
% ?


\subsection{[[-output-obj]]}

% convenient if want to load ocaml code from a kernel :)

<<constant [[Clflags.object_name]]>>=
let object_name = ref ("camlprog" ^ Config.ext_obj) (* -o *)
@
%camlprog??

<<constant [[Clflags.output_c_object]]>>=
let output_c_object = ref false         (* -output-obj *)
@
%??

<<[[Main.main()]] command line options>>=
"-output-obj", Arg.Unit(fun () -> output_c_object := true;
                                  custom_runtime := true),
      "Output a C object file instead of an executable";
@


<<[[Bytelink.link()]] if output obj>>=
let c_file =
  Filename.chop_suffix !Clflags.object_name Config.ext_obj ^ ".c" in
if Sys.file_exists c_file then raise(Error(File_exists c_file));
(try
  link_bytecode_as_c objfiles c_file;
  if Ccomp.compile_file_bytecode c_file <> 0
  then raise(Error Custom_runtime);
  remove_file c_file
with x ->
  remove_file c_file;
  remove_file !Clflags.object_name;
  raise x
)
@

<<function [[Bytelink.link_bytecode_as_c]]>>=
(* Output a bytecode executable as a C file *)

let link_bytecode_as_c objfiles outfile =
  let tolink = List.fold_right scan_file objfiles [] in
  let outchan = open_out outfile in
  try
    (* The bytecode *)
    output_string outchan "static int caml_code[] = {\n";
    Symtable.init();
    Hashtbl.clear crc_interfaces;
    let output_fun = output_code_string outchan
    and currpos_fun () = fatal_error "Bytelink.link_bytecode_as_c" in
    List.iter (link_file output_fun currpos_fun) tolink;
    (* The final STOP instruction *)
    Printf.fprintf outchan "\n0x%x};\n\n" Opcodes.opSTOP;
    (* The table of global data *)
    output_string outchan "static char * caml_data =\n";
    output_data_string outchan
      (Marshal.to_string (Symtable.initial_global_table()) []);
    (* The table of primitives *)
    Symtable.output_primitive_table outchan;
    (* The entry point *)
    output_string outchan "\n
void caml_startup(argv)
        char ** argv;
{
  caml_startup_code(caml_code, sizeof(caml_code), caml_data, argv);
}\n";
    close_out outchan
  with x ->
    close_out outchan;
    raise x
@


%\subsection{[[-make-runtime]]}
% and -use-runtime, but was not in ocaml 1.07 yet







\chapter{Interpreting}
% Running

% emacs lisp bytecode:
%http://nullprogram.com/blog/2014/01/04/
% survey on efficient interpreters
%https://www.jilp.org/vol5/v5paper12.pdf

% MoarVM?

% Ocaml interpreter step by step:
%https://github.com/johnwhitington/ocamli


<<signature function interprete>>=
value interprete (code_t prog, asize_t prog_size);
@
% have seen value in core DS, typedef long value;

<<typedef [[opcode_t]]>>=
typedef int32 opcode_t;
@
<<typedef [[code_t]]>>=
typedef opcode_t * code_t;
@
% for start of array, or for idx in array

% asize_t is in misc.h = int
% but seems that prog_size is actually not used

\section{[[main()]] (of [[ocamlrun]])}

%/* Main entry point (can be overriden by a user-provided main()
%   function that calls caml_main() later. */

<<function [[main]]>>=
int main(int argc, char **argv)
{
  caml_main(argv);
  sys_exit(Val_int(0));
  return 0; /* not reached */
}
@
% note that having a main() in libcamlrun.a is annoying for 8l.
% I had to patch 8l to force the loading of libcamlrun.a(main.o).


\subsection{[[caml_main()]]}

<<function [[caml_main]]>>=
/* Main entry point when loading code from a file */

void caml_main(char **argv)
{
  int fd;
  struct exec_trailer trail;
  int pos;
  struct longjmp_buffer raise_buf;
  struct channel * chan;

  /* Machine-dependent initialization of the floating-point hardware
     so that it behaves as much as possible as specified in IEEE */
  init_ieee_floats();

  /* Set up a catch-all exception handler */
  if (sigsetjmp(raise_buf.buf, 1) == 0) {
    external_raise = &raise_buf;
    /* Determine options and position of bytecode file */
#ifdef DEBUG
    verbose_init = 1;
#endif
    parse_camlrunparam();
    pos = 0;
    fd = attempt_open(&argv[0], &trail, 0);
    if (fd < 0) {

      pos = parse_command_line(argv);
      if (argv[pos] == 0)
        fatal_error("No bytecode file specified.\n");

      fd = attempt_open(&argv[pos], &trail, 1);
      switch(fd) {
      case FILE_NOT_FOUND:
        fatal_error_arg("Fatal error: cannot find file %s\n", argv[pos]);
        break;
      case BAD_BYTECODE:
        fatal_error_arg(
          "Fatal error: the file %s is not a bytecode executable file\n",
          argv[pos]);
        break;
      }
    }
    /* Initialize the abstract machine */
    init_gc (minor_heap_init, heap_size_init, heap_chunk_init,
             percent_free_init, max_percent_free_init, verbose_init);
    init_stack (max_stack_init);
    init_atoms();

    /* Initialize the interpreter */
    interprete(NULL, 0);

    /* Initialize the debugger, if needed */
    debugger_init();

    /* Load the code */
    lseek(fd, - (long) (TRAILER_SIZE + trail.code_size + trail.prim_size
                        + trail.data_size + trail.symbol_size
                        + trail.debug_size), SEEK_END);
    load_code(fd, trail.code_size);

    /* Check the primitives */
    check_primitives(fd, trail.prim_size);

    /* Load the globals */
    chan = open_descriptor(fd);
    global_data = input_val(chan);
    close_channel(chan); // close also fd
    /* Ensure that the globals are in the major heap. */
    oldify(global_data, &global_data);

    /* Record the command-line arguments */
    sys_init(argv + pos);

    /* Execute the program */
    debugger(PROGRAM_START);

    interprete(start_code, trail.code_size);

  } else {
    if (debugger_in_use) {
      extern_sp = &exn_bucket; /* The debugger needs the exception value. */
      debugger(UNCAUGHT_EXC);
    }
    fatal_uncaught_exception(exn_bucket);
  }
}
@

%\subsection{Command line processing}

<<function [[parse_command_line]]>>=
/* Parse options on the command line */

static int parse_command_line(char **argv)
{
  int i;

  for(i = 1; argv[i] != NULL && argv[i][0] == '-'; i++) {
    switch(argv[i][1]) {
    case 'b':
      init_backtrace();
      break;
    <<[[parse_command_line()]] cases>>
    default:
      fatal_error_arg("Unknown option %s.\n", argv[i]);
    }
  }
  return i;
}
@

\subsection{Bytecode executable format, [[.byte]]}
% again, but this time in C for ocamlrun to read

% see section in linker


\subsection{Loading the executable}

\subsection{Initializing}

\section{[[interpreter()]]}

% todo: maybe do a simpler version of the interpter
% without all those ifdef THREADED_CODE acting
% as a simpler model. Those #else are ugly otherwise.

% // array<opcode>
<<function [[interpreter]]>>=
value interprete(code_t prog, asize_t prog_size)
{
  <<[[interpreter()]] local variables>>

  <<[[interpreter()]] initialisations>>

  <<[[interpreter()]] ifdef [[THREADED_CODE]], loop start>>
  #else
  while(1) {
    <<[[interpreter()]] ifdef [[DEBUG]], loop start>>
    curr_instr = *pc++;
    dispatch_instr:
    switch(curr_instr) {
      #endif /* #else THREADED_CODE */
  
    <<[[interpreter()]] basic stack operations cases>>
    <<[[interpreter()]] env access cases>>
    <<[[interpreter()]] function application cases>>
    <<[[interpreter()]] misc cases>>
    <<[[interpreter()]] global data access cases>>
    <<[[interpreter()]] blocks allocation cases>>
    <<[[interpreter()]] blocks access cases>>
    <<[[interpreter()]] recursive definition cases>>
    <<[[interpreter()]] branching cases>>
    <<[[interpreter()]] exception cases>>
    <<[[interpreter()]] signal cases>>
    <<[[interpreter()]] foreign c calls cases>>
    <<[[interpreter()]] arithmetics cases>>
    <<[[interpreter()]] array cases>>
    <<[[interpreter()]] string cases>>
    <<[[interpreter()]] debugger cases>>

    #ifndef THREADED_CODE
    default:
      fatal_error_arg("Fatal error: bad opcode (%lx)\n",
                      (char *)(long)(*(pc-1)));
    }
  }
  #endif /* ifndef THREADED_CODE */
}
@
% classic interpreter loop
%note: maybe better to be more explicit in order of switch cases,
% and anyway some cases are really long and you want to subsplit
% them, so easier to name the intermediate chunks.
%note: dispatch_instr seems used only for debugger

%less: reorder and group like for instruct.h?
%coupling? order of labels here must correspond to order
% of instruct.h? is it an assumption for jumptbl.h to work?
% I don't think so.


% there is threaded code and simpler code, with different
% ifdefs, but for explanation purpose we focus on the simpler
% non threaded code
<<constant [[THREADED_CODE]]>>=
#define THREADED_CODE
@
% if does not have gcc first-class labels, can't have THREADED_CODE
% see advanced topics chapter



% when no threaded code
<<macro [[Instruct]]>>=
#  define Instruct(name) case name
@
<<macro [[Next]]>>=
#  define Next break
@



\subsection{Abstract machine registers}

<<interp.c toplevel comment>>=
/* Registers for the abstract machine:
        pc         the code pointer
        sp         the stack pointer (grows downward)
        accu       the accumulator
        env        heap-allocated environment

        trapsp     pointer to the current trap frame
        extra_args number of extra arguments provided by the caller

sp is a local copy of the global variable extern_sp. */
@
% so it's a one register stack machine :) a mix of stack and register
% machine (ok maybe 2 with the env)

<<[[interpreter()]] local variables>>=
<<[[interpreter()]] ifdef [[PC_REG]]>>
#else
register code_t pc;
register value * sp;
register value accu;
#endif
<<[[interpreter()]] ifdef [[THREADED_CODE]], [[jumptbl_base]] register declaration>>
value env;
long extra_args;

#ifndef THREADED_CODE
opcode_t curr_instr;
#endif
<<[[interpreter()]] other local variables>>
@
% the main one!

<<global [[trapsp]]>>=
value * trapsp;
@
% why not a local like for the other?


<<[[interpreter()]] initialisations>>=
<<[[interpreter()]] ifdef [[THREADED_CODE]] initialisations>>
<<[[interpreter()]] [[initial_xxx]] initialisations>>
<<[[interpreter()]] exception initialisations>>

sp = extern_sp;
pc = prog;
extra_args = 0;
env = Atom(0);
accu = Val_int(0);
@
% extern_sp in the sense that it's a global defined elsewhere
% but we have a local copy here.

<<global [[extern_sp]]>>=
value * extern_sp;
@



\subsection{Integer arithmetics}
% it's about the Is_long()
% it's about mainly accu


<<integer arithmetics opcodes>>=
CONSTINT,
@

<<[[interpreter()]] arithmetics cases>>=
/* Integer constants */

    <<[[interpreter()]] before CONSTINT case>>
    Instruct(CONSTINT):
      accu = Val_int(*pc);
      pc++;
      Next;
@

<<integer arithmetics opcodes>>=
  CONST0, CONST1, CONST2, CONST3, 
  PUSHCONSTINT,
  PUSHCONST0, PUSHCONST1, PUSHCONST2, PUSHCONST3, 
@

\ifallcode
<<[[interpreter()]] arithmetics cases>>=
    Instruct(CONST0):
      accu = Val_int(0); Next;
    Instruct(CONST1):
      accu = Val_int(1); Next;
    Instruct(CONST2):
      accu = Val_int(2); Next;
    Instruct(CONST3):
      accu = Val_int(3); Next;

    Instruct(PUSHCONST0):
      *--sp = accu; accu = Val_int(0); Next;
    Instruct(PUSHCONST1):
      *--sp = accu; accu = Val_int(1); Next;
    Instruct(PUSHCONST2):
      *--sp = accu; accu = Val_int(2); Next;
    Instruct(PUSHCONST3):
      *--sp = accu; accu = Val_int(3); Next;
@

<<[[interpreter()]] before CONSTINT case>>=
    Instruct(PUSHCONSTINT):
      *--sp = accu;
      /* Fallthrough */
@
\fi



<<integer arithmetics opcodes>>=
NEGINT, ADDINT, SUBINT, MULINT, DIVINT, MODINT,
@

% builtins! finally, but handling the special int encoding used by ocaml
<<[[interpreter()]] arithmetics cases>>=
/* Integer arithmetic */

    Instruct(NEGINT):
      accu = (value)(2 - (long)accu); Next;
    Instruct(ADDINT):
      accu = (value)((long) accu + (long) *sp++ - 1); Next;
    Instruct(SUBINT):
      accu = (value)((long) accu - (long) *sp++ + 1); Next;
    Instruct(MULINT):
      accu = Val_long(Long_val(accu) * Long_val(*sp++)); Next;

    Instruct(DIVINT): {
      long divisor = Long_val(*sp++);
      if (divisor == 0) { Setup_for_c_call; raise_zero_divide(); }
      accu = Val_long(Long_val(accu) / divisor);
      Next;
    }
    Instruct(MODINT): {
      long divisor = Long_val(*sp++);
      if (divisor == 0) { Setup_for_c_call; raise_zero_divide(); }
      accu = Val_long(Long_val(accu) % divisor);
      Next;
    }
@


<<integer arithmetics opcodes>>=
ANDINT, ORINT, XORINT, 
@

<<[[interpreter()]] arithmetics cases>>=
Instruct(ANDINT):
  accu = (value)((long) accu & (long) *sp++); Next;
Instruct(ORINT):
  accu = (value)((long) accu | (long) *sp++); Next;
Instruct(XORINT):
  accu = (value)(((long) accu ^ (long) *sp++) | 1); Next;
@


<<integer arithmetics opcodes>>=
LSLINT, LSRINT, ASRINT,
@

<<[[interpreter()]] arithmetics cases>>=
Instruct(LSLINT):
  accu = (value)((((long) accu - 1) << Long_val(*sp++)) + 1); Next;
Instruct(LSRINT):
  accu = (value)((((unsigned long) accu - 1) >> Long_val(*sp++)) | 1);
  Next;
Instruct(ASRINT):
  accu = (value)((((long) accu - 1) >> Long_val(*sp++)) | 1); Next;
@

<<integer arithmetics opcodes>>=
EQ, NEQ, 
@

<<integer arithmetics opcodes>>=
LTINT, LEINT, GTINT, GEINT,
@


<<[[interpreter()]] arithmetics cases>>=
#define Integer_comparison(opname,tst) \
    Instruct(opname): \
      accu = Val_int((long) accu tst (long) *sp++); Next;

    Integer_comparison(EQ, ==)
    Integer_comparison(NEQ, !=)
    Integer_comparison(LTINT, <)
    Integer_comparison(LEINT, <=)
    Integer_comparison(GTINT, >)
    Integer_comparison(GEINT, >=)
@
% note that this is used only for the compare_int! it's not
% the same as the generic compare that is generic

<<integer arithmetics opcodes>>=
OFFSETINT, OFFSETREF,
@
% ????

<<[[interpreter()]] arithmetics cases>>=
    Instruct(OFFSETINT):
      accu += *pc << 1;
      pc++;
      Next;
    Instruct(OFFSETREF):
      Field(accu, 0) += *pc << 1;
      accu = Val_unit;
      pc++;
      Next;
@
% >> >>


\subsection{Stack operations}

% it's about sp mainly (and accu)

<<basic stack operations opcodes>>=
ACC,
PUSH,
POP, 
ASSIGN,
@
%main one

<<[[interpreter()]] basic stack operations cases>>=
/* Basic stack operations */

    <<[[interpreter()]] basic stack operation before ACC case>>
    Instruct(ACC):
      accu = sp[*pc++];
      Next;
    Instruct(PUSH): Instruct(PUSHACC0):
      *--sp = accu; 
      Next;
    Instruct(POP):
      sp += *pc++;
      Next;
    Instruct(ASSIGN):
      sp[*pc++] = accu;
      accu = Val_unit;
      Next;
@
% need PUSHACC0?



<<basic stack operations opcodes>>=
  ACC0, ACC1, ACC2, ACC3, ACC4, ACC5, ACC6, ACC7,
@

<<[[interpreter()]] basic stack operations cases>>=
    Instruct(ACC0):
      accu = sp[0]; Next;
    Instruct(ACC1):
      accu = sp[1]; Next;
    Instruct(ACC2):
      accu = sp[2]; Next;
    Instruct(ACC3):
      accu = sp[3]; Next;
    Instruct(ACC4):
      accu = sp[4]; Next;
    Instruct(ACC5):
      accu = sp[5]; Next;
    Instruct(ACC6):
      accu = sp[6]; Next;
    Instruct(ACC7):
      accu = sp[7]; Next;
@
%opti: start to see specialized operations, e.g. ACC1 is really
% an ACC and a CONST0 before, but here compressed in one single opcode.

% there will be many XXX[0-9] later


<<basic stack operations opcodes>>=
  PUSHACC0, PUSHACC1, PUSHACC2, PUSHACC3,
  PUSHACC4, PUSHACC5, PUSHACC6, PUSHACC7,
@

<<[[interpreter()]] basic stack operations cases>>=
    Instruct(PUSHACC1):
      *--sp = accu; accu = sp[1]; Next;
    Instruct(PUSHACC2):
      *--sp = accu; accu = sp[2]; Next;
    Instruct(PUSHACC3):
      *--sp = accu; accu = sp[3]; Next;
    Instruct(PUSHACC4):
      *--sp = accu; accu = sp[4]; Next;
    Instruct(PUSHACC5):
      *--sp = accu; accu = sp[5]; Next;
    Instruct(PUSHACC6):
      *--sp = accu; accu = sp[6]; Next;
    Instruct(PUSHACC7):
      *--sp = accu; accu = sp[7]; Next;
@
% start to see composite operations in one opcode, e.g. 
% PUSHACC1 is really a PUSH and an ACC1.
% so faster interpreter. See zinc manual.

<<basic stack operations opcodes>>=
  PUSHACC, 
@

<<[[interpreter()]] basic stack operation before ACC case>>=
    Instruct(PUSHACC):
      *--sp = accu;
      /* Fallthrough */
@
% there will be many PUSHXXX later


\subsection{Environment access}
% environment operations
% Heap operations?

<<env access opcodes>>=
ENVACC,
@

<<[[interpreter()]] env access cases>>=
/* Access in heap-allocated environment */

    <<[[interpreter()]] env access before ENVACC case>>
    Instruct(ENVACC):
      accu = Field(env, *pc++);
      Next;
@


<<env access opcodes>>=
  ENVACC1, ENVACC2, ENVACC3, ENVACC4, 
  PUSHENVACC1, PUSHENVACC2, PUSHENVACC3, PUSHENVACC4, PUSHENVACC,
@

\ifallcode

<<[[interpreter()]] env access cases>>=
    Instruct(ENVACC1):
      accu = Field(env, 1); Next;
    Instruct(ENVACC2):
      accu = Field(env, 2); Next;
    Instruct(ENVACC3):
      accu = Field(env, 3); Next;
    Instruct(ENVACC4):
      accu = Field(env, 4); Next;

    Instruct(PUSHENVACC1):
      *--sp = accu; accu = Field(env, 1); Next;
    Instruct(PUSHENVACC2):
      *--sp = accu; accu = Field(env, 2); Next;
    Instruct(PUSHENVACC3):
      *--sp = accu; accu = Field(env, 3); Next;
    Instruct(PUSHENVACC4):
      *--sp = accu; accu = Field(env, 4); Next;
@

<<[[interpreter()]] env access before ENVACC case>>=
Instruct(PUSHENVACC):
  *--sp = accu;
  /* Fallthrough */
@
\fi

\subsection{Blocks}
% Heap operations?
% have seen stack, env, ints, now it's about heap?

% it's about the Is_block()

\subsubsection{Blocks allocation}

<<blocks allocation opcodes>>=
ATOM,
MAKEBLOCK,
@


<<[[interpreter()]] blocks allocation cases>>=
/* Allocation of blocks */
    <<[[interpreter()]] before ATOM case>>
    Instruct(ATOM):
      accu = Atom(*pc++); Next;

    Instruct(MAKEBLOCK): {
      mlsize_t wosize = *pc++;
      tag_t tag = *pc++;
      mlsize_t i;
      value block;
      Alloc_small(block, wosize, tag);
      Field(block, 0) = accu;
      for (i = 1; i < wosize; i++) Field(block, i) = *sp++;
      accu = block;
      Next;
    }
@
% will see Alloc_small later

<<blocks allocation opcodes>>=
  PUSHATOM,
  ATOM0, PUSHATOM0, 
  MAKEBLOCK1, MAKEBLOCK2, MAKEBLOCK3,
@


\ifallcode
<<[[interpreter()]] before ATOM case>>=
Instruct(PUSHATOM):
  *--sp = accu;
  /* Fallthrough */
@

<<[[interpreter()]] blocks allocation cases>>=
    Instruct(PUSHATOM0):
      *--sp = accu;
      /* Fallthrough */
    Instruct(ATOM0):
      accu = Atom(0); Next;

    Instruct(MAKEBLOCK1): {
      tag_t tag = *pc++;
      value block;
      Alloc_small(block, 1, tag);
      Field(block, 0) = accu;
      accu = block;
      Next;
    }
    Instruct(MAKEBLOCK2): {
      tag_t tag = *pc++;
      value block;
      Alloc_small(block, 2, tag);
      Field(block, 0) = accu;
      Field(block, 1) = sp[0];
      sp += 1;
      accu = block;
      Next;
    }
    Instruct(MAKEBLOCK3): {
      tag_t tag = *pc++;
      value block;
      Alloc_small(block, 3, tag);
      Field(block, 0) = accu;
      Field(block, 1) = sp[0];
      Field(block, 2) = sp[1];
      sp += 2;
      accu = block;
      Next;
    }
@
\fi


\subsubsection{Blocks access}

<<blocks access opcodes>>=
GETFIELD,
SETFIELD,
@


<<[[interpreter()]] other local variables>>=
value * modify_dest, modify_newval;
@


<<[[interpreter()]] blocks access cases>>=
/* Access to components of blocks */
    Instruct(GETFIELD):
      accu = Field(accu, *pc); pc++; Next;

    Instruct(SETFIELD):
      modify_dest = &Field(accu, *pc);
      pc++;
      modify_newval = *sp++;
      goto modify;

    <<[[interpreter()]] before modify label>>
    modify:
      Modify(modify_dest, modify_newval);
      accu = Val_unit;
      Next;
@

%http://web.archive.org/web/20111114164033/http://eigenclass.org/R2/writings/optimizing-caml_modify

<<function [[Modify]]>>=
/* You must use [Modify] to change a field of an existing shared block,
   unless you are sure the value being overwritten is not a shared block and
   the value being written is not a young block. */
/* [Modify] never calls the GC. */

#define Modify(fp, val) {                                                   \
  value _old_ = *(fp);                                                      \
  *(fp) = (val);                                                            \
  if (Is_in_heap (fp)){                                                     \
    if (gc_phase == Phase_mark) darken (_old_, NULL);                       \
    if (Is_block (val) && Is_young (val)                                    \
        && ! (Is_block (_old_) && Is_young (_old_))){                       \
      *ref_table_ptr++ = (fp);                                              \
      if (ref_table_ptr >= ref_table_limit){                                \
        Assert (ref_table_ptr == ref_table_limit);                          \
        realloc_ref_table ();                                               \
      }                                                                     \
    }                                                                       \
  }                                                                         \
}                                                                           \
@

<<function [[modify]]>>=
/* You must use [modify] to change a field of an existing shared block,
   unless you are sure the value being overwritten is not a shared block and
   the value being written is not a young block. */
/* [modify] never calls the GC. */
void modify (value *fp, value val)
{
  Modify (fp, val);
}
@




<<blocks access opcodes>>=
  GETFIELD0, GETFIELD1, GETFIELD2, GETFIELD3,
  SETFIELD0, SETFIELD1, SETFIELD2, SETFIELD3,
@

\ifallcode

<<[[interpreter()]] before modify label>>=
Instruct(SETFIELD0):
  modify_dest = &Field(accu, 0);
  modify_newval = *sp++;
/* Fallthrough */
@

<<[[interpreter()]] blocks access cases>>=

    Instruct(GETFIELD0):
      accu = Field(accu, 0); Next;
    Instruct(GETFIELD1):
      accu = Field(accu, 1); Next;
    Instruct(GETFIELD2):
      accu = Field(accu, 2); Next;
    Instruct(GETFIELD3):
      accu = Field(accu, 3); Next;

    Instruct(SETFIELD1):
      modify_dest = &Field(accu, 1);
      modify_newval = *sp++;
      goto modify;
    Instruct(SETFIELD2):
      modify_dest = &Field(accu, 2);
      modify_newval = *sp++;
      goto modify;
    Instruct(SETFIELD3):
      modify_dest = &Field(accu, 3);
      modify_newval = *sp++;
      goto modify;
@
\fi

\subsection{Global data access}
% so have seen stack, heap, now it's about data section?

%todo: what are those globals?

<<global data access opcodes>>=
GETGLOBAL, 
SETGLOBAL, 
@


<<global [[global_data]]>>=
value global_data;
@

% see also meta.mli?

<<[[interpreter()]] global data access cases>>=
    <<[[interpreter()]] before GETGLOBAL case>>
    Instruct(GETGLOBAL):
      accu = Field(global_data, *pc);
      pc++;
      Next;

    Instruct(SETGLOBAL):
      modify(&Field(global_data, *pc), accu);
      accu = Val_unit;
      pc++;
      Next;
@

<<global data access opcodes>>=
GETGLOBALFIELD,
@
% GETGLOBALFIELD is kind of a composite no?

<<[[interpreter()]] global data access cases>>=
    <<[[interpreter()]] before GETGLOBALFIELD case>>
    Instruct(GETGLOBALFIELD): {
      accu = Field(global_data, *pc);
      pc++;
      accu = Field(accu, *pc);
      pc++;
      Next;
    }
@


<<global data access opcodes>>=
  PUSHGETGLOBAL, PUSHGETGLOBALFIELD, 
@

\ifallcode

<<[[interpreter()]] before GETGLOBAL case>>=
Instruct(PUSHGETGLOBAL):
  *--sp = accu;
  /* Fallthrough */
@

<<[[interpreter()]] before GETGLOBALFIELD case>>=
Instruct(PUSHGETGLOBALFIELD):
  *--sp = accu;
  /* Fallthrough */
@

\fi

\subsection{Branching operations}

<<branching opcodes>>=
BRANCH, 
BRANCHIF, 
BRANCHIFNOT, 
SWITCH, 
BOOLNOT,
@

% note the += here, so jumps are relative!
<<[[interpreter()]] branching cases>>=
/* Branches and conditional branches */

    Instruct(BRANCH):
      pc += *pc;
      Next;
    Instruct(BRANCHIF):
      if (accu != Val_false) pc += *pc; else pc++;
      Next;
    Instruct(BRANCHIFNOT):
      if (accu == Val_false) pc += *pc; else pc++;
      Next;
    Instruct(SWITCH): {
      uint32 sizes = *pc++;
      if (Is_block(accu)) {
        long index = Tag_val(accu);
        Assert(index >= 0 && index < (sizes >> 16));
        pc += pc[(sizes & 0xFFFF) + index];
      } else {
        long index = Long_val(accu);
        if ((unsigned long) index < (sizes & 0xFFFF))
          pc += pc[index];
        else
          pc += (sizes & 0xFFFF) + (sizes >> 16);
      }
      Next;
    }
    Instruct(BOOLNOT):
      accu = Val_not(accu);
      Next;
@

\subsection{Function application}

<<function application opcodes>>=
PUSH_RETADDR, 
APPLY, 
APPTERM, 
RETURN, 
@


<<function [[Code_val]]>>=
#define Code_val(val) (((code_t *) (val)) [0])     /* Also an l-value. */
@
\t how does it work? what is the value??
% see code for closure:
%      Alloc_small(accu, 1 + nvars, Closure_tag);
%      Code_val(accu) = pc + *pc;
% so code is a block and pc is in first field

% pc + *pc! so jumps are relative.
<<[[interpreter()]] function application cases>>=
/* Function application */

    Instruct(PUSH_RETADDR): {
      sp -= 3;
      sp[0] = (value) (pc + *pc);
      sp[1] = env;
      sp[2] = Val_long(extra_args);
      pc++;
      Next;
    }
    Instruct(APPLY): {
      extra_args = *pc - 1;
      pc = Code_val(accu);
      env = accu;
      goto check_stacks;
    }
    Instruct(APPTERM): {
      int nargs = *pc++;
      int slotsize = *pc;
      value * newsp;
      int i;
      /* Slide the nargs bottom words of the current frame to the top
         of the frame, and discard the remainder of the frame */
      newsp = sp + slotsize - nargs;
      for (i = nargs - 1; i >= 0; i--) newsp[i] = sp[i];
      sp = newsp;
      pc = Code_val(accu);
      env = accu;
      extra_args += nargs - 1;
      goto check_stacks;
    }
    Instruct(RETURN): {
      sp += *pc++;
      if (extra_args > 0) {
        extra_args--;
        pc = Code_val(accu);
        env = accu;
      } else {
        pc = (code_t)(sp[0]);
        env = sp[1];
        extra_args = Long_val(sp[2]);
        sp += 3;
      }
      Next;
    }
@


<<[[interpreter()]] before [[CHECK_SIGNALS]] case>>=
/* Stack checks */

    check_stacks:
      if (sp < stack_threshold) {
        extern_sp = sp;
        realloc_stack();
        sp = extern_sp;
      }
      /* Fall through CHECK_SIGNALS */
@


<<function application opcodes>>=
  APPLY1, APPLY2, APPLY3,
  APPTERM1, APPTERM2, APPTERM3, 
@

% no allcode here, it's an important difference
<<[[interpreter()]] function application cases>>=
    Instruct(APPLY1): {
      value arg1 = sp[0];
      sp -= 3;
      sp[0] = arg1;
      sp[1] = (value)pc;
      sp[2] = env;
      sp[3] = Val_long(extra_args);
      pc = Code_val(accu);
      env = accu;
      extra_args = 0;
      goto check_stacks;
    }
    Instruct(APPLY2): {
      value arg1 = sp[0];
      value arg2 = sp[1];
      sp -= 3;
      sp[0] = arg1;
      sp[1] = arg2;
      sp[2] = (value)pc;
      sp[3] = env;
      sp[4] = Val_long(extra_args);
      pc = Code_val(accu);
      env = accu;
      extra_args = 1;
      goto check_stacks;
    }
    Instruct(APPLY3): {
      value arg1 = sp[0];
      value arg2 = sp[1];
      value arg3 = sp[2];
      sp -= 3;
      sp[0] = arg1;
      sp[1] = arg2;
      sp[2] = arg3;
      sp[3] = (value)pc;
      sp[4] = env;
      sp[5] = Val_long(extra_args);
      pc = Code_val(accu);
      env = accu;
      extra_args = 2;
      goto check_stacks;
    }

    Instruct(APPTERM1): {
      value arg1 = sp[0];
      sp = sp + *pc - 1;
      sp[0] = arg1;
      pc = Code_val(accu);
      env = accu;
      goto check_stacks;
    }
    Instruct(APPTERM2): {
      value arg1 = sp[0];
      value arg2 = sp[1];
      sp = sp + *pc - 2;
      sp[0] = arg1;
      sp[1] = arg2;
      pc = Code_val(accu);
      env = accu;
      extra_args += 1;
      goto check_stacks;
    }
    Instruct(APPTERM3): {
      value arg1 = sp[0];
      value arg2 = sp[1];
      value arg3 = sp[2];
      sp = sp + *pc - 3;
      sp[0] = arg1;
      sp[1] = arg2;
      sp[2] = arg3;
      pc = Code_val(accu);
      env = accu;
      extra_args += 2;
      goto check_stacks;
    }
@



\subsection{Recursive definitions}

<<recursive definition opcodes>>=
DUMMY, 
UPDATE,
@

<<[[interpreter()]] recursive definition cases>>=
/* For recursive definitions */

    Instruct(DUMMY): {
      int size = *pc++;
      Alloc_small(accu, size, 0);
      while (size--) Field(accu, size) = Val_long(0);
      Next;
    }
    Instruct(UPDATE): {
      value newval = *sp++;
      mlsize_t size, n;
      size = Wosize_val(newval);
      Assert(size == Wosize_val(accu));
      Tag_val(accu) = Tag_val(newval);
      for (n = 0; n < size; n++) {
        modify(&Field(accu, n), Field(newval, n));
      }
      accu = Val_unit;
      Next;
    }
@


\subsection{Exceptions}

% can raise exn from .ml, but also from .c

% saw important trapsp "register" before.

<<exception [[opcodes]]>>=
PUSHTRAP, 
POPTRAP, 
RAISE,
@

<<[[interpreter()]] exception cases>>=
/* Exceptions */

    Instruct(PUSHTRAP):
      sp -= 4;
      // push
      Trap_pc(sp) = pc + *pc;
      Trap_link(sp) = trapsp;
      sp[2] = env;
      sp[3] = Val_long(extra_args);
      trapsp = sp;
      pc++;
      Next;

    Instruct(POPTRAP):
      /* We should check here if a signal is pending, to preserve the
         semantics of the program w.r.t. exceptions. Unfortunately,
         process_signal destroys the accumulator, and there is no
         convenient way to preserve it... */
      trapsp = Trap_link(sp);
      sp += 4;
      Next;

    Instruct(RAISE):
    raise_exception:
      if (trapsp >= trap_barrier) debugger(TRAP_BARRIER);
      if (backtrace_active) stash_backtrace(accu, pc, sp);
      // unwind the stack
      sp = trapsp;
      if ((char *) sp >= (char *) stack_high - initial_sp_offset) {
        exn_bucket = accu;
        external_raise = initial_external_raise;
        extern_sp = sp;
        siglongjmp(external_raise->buf, 1);
      }
      // restore
      pc = Trap_pc(sp);
      trapsp = Trap_link(sp);
      env = sp[2];
      extra_args = Long_val(sp[3]);

      sp += 4;
      Next;
@
%TODO: poptrap is better in more recent version of ocaml,
% there is a comment that seems to indicate it better handles
% signals

<<function [[Trap_pc]]>>=
#define Trap_pc(tp) (((code_t *)(tp))[0])
@
<<function [[Trap_link]]>>=
#define Trap_link(tp) (((value **)(tp))[1])
@
% useful? could instead replace by sp[0] = ... no?


% will explain many things later


\subsection{Foreign C calls}


<<foreign C calls opcodes>>=
C_CALLN,
@


<<[[interpreter()]] foreign c calls cases>>=
/* Calling C functions */

    Instruct(C_CALLN): {
      int nargs = *pc++;
      *--sp = accu;
      Setup_for_c_call;
      accu = cprim[*pc](sp + 1, nargs);
      Restore_after_c_call;
      sp += nargs;
      pc++;
      Next;
    }
@

<<constant [[Setup_for_c_call]]>>=
#define Setup_for_c_call { *--sp = env; extern_sp = sp; }
@

<<constant [[Restore_after_c_call]]>>=
#define Restore_after_c_call { sp = extern_sp; env = *sp++; }
@

<<foreign C calls opcodes>>=
  C_CALL1, C_CALL2, C_CALL3, C_CALL4, C_CALL5,
@

\ifallcode
<<[[interpreter()]] foreign c calls cases>>=

    Instruct(C_CALL1):
      Setup_for_c_call;
      accu = cprim[*pc](accu);
      Restore_after_c_call;
      pc++;
      Next;
    Instruct(C_CALL2):
      Setup_for_c_call;
      accu = cprim[*pc](accu, sp[1]);
      Restore_after_c_call;
      sp += 1;
      pc++;
      Next;
    Instruct(C_CALL3):
      Setup_for_c_call;
      accu = cprim[*pc](accu, sp[1], sp[2]);
      Restore_after_c_call;
      sp += 2;
      pc++;
      Next;
    Instruct(C_CALL4):
      Setup_for_c_call;
      accu = cprim[*pc](accu, sp[1], sp[2], sp[3]);
      Restore_after_c_call;
      sp += 3;
      pc++;
      Next;
    Instruct(C_CALL5):
      Setup_for_c_call;
      accu = cprim[*pc](accu, sp[1], sp[2], sp[3], sp[4]);
      Restore_after_c_call;
      sp += 4;
      pc++;
      Next;
@
\fi


\subsection{Signals}

%less: this is subtle, maybe put in advanced topics?

% have implication for threads. see thread.ml comment:
%(* In sleep() below, we rely on the fact that signals are detected
%   only at function applications and beginning of loops,
%   making all other operations atomic. *)


<<signal opcodes>>=
CHECK_SIGNALS,
@

<<[[interpreter()]] signal cases>>=
<<[[interpreter()]] before [[CHECK_SIGNALS]] case>>

/* Signal handling */

    Instruct(CHECK_SIGNALS):    /* accu not preserved */
      if (something_to_do) goto process_signal;
      Next;

    process_signal:
      something_to_do = 0;
      if (force_major_slice){
        Setup_for_gc;
        minor_collection ();
        Restore_after_gc;
      }
      /* If a signal arrives between the following two instructions,
         it will be lost. */
      { int signal_number = pending_signal;
        pending_signal = 0;
        if (signal_number) {
          /* Push a return frame to the current code location */
          sp -= 4;
          sp[0] = Val_int(signal_number);
          sp[1] = (value) pc;
          sp[2] = env;
          sp[3] = Val_long(extra_args);
          /* Branch to the signal handler */
          env = Field(signal_handlers, signal_number);
          pc = Code_val(env);
          extra_args = 0;
        }
      }
      Next;
@

\subsection{Misc}

<<misc opcodes>>=
RESTART, 
GRAB,
CLOSURE, 
CLOSUREREC,
@

<<[[interpreter()]] misc cases>>=
    Instruct(RESTART): {
      int num_args = Wosize_val(env) - 2;
      int i;
      sp -= num_args;
      for (i = 0; i < num_args; i++) sp[i] = Field(env, i + 2);
      env = Field(env, 1);
      extra_args += num_args;
      Next;
    }

    Instruct(GRAB): {
      int required = *pc++;
      if (extra_args >= required) {
        extra_args -= required;
      } else {
        mlsize_t num_args, i;
        num_args = 1 + extra_args; /* arg1 + extra args */
        Alloc_small(accu, num_args + 2, Closure_tag);
        Field(accu, 1) = env;
        for (i = 0; i < num_args; i++) Field(accu, i + 2) = sp[i];
        Code_val(accu) = pc - 3; /* Point to the preceding RESTART instr. */
        sp += num_args;
        pc = (code_t)(sp[0]);
        env = sp[1];
        extra_args = Long_val(sp[2]);
        sp += 3;
      }
      Next;
    }

    Instruct(CLOSURE): {
      int nvars = *pc++;
      int i;
      if (nvars > 0) *--sp = accu;
      Alloc_small(accu, 1 + nvars, Closure_tag);
      Code_val(accu) = pc + *pc;
      for (i = 0; i < nvars; i++) Field(accu, i + 1) = sp[i];
      sp += nvars;
      pc++;
      Next;
    }

    Instruct(CLOSUREREC): {
      int nvars = *pc++;
      int i;
      if (nvars > 0) *--sp = accu;
      Alloc_small(accu, 2 + nvars, Closure_tag);
      Code_val(accu) = pc + *pc;
      Field(accu, 1) = Val_int(0);
      for (i = 0; i < nvars; i++) Field(accu, i + 2) = sp[i];
      sp += nvars;
      modify(&Field(accu, 1), accu);
      pc++;
      Next;
    }
@


\subsection{XXX}


%XXX
<<[[interpreter()]] other local variables>>=
struct longjmp_buffer *    initial_external_raise;
int                        initial_sp_offset;
struct caml__roots_block * initial_local_roots;
int                        initial_callback_depth;
@

%XXX
<<[[interpreter()]] [[initial_xxx]] initialisations>>=
initial_local_roots = local_roots;
initial_sp_offset = (char *) stack_high - (char *) extern_sp;
initial_external_raise = external_raise;
initial_callback_depth = callback_depth;
@




\section{Memory allocation}
% could be in gc section, but it's a bit different

<<constant [[Page_log]]>>=
/* The size of a page for memory management (in bytes) is [1 << Page_log].
   It must be a multiple of [sizeof (long)]. */
#define Page_log 12             /* A page is 4 kilobytes. */
@

<<constant [[Page_size]]>>=
/* Do not change this definition. */
#define Page_size (1 << Page_log)
@




<<function [[alloc]]>>=
value alloc (mlsize_t wosize, tag_t tag)
{
  value result;
  mlsize_t i;

  Assert (wosize > 0);
  if (wosize <= Max_young_wosize){
    Alloc_small (result, wosize, tag);
    if (tag < No_scan_tag){
      for (i = 0; i < wosize; i++) Field (result, i) = 0;
    }
  }else{
    result = alloc_shr (wosize, tag);
    if (tag < No_scan_tag) memset (Bp_val (result), 0, Bsize_wsize (wosize));
    result = check_urgent_gc (result);
  }
  return result;
}

value alloc_small (mlsize_t wosize, tag_t tag)
{
  value result;
  
  Assert (wosize > 0 && wosize <= Max_young_wosize);
  Alloc_small (result, wosize, tag);
  return result;
}
@



<<function [[expand_heap]]>>=
/* Allocate more memory from malloc for the heap.
   Return a block of at least the requested size (in words).
   Return NULL when out of memory.

   Faudrait nettoyer tout ca pour decoupler heap_start de heap_base
   et pour simplifier l'agrandissement de page_table.
*/
static char *expand_heap (mlsize_t request)
{
  char *mem;
  page_table_entry *new_page_table;
  asize_t new_page_table_size;
  asize_t malloc_request;
  asize_t i, more_pages;
  void *block;

  malloc_request = round_heap_chunk_size (Bhsize_wosize (request));
  gc_message ("Growing heap to %luk bytes\n",
              (stat_heap_size + malloc_request) / 1024);
  mem = aligned_malloc (malloc_request + sizeof (heap_chunk_head),
                        sizeof (heap_chunk_head), &block);
  if (mem == NULL){
    gc_message ("No room for growing heap\n", 0);
    return NULL;
  }
  mem += sizeof (heap_chunk_head);
  Chunk_size (mem) = malloc_request;
  Chunk_block (mem) = block;
  Assert (Wosize_bhsize (malloc_request) >= request);
  Hd_hp (mem) = Make_header (Wosize_bhsize (malloc_request), 0, Blue);

  if (mem < heap_start){
    more_pages = -Page (mem);
  }else if (Page (mem + malloc_request) > page_table_size){
    more_pages = Page (mem + malloc_request) - page_table_size;
  }else{
    more_pages = 0;
  }

  if (more_pages != 0){
    new_page_table_size = page_table_size + more_pages;
    new_page_table =
      (page_table_entry *) 
        malloc(new_page_table_size * sizeof(page_table_entry));
    if (new_page_table == NULL){
      gc_message ("No room for growing page table\n", 0);
      free (mem);
      return NULL;
    }
  } else {
    new_page_table = NULL;
    new_page_table_size = 0;
  }

  if (mem < heap_start){
    Assert (more_pages != 0);
    for (i = 0; i < more_pages; i++){
      new_page_table [i] = Not_in_heap;
    }
    bcopy (page_table, new_page_table + more_pages,
           page_table_size * sizeof(page_table_entry));
    Chunk_next (mem) = heap_start;
    heap_start = mem;
  }else{
    char **last;
    char *cur;

    if (mem + malloc_request > heap_end) heap_end = mem + malloc_request;
    if (more_pages != 0){
      for (i = page_table_size; i < new_page_table_size; i++){
        new_page_table [i] = Not_in_heap;
      }
      bcopy (page_table, new_page_table, 
             page_table_size * sizeof(page_table_entry));
    }
    last = &heap_start;
    cur = *last;
    while (cur != NULL && cur < mem){
      last = &(Chunk_next (cur));
      cur = *last;
    }
    Chunk_next (mem) = cur;
    *last = mem;
  }

  if (more_pages != 0){
    free ((char *) page_table);
    page_table = new_page_table;
    page_table_size = new_page_table_size;
  }

  for (i = Page (mem); i < Page (mem + malloc_request); i++){
    page_table [i] = In_heap;
  }
  stat_heap_size += malloc_request;
  return Bp_hp (mem);
}
@

\section{Stack managment}

<<global [[stack_low]]>>=
value * stack_low;
@

<<global [[stack_high]]>>=
value * stack_high;
@

<<global [[stack_threshold]]>>=
value * stack_threshold;
@


<<global [[max_stack_size]]>>=
unsigned long max_stack_size;            /* also used in gc_ctrl.c */
@


<<constant [[Stack_size]]>>=
/* Initial size of stack (bytes). */
#define Stack_size (4096 * sizeof(value))
@

<<constant [[Stack_threshold]]>>=
/* Minimum free size of stack (bytes); below that, it is reallocated. */
#define Stack_threshold (256 * sizeof(value))
@

<<constant [[Max_stack_def]]>>=
/* Default maximum size of the stack (words). */
#define Max_stack_def (256 * 1024)
@


<<function [[init_stack]]>>=
void init_stack (long unsigned int initial_max_size)
{
  stack_low = (value *) stat_alloc(Stack_size);
  stack_high = stack_low + Stack_size / sizeof (value);
  stack_threshold = stack_low + Stack_threshold / sizeof (value);
  extern_sp = stack_high;
  trapsp = stack_high;
  trap_barrier = stack_high + 1;
  max_stack_size = initial_max_size;
  gc_message ("Initial stack limit: %luk bytes\n",
          max_stack_size / 1024 * sizeof (value));
}
@

<<function [[realloc_stack]]>>=
void realloc_stack(void)
{        
  asize_t size;
  value * new_low, * new_high, * new_sp;
  value * p;

  Assert(extern_sp >= stack_low);
  size = stack_high - stack_low;
  if (size >= max_stack_size) raise_stack_overflow();
  size *= 2;
  gc_message ("Growing stack to %luk bytes\n",
              (unsigned long) size * sizeof(value) / 1024);
  new_low = (value *) stat_alloc(size * sizeof(value));
  new_high = new_low + size;

#define shift(ptr) \
    ((char *) new_high - ((char *) stack_high - (char *) (ptr)))

  new_sp = (value *) shift(extern_sp);
  bcopy((char *) extern_sp,
        (char *) new_sp,
        (stack_high - extern_sp) * sizeof(value));
  stat_free(stack_low);
  trapsp = (value *) shift(trapsp);
  trap_barrier = (value *) shift(trap_barrier);
  for (p = trapsp; p < new_high; p = Trap_link(p))
    Trap_link(p) = (value *) shift(Trap_link(p));
  stack_low = new_low;
  stack_high = new_high;
  stack_threshold = stack_low + Stack_threshold / sizeof (value);
  extern_sp = new_sp;

#undef shift
}
@


<<function [[change_max_stack_size]]>>=
void change_max_stack_size (long unsigned int new_max_size)
{
  asize_t size = stack_high - extern_sp + Stack_threshold / sizeof (value);

  if (new_max_size < size) new_max_size = size;
  if (new_max_size != max_stack_size){
    gc_message ("Changing stack limit to %luk bytes\n",
                new_max_size * sizeof (value) / 1024);
  }
  max_stack_size = new_max_size;
}
@


\section{Exceptions}

\subsection{[[setlongmjp()]]}

% this is the basic block to build on to support exception.
% long jump!

% maybe can do a reminder

\subsection{[[raise_buf]] and [[external_raise]]}

<<global [[external_raise]]>>=
struct longjmp_buffer * external_raise;
@



<<struct [[longjmp_buffer]]>>=
struct longjmp_buffer {
  sigjmp_buf buf;
};
@

<<[[interpreter()]] other local variables>>=
struct longjmp_buffer raise_buf;
@
% for exn
<<[[interpreter()]] exception initialisations>>=
if (sigsetjmp(raise_buf.buf, 1)) {
  local_roots = initial_local_roots;
  sp = extern_sp;
  callback_depth = initial_callback_depth;
  accu = exn_bucket;
  pc = NULL;
  goto raise_exception;
}
external_raise = &raise_buf;
@

<<global [[exn_bucket]]>>=
value exn_bucket;
@



\subsection{[[mlraise()]]}


<<function [[mlraise]]>>=
void mlraise(value v)
{
  Assert(! async_signal_mode);
  Unlock_exn();
  exn_bucket = v;
  siglongjmp(external_raise->buf, 1);
}
@


\subsection{[[failwith()]] and basic exceptions}

<<function [[failwith]]>>=
void failwith (char *msg)
{
  raise_with_string(Field(global_data, FAILURE_EXN), msg);
}
@

<<function [[invalid_argument]]>>=
void invalid_argument (char *msg)
{
  raise_with_string(Field(global_data, INVALID_EXN), msg);
}
@


<<constant [[OUT_OF_MEMORY_EXN]]>>=
#define OUT_OF_MEMORY_EXN 0     /* "Out_of_memory" */
@

<<constant [[SYS_ERROR_EXN]]>>=
#define SYS_ERROR_EXN 1         /* "Sys_error" */
@

<<constant [[FAILURE_EXN]]>>=
#define FAILURE_EXN 2           /* "Failure" */
@

<<constant [[INVALID_EXN]]>>=
#define INVALID_EXN 3           /* "Invalid_argument" */
@

<<constant [[END_OF_FILE_EXN]]>>=
#define END_OF_FILE_EXN 4       /* "End_of_file" */
@

<<constant [[ZERO_DIVIDE_EXN]]>>=
#define ZERO_DIVIDE_EXN 5       /* "Division_by_zero" */
@

<<constant [[NOT_FOUND_EXN]]>>=
#define NOT_FOUND_EXN 6         /* "Not_found" */
@

<<constant [[MATCH_FAILURE_EXN]]>>=
#define MATCH_FAILURE_EXN 7     /* "Match_failure" */
@

<<constant [[STACK_OVERFLOW_EXN]]>>=
#define STACK_OVERFLOW_EXN 8    /* "Stack_overflow" */
@



\section{Primitives}

%typedef value (*c_primitive)();
%
%extern c_primitive cprim[];
%extern char * names_of_cprim[];

\section{Foreign calls}

\subsection{Calling C from OCaml}

\subsection{Calling OCaml from C}
% callback.c










\chapter{Garbage Collection}

%http://journal.stuffwithstuff.com/2013/12/08/babys-first-garbage-collector/

%https://medium.com/@octskyward/modern-garbage-collection-911ef4f8bd8e#.7iyq9f6l5

\section{Colors}

% bits 8-9 are for colors in a block header
% and one of Make_header argument is a color

<<constant [[White]]>>=
#define White (0 << 8)
@

<<constant [[Gray]]>>=
#define Gray  (1 << 8)
@

<<constant [[Blue]]>>=
#define Blue  (2 << 8)
@

<<constant [[Black]]>>=
#define Black (3 << 8)
@

\section{Roots}

%/* [register_global_root] registers a global C variable as a memory root
%   for the duration of the program, or until [remove_global_root] is
%   called. */
%
%void register_global_root (value *);
%
%/* [remove_global_root] removes a memory root registered on a global C
%   variable with [register_global_root]. */
%
%void remove_global_root (value *);

<<struct [[caml__roots_block]]>>=
/*
   [Begin_roots] and [End_roots] are used for C variables that are GC roots.
   It must contain all values in C local variables and function parameters
   at the time the minor GC is called.
   Usage:
   After initialising your local variables to legal Caml values, but before
   calling allocation functions, insert [Begin_roots_n(v1, ... vn)], where
   v1 ... vn are your variables of type [value] that you want to be updated
   across allocations.
   At the end, insert [End_roots()].

   Note that [Begin_roots] opens a new block, and [End_roots] closes it.
   Thus they must occur in matching pairs at the same brace nesting level.

   You can use [Val_unit] as a dummy initial value for your variables.
*/


struct caml__roots_block {
  struct caml__roots_block *next;
  long ntables;
  long nitems;
  value *tables [5];
};
@


<<constant [[Begin_root]]>>=
#define Begin_root Begin_roots1
@

<<macro [[Begin_roots1]]>>=
#define Begin_roots1(r0) { \
  struct caml__roots_block caml__roots_block; \
  caml__roots_block.next = local_roots; \
  local_roots = &caml__roots_block; \
  caml__roots_block.nitems = 1; \
  caml__roots_block.ntables = 1; \
  caml__roots_block.tables[0] = &(r0);
@

<<macro [[End_roots]]>>=
#define End_roots() local_roots = caml__roots_block.next; }
@



\section{Mark}

\section{Sweep}

\section{Major collection}

\section{Minor collection}


<<function [[Alloc_small]]>>=
#define Alloc_small(result, wosize, tag) {            Assert (wosize >= 1); \
  young_ptr -= Bhsize_wosize (wosize);                                      \
  if (young_ptr < young_limit){                                             \
    Setup_for_gc;                                                           \
    Garbage_collection_function ();                                         \
    Restore_after_gc;                                                       \
    young_ptr -= Bhsize_wosize (wosize);                                    \
  }                                                                         \
  Hd_hp (young_ptr) = Make_header ((wosize), (tag), Black);                 \
  (result) = Val_hp (young_ptr);                                            \
}
@
% will see gc stuff far later


<<constant [[Garbage_collection_function]]>>=
#define Garbage_collection_function minor_collection
@
% for bytecode


<<function [[minor_collection]]>>=
void minor_collection (void)
{
  value **r;
  long prev_alloc_words = allocated_words;

  in_minor_collection = 1;
  gc_message ("<", 0);
  oldify_local_roots();
  for (r = ref_table; r < ref_table_ptr; r++) oldify (**r, *r);
  stat_minor_words += Wsize_bsize (young_end - young_ptr);
  young_ptr = young_end;
  ref_table_ptr = ref_table;
  ref_table_limit = ref_table_threshold;
  gc_message (">", 0);
  in_minor_collection = 0;

  stat_promoted_words += allocated_words - prev_alloc_words;
  ++ stat_minor_collections;
  major_collection_slice ();
  force_major_slice = 0;
}
@



<<function [[Is_young]]>>=
#define Is_young(val) \
  ((addr)(val) > (addr)young_start && (addr)(val) < (addr)young_end)
@


<<constant [[Max_young_wosize]]>>=
/* Maximum size of a block allocated in the young generation (words). */
/* Must be > 4 */
#define Max_young_wosize 256
@

<<constant [[Minor_heap_min]]>>=
/* Minimum size of the minor zone (words).
   This must be at least [Max_young_wosize + 1]. */
#define Minor_heap_min 4096
@

<<constant [[Minor_heap_max]]>>=
/* Maximum size of the minor zone (words).
   Must be greater than or equal to [Minor_heap_min].
*/
#define Minor_heap_max (1 << 28)
@

<<constant [[Minor_heap_def]]>>=
/* Default size of the minor zone. (words)  */
#define Minor_heap_def 32768
@

\section{Compaction}

\t How can move around things? how code currently running can handle that?
\t  pointers are moved then? 

\section{Tunning, [[CAMLRUNPARAM=xxx]]}

<<function [[parse_camlrunparam]]>>=
static void parse_camlrunparam(void)
{
  char *opt = getenv ("CAMLRUNPARAM");
  if (opt != NULL){
    while (*opt != '\0'){
      switch (*opt++){
      case 's': scanmult (opt, &minor_heap_init); break;
      case 'i': scanmult (opt, &heap_chunk_init); break;
      case 'h': scanmult (opt, &heap_size_init); break;
      case 'l': scanmult (opt, &max_stack_init); break;
      case 'o': scanmult (opt, &percent_free_init); break;
      case 'O': scanmult (opt, &max_percent_free_init); break;
      <<[[parse_camlrunparam()]] switch opt cases>>
      }
    }
  }
}
@
\t use OCAMLRUNPARAM instead

<<function [[scanmult]]>>=
/* The option letter for each runtime option is the first letter of the
   last word of the ML name of the option (see [stdlib/gc.mli]).
   Except for l (maximum stack size) and h (initial heap size).
*/

static void scanmult (char *opt, long unsigned int *var)
{
  char mult = ' ';
  sscanf (opt, "=%lu%c", var, &mult);
  if (mult == 'k') *var = *var * 1024;
  if (mult == 'M') *var = *var * (1024 * 1024);
  if (mult == 'G') *var = *var * (1024 * 1024 * 1024);
}
@








\chapter{Native Code Generation}

%use ARM? or riscv recent backend?
% https://github.com/nojb/riscv-ocamlopt

%understand generated assembly to optimize perf of your program:
% https://janestreet.github.io/ocaml-perf-notes.html

<<constant [[Clflags.native_code]]>>=
let native_code = ref false             (* set to true under ocamlopt *)
@



<<constant [[Clflags.inline_threshold]]>>=
let inline_threshold = ref 10
@

<<constant [[Clflags.keep_asm_file]]>>=
let keep_asm_file = ref false           (* -S *)
@


<<signature [[Config.cmx_magic_number]]>>=
val cmx_magic_number: string
        (* Magic number for compilation unit descriptions *)
@

<<signature [[Config.cmxa_magic_number]]>>=
val cmxa_magic_number: string
        (* Magic number for libraries of compilation unit descriptions *)
@


\section{Runtime tweaks}

<<function [[Is_atom]] (ifdef [[NATIVE_CODE]])>>=
#define Is_atom(v) \
  ((((char *)(v) >= static_data_start && (char *)(v) < static_data_end) || \
   ((v) >= Atom(0) && (v) <= Atom(255))))
@

<<constant [[Garbage_collection_function]] (ifdef [[NATIVE_CODE]])>>=
#define Garbage_collection_function garbage_collection
@





\chapter{Debugging Support}

%input: a flag
<<constant [[Clflags.debug]]>>=
let debug = ref false                   (* -g *)
@
<<[[Main.main()]] command line options>>=
"-g", Arg.Set debug, " Save debugging information";
@

%output: a debugging section in the executable (and before in the cmo's)

% we've seen in linking section that the executable has 
% a debug table (and also in .cmo)

<<[[link_bytecode()]] set pos5 and generate debug infos>>=
let pos5 = pos_out outchan in
if !Clflags.debug then output_debug_info outchan;
@

<<function [[Bytelink.output_debug_info]]>>=
(* Output the debugging information *)
(* Format is:
      <int32>          number of event lists
      <int32>          offset of first event list
      <output_value>   first event list
      ...
      <int32>          offset of last event list
      <output_value>   last event list *)

let output_debug_info oc =
  output_binary_int oc (List.length !debug_info);
  !debug_info |> List.iter (fun (ofs, evl) -> 
    output_binary_int oc ofs; 
    output_string oc evl
  );
  debug_info := []
@
% note that those are event lists! not events
% it just aggregates the debug_event lists in each .cmo
% and add the relocation information of its bytecode.

<<constant [[Bytelink.debug_info]]>>=
(* Relocate and record compilation events *)

let debug_info = ref ([] : (int * string) list)
@
% the string is really a marshalled debug event list
% the int is the pos in the aggregated bytecode, for relocation


% we need to go from charpos+Module -> event

\section{Events}


\subsection{Lambda events}

<<[[Lambda.lambda]] other cases>>=
| Levent of lambda * lambda_event
@

<<type [[Lambda.lambda_event]]>>=
and lambda_event =
  { lev_loc: int;
    lev_kind: lambda_event_kind;
    lev_repr: int ref option;
    lev_env: unit; (*Env.summary*) }
@

<<type [[Lambda.lambda_event_kind]]>>=
and lambda_event_kind =
    Lev_before
  | Lev_after of Types.type_expr
  | Lev_function
@

\subsection{Instruction events}
% for .cmo and for .byte

% this will be marshalled directly in the executable

%(* The ce_stack component gives locations of variables residing 
%   in the stack. The locations are offsets w.r.t. the origin of the
%   stack frame.
%   The ce_heap component gives the positions of variables residing in the
%   heap-allocated environment. *)

<<type [[Instruct.compilation_env]]>>=
(* Structure of compilation environments *)

type compilation_env =
  { ce_stack: int Ident.tbl; (* Positions of variables in the stack *)
    ce_heap: int Ident.tbl } (* Structure of the heap-allocated env *)
@

<<type [[Instruct.debug_event]]>>=
type debug_event =
  { mutable ev_pos: int;                (* Position in bytecode *)
    ev_module: string;                  (* Name of defining module *)
    ev_char: int;                       (* Location in source file *)
    ev_kind: debug_event_kind;          (* Before/after event *)

    ev_info: debug_event_info;          (* Extra information *)
    ev_typenv: unit(*Env.summary*);     (* Typing environment *)
    ev_compenv: compilation_env;        (* Compilation environment *)
    ev_stacksize: int;                  (* Size of stack frame *)
    ev_repr: debug_event_repr }         (* Position of the representative *)
@
% Module + char!! enough for backtrace. and ev_pos (need to be relocated)
% to find which bytecode corresponds to which event

<<type [[Instruct.debug_event_kind]]>>=
and debug_event_kind =
    Event_before
  | Event_after of Types.type_expr
  | Event_pseudo
@

<<type [[Instruct.debug_event_info]]>>=
and debug_event_info =
    Event_function
  | Event_return of int
  | Event_other
@

<<type [[Instruct.debug_event_repr]]>>=
and debug_event_repr =
    Event_none
  | Event_parent of int ref
  | Event_child of int ref
@

\subsection{Bytecode object events}
%  in .cmo?

<<constant [[Emitcode.events]]>>=
(* Debugging events *)

let events = ref ([] : Instruct.debug_event list)
@

<<function [[Emitcode.record_event]]>>=
let record_event ev =
  ev.ev_pos <- !out_position;
  events := ev :: !events
@
% out_position?
% this will be relocated later.

\subsection{Bytecode executable events}

%old:<<function Bytelink.record_events>>=
% bytelink was doing the relocating, but instead we do
% it more lazily for instance when loading the debug_infos
% from the executable

\section{Backtraces}
% simpler than debugger, and illustrates some of the use of
% debug events so can be good to put before the section on the debugger.

<<[[parse_camlrunparam()]] switch opt cases>>=
case 'b': init_backtrace(); break;
@

% ocamlrun -b, or CAMLRUNPARAM=b
% very very very useful
% see fork-efuns on plan9 and Array.get exn, so much easier if have
% full backtrace.

%note: reraise handled nicely by using the address of the exn
% (instead of a special Kreraise as was the case originally)

\section{Interpreter hooks}

\subsection{Debugger opcodes}

<<debugger opcodes>>=
STOP, EVENT, BREAK
@

<<global [[event_count]]>>=
unsigned long event_count;
@

<<[[interpreter()]] debugger cases>>=
/* Debugging and machine control */

    Instruct(STOP):
      external_raise = initial_external_raise;
      extern_sp = sp;
      return accu;

    Instruct(EVENT):
      if (--event_count == 0) {
        Setup_for_debugger;
        debugger(EVENT_COUNT);
        Restore_after_debugger;
      }
      Restart_curr_instr;

    Instruct(BREAK):
      Setup_for_debugger;
      debugger(BREAKPOINT);
      Restore_after_debugger;
      Restart_curr_instr;
@

<<constant [[Setup_for_debugger]]>>=
/* Debugger interface */

#define Setup_for_debugger \
   { sp -= 4; \
     sp[0] = accu; sp[1] = (value)(pc - 1); \
     sp[2] = env; sp[3] = Val_long(extra_args); \
     extern_sp = sp; }
@

<<constant [[Restore_after_debugger]]>>=
#define Restore_after_debugger { sp += 4; }
@


<<macro [[Restart_curr_instr]]>>=
#define Restart_curr_instr \
  curr_instr = saved_code[pc - 1 - start_code]; \
  goto dispatch_instr
@

\ifallcode
<<macro [[Restart_curr_instr]] (if [[THREADED_CODE]])>>=
#define Restart_curr_instr \
  goto *(jumptable[saved_code[pc - 1 - start_code]])
@
\fi

\subsection{Debugger events}

<<enum [[event_kind]]>>=
enum event_kind {
  EVENT_COUNT, BREAKPOINT, PROGRAM_START, PROGRAM_EXIT,
  TRAP_BARRIER, UNCAUGHT_EXC
};
@

\subsection{Debugger protocol}

\subsubsection{Request}

<<enum [[debugger_request]]>>=
/* Requests from the debugger to the runtime system */

enum debugger_request {
  REQ_SET_EVENT = 'e',          /* uint32 pos */
  /* Set an event on the instruction at position pos */
  REQ_SET_BREAKPOINT = 'B',     /* uint32 pos */
  /* Set a breakpoint at position pos */
  REQ_RESET_INSTR = 'i',        /* uint32 pos */
  /* Clear an event or breapoint at position pos, restores initial instr. */
  REQ_CHECKPOINT = 'c',         /* no args */
  /* Checkpoint the runtime system by forking a child process. 
     Reply is pid of child process or -1 if checkpoint failed. */
  REQ_GO = 'g',                 /* uint32 n */
  /* Run the program for n events.
     Reply is one of debugger_reply described below. */
  REQ_STOP = 's',               /* no args */
  /* Terminate the runtime system */
  REQ_WAIT = 'w',               /* no args */
  /* Reap one dead child (a discarded checkpoint). */
  REQ_INITIAL_FRAME = '0',      /* no args */
  /* Set current frame to bottom frame (the one currently executing).
     Reply is stack offset and current pc. */
  REQ_GET_FRAME = 'f',          /* no args */
  /* Return current frame location (stack offset + current pc). */
  REQ_SET_FRAME = 'S',          /* uint32 stack_offset */
  /* Set current frame to given stack offset. No reply. */
  REQ_UP_FRAME = 'U',           /* uint32 n */
  /* Move one frame up. Argument n is size of current frame (in words).
     Reply is stack offset and current pc, or -1 if top of stack reached. */
  REQ_SET_TRAP_BARRIER = 'b',   /* uint32 offset */
  /* Set the trap barrier at the given offset. */
  REQ_GET_LOCAL = 'L',          /* uint32 slot_number */
  /* Return the local variable at the given slot in the current frame.
     Reply is one value. */
  REQ_GET_ENVIRONMENT = 'E',    /* uint32 slot_number */
  /* Return the local variable at the given slot in the heap environment
     of the current frame. Reply is one value. */
  REQ_GET_GLOBAL = 'G',         /* uint32 global_number */
  /* Return the specified global variable. Reply is one value. */
  REQ_GET_ACCU = 'A',           /* no args */
  /* Return the current contents of the accumulator. Reply is one value. */
  REQ_GET_HEADER = 'H',         /* mlvalue v */
  /* As REQ_GET_OBJ, but sends only the header. */
  REQ_GET_FIELD = 'F',          /* mlvalue v, uint32 fieldnum */
  /* As REQ_GET_OBJ, but sends only one field. */
  REQ_MARSHAL_OBJ = 'M',        /* mlvalue v */
  /* Send a copy of the data structure rooted at v, using the same
     format as output_value. */
  REQ_GET_CLOSURE_CODE = 'C'    /* mlvalue v */
  /* Send the code address of the given closure.
     Reply is one uint32. */
};
@

\subsubsection{Reply}

<<enum [[debugger_reply]]>>=
/* Replies to a REQ_GO request. All replies are followed by three uint32:
   - the value of the event counter
   - the position of the stack
   - the current pc. */

enum debugger_reply {
  REP_EVENT = 'e',
  /* Event counter reached 0. */
  REP_BREAKPOINT = 'b',
  /* Breakpoint hit. */
  REP_EXITED = 'x',
  /* Program exited by calling exit or reaching the end of the source. */
  REP_TRAP = 's',
  /* Trap barrier crossed. */
  REP_UNCAUGHT_EXC = 'u'
  /* Program exited due to a stray exception. */
};
@

\subsection{[[debugger()]]}

<<function [[debugger]]>>=
void debugger(enum event_kind event)
{
  int frame_number;
  value * frame;
  long i, pos;
  value val;

  if (dbg_socket == -1) return;  /* Not connected to a debugger. */

  /* Reset current frame */
  frame_number = 0;
  frame = extern_sp + 1;

  /* Report the event to the debugger */
  switch(event) {
  case PROGRAM_START:           /* Nothing to report */
    goto command_loop;
  case EVENT_COUNT:
    putch(dbg_out, REP_EVENT);
    break;
  case BREAKPOINT:
    putch(dbg_out, REP_BREAKPOINT);
    break;
  case PROGRAM_EXIT:
    putch(dbg_out, REP_EXITED);
    break;
  case TRAP_BARRIER:
    putch(dbg_out, REP_TRAP);
    break;
  case UNCAUGHT_EXC:
    putch(dbg_out, REP_UNCAUGHT_EXC);
    break;
  }
  putword(dbg_out, event_count);
  if (event == EVENT_COUNT || event == BREAKPOINT) {
    putword(dbg_out, stack_high - frame);
    putword(dbg_out, (Pc(frame) - start_code) * sizeof(opcode_t));
  } else {
    /* No PC and no stack frame associated with other events */
    putword(dbg_out, 0);
    putword(dbg_out, 0);
  }
  flush(dbg_out);

 command_loop:
  
  /* Read and execute the commands sent by the debugger */
  while(1) {
    switch(getch(dbg_in)) {
    case REQ_SET_EVENT:
      pos = getword(dbg_in);
      Assert(pos >= 0 && pos < code_size);
      set_instruction(start_code + pos / sizeof(opcode_t), EVENT);
      break;
    case REQ_SET_BREAKPOINT:
      pos = getword(dbg_in);
      Assert(pos >= 0 && pos < code_size);
      set_instruction(start_code + pos / sizeof(opcode_t), BREAK);
      break;
    case REQ_RESET_INSTR:
      pos = getword(dbg_in);
      Assert(pos >= 0 && pos < code_size);
      pos = pos / sizeof(opcode_t);
      set_instruction(start_code + pos, saved_code[pos]);
      break;
    case REQ_CHECKPOINT:
      i = fork();
      if (i == 0) {
        close_connection();     /* Close parent connection. */
        open_connection();      /* Open new connection with debugger */
      } else {
        putword(dbg_out, i);
        flush(dbg_out);
      }
      break;
    case REQ_GO:
      event_count = getword(dbg_in);
      return;
    case REQ_STOP:
      exit(0);
      break;
    case REQ_WAIT:
      wait(NULL);
      break;
    case REQ_INITIAL_FRAME:
      frame = extern_sp + 1;
      /* Fall through */
    case REQ_GET_FRAME:
      putword(dbg_out, stack_high - frame);
      putword(dbg_out, (Pc(frame) - start_code) * sizeof(opcode_t));
      flush(dbg_out);
      break;
    case REQ_SET_FRAME:
      i = getword(dbg_in);
      frame = stack_high - i;
      break;
    case REQ_UP_FRAME:
      i = getword(dbg_in);
      if (frame + Extra_args(frame) + i + 3 >= stack_high) {
        putword(dbg_out, -1);
      } else {
        frame += Extra_args(frame) + i + 3;
        putword(dbg_out, stack_high - frame);
        putword(dbg_out, (Pc(frame) - start_code) * sizeof(opcode_t));
      }
      flush(dbg_out);
      break;
    case REQ_SET_TRAP_BARRIER:
      i = getword(dbg_in);
      trap_barrier = stack_high - i;
      break;
    case REQ_GET_LOCAL:
      i = getword(dbg_in);
      putval(dbg_out, Locals(frame)[i]);
      flush(dbg_out);
      break;
    case REQ_GET_ENVIRONMENT:
      i = getword(dbg_in);
      putval(dbg_out, Field(Env(frame), i));
      flush(dbg_out);
      break;
    case REQ_GET_GLOBAL:
      i = getword(dbg_in);
      putval(dbg_out, Field(global_data, i));
      flush(dbg_out);
      break;
    case REQ_GET_ACCU:
      putval(dbg_out, *extern_sp);
      flush(dbg_out);
      break;
    case REQ_GET_HEADER:
      val = getval(dbg_in);
      putword(dbg_out, Hd_val(val));
      flush(dbg_out);
      break;
    case REQ_GET_FIELD:
      val = getval(dbg_in);
      i = getword(dbg_in);
      putval(dbg_out, Field(val, i));
      flush(dbg_out);
      break;
    case REQ_MARSHAL_OBJ:
      val = getval(dbg_in);
      safe_output_value(dbg_out, val);
      flush(dbg_out);
      break;
    case REQ_GET_CLOSURE_CODE:
      val = getval(dbg_in);
      putword(dbg_out, (Code_val(val) - start_code) * sizeof(opcode_t));
      flush(dbg_out);
      break;
    }
  }
}
@

\section{[[ocamldebug]]}

% large, very large.

\chapter{Profiling Support}

% actually there is no flag for profiling in ocamlc?
% need more recent ocaml?

%in recent ocaml
% need to use ocamlcp and then ocamlprof, or ocamlopt -p and gprof








\chapter{Extra Features}
% advanced? hmm not really more advanced, very often it's just sugar
% but I can't use "extensions" either.

% objects? meh can do with records, even super, self, cf native code
%  gen chapter :)
% functors? can be interesting to understand how it's compiled


%less: could put 'when' here too

%less: maybe can put here the  ignore as a builtin so faster
% (so see the %ignore, Pignore, and maybe even instruction)

\section{Records adjustments, [[with]]}

%note: we could have included the construction before, or even merged
% it with Pexpr_record (as originally did by Leroy),
% but better to add a new constructor so can more easily aspectize it.
% We can see how easy it is to extend ocaml when the extension is really
% just sugar.

% AST
<<[[Parsetree.expression_desc]] cases>>=
| Pexp_record_with of expression * (Longident.t * expression) list
@
<<[[Typedtree.expression_desc]] cases>>=
| Texp_record_with of expression * (label_description * expression) list
@

% parsing
<<rule [[simple_expr]] cases>>=
| LBRACE simple_expr WITH lbl_expr_list opt_semi RBRACE
    { mkexp(Pexp_record_with($2, List.rev $4)) }
@
%$

%typing

<<[[Typecore.type_exp()]] match cases>>=
| Pexp_record_with (sexp, lid_sexp_list) ->
    let ty = newvar() in
    let num_fields = ref 0 in
    let type_label_exp (lid, sarg) =
      let label =
        try
          Env.lookup_label lid env
        with Not_found ->
          raise(Error(sexp.pexp_loc, Unbound_label lid)) 
      in
      let (ty_arg, ty_res) = instance_label label in
      (try
        unify env ty_res ty
      with Unify ->
        raise(Error(sexp.pexp_loc, Label_mismatch(lid, ty_res, ty)))
      );
      let arg = type_expect env sarg ty_arg in
      num_fields := Array.length label.lbl_all;
      (label, arg) 
    in
    let lbl_exp_list = List.map type_label_exp lid_sexp_list in

    let rec check_duplicates = function
      [] -> ()
    | (lid, _sarg) :: remainder ->
        if List.mem_assoc lid remainder
        then raise(Error(sexp.pexp_loc, Label_multiply_defined lid))
        else check_duplicates remainder 
    in
    check_duplicates lid_sexp_list;

    let exp = type_expect env sexp ty in

    { exp_desc = Texp_record_with (exp, lbl_exp_list);
      exp_loc = sexp.pexp_loc;
      exp_type = ty }
@
%todo: hmm would be nice to explain which one are missing ...

<<[[Typecore.is_nonexpansive()]] extra cases>>=
| Texp_record_with (exp, lbl_exp_list) ->
    lbl_exp_list |> List.for_all (fun (lbl, exp) -> 
      lbl.lbl_mut = Immutable && is_nonexpansive exp
     ) &&
    is_nonexpansive exp
@      

%compiling

<<[[Translcore.transl_exp()]] cases>>=
| Texp_record_with (init_expr, ((lbl1, _) :: _ as lbl_expr_list)) ->

    let all_labels = lbl1.lbl_all in
    let lv = Array.create (Array.length all_labels) Lstaticfail in
    let init_id = Ident.create "init" in
    for i = 0 to Array.length all_labels - 1 do
      let access =
        match all_labels.(i).lbl_repres with
          Record_regular -> Pfield i
        | Record_float -> Pfloatfield i 
      in
      lv.(i) <- Lprim(access, [Lvar init_id])
    done;

    lbl_expr_list |> List.iter (fun (lbl, expr) -> 
      lv.(lbl.lbl_pos) <- transl_exp expr
    );
    let ll = Array.to_list lv in
    let mut =
      if List.exists (fun (lbl, expr) -> lbl.lbl_mut = Mutable) lbl_expr_list
      then Mutable
      else Immutable in
    let lam =
      try
        if mut = Mutable then raise Not_constant;
        let cl = List.map extract_constant ll in
        match lbl1.lbl_repres with
          Record_regular -> Lconst(Const_block(0, cl))
        | Record_float ->
            Lconst(Const_float_array(List.map extract_float cl))
      with Not_constant ->
        match lbl1.lbl_repres with
            Record_regular -> Lprim(Pmakeblock(0, mut), ll)
          | Record_float -> Lprim(Pmakearray Pfloatarray, ll) 
    in
    Llet(Strict, init_id, transl_exp init_expr, lam)
@

%TODO: port optimisation of 2.02:
%"Changed compilation scheme for "{r with lbl = e}" when r has many fields
%so as to avoid code size explosion."

\section{Arrays}


% AST
<<[[Parsetree.expression_desc]] cases>>=
| Pexp_array of expression list
@
<<[[Typedtree.expression_desc]] cases>>=
| Texp_array of expression list
@


% Lexer
<<[[Lexer.token()]] operator cases>>=
| "[|" { LBRACKETBAR } | "|]" { BARRBRACKET }
@


% Parser
<<rule [[simple_expr]] cases>>=
| LBRACKETBAR expr_semi_list opt_semi BARRBRACKET
    { mkexp(Pexp_array(List.rev $2)) }
| LBRACKETBAR BARRBRACKET
    { mkexp(Pexp_array []) }
@
%$
% sugar
<<rule [[simple_expr]] cases>>=
| simple_expr DOT LPAREN seq_expr RPAREN
    { mkexp(Pexp_apply(mkexp(Pexp_ident(array_function "Array" "get")),
                       [$1; $4])) }
@
%$
<<rule expr cases>>=
| simple_expr DOT LPAREN seq_expr RPAREN LESSMINUS expr
    { mkexp(Pexp_apply(mkexp(Pexp_ident(array_function "Array" "set")),
                       [$1; $4; $7])) }
@
%$


%Typer
<<signatures [[Predef.type_xxx]]>>=
val type_array : type_expr -> type_expr
@
<<constants [[Predef.type_xxx]]>>=
and type_array t = Tconstr(path_array, [t])
@
<<signatures [[Predef.path_xxx]]>>=
val path_array: Path.t
@
<<constants [[Predef.path_xxx]]>>=
and path_array = Pident ident_array
@
%and ident_array = Ident.create "array"

<<[[Predef.build_initial_env()]] decls>>=
let decl_array =
  let tvar = newvar() in
  {type_params = [tvar];
   type_arity = 1;
   type_kind = Type_abstract;
   type_manifest = None}
in
@
%  add_type ident_array decl_array (

<<[[Typecore.type_exp()]] match cases>>=
| Pexp_array(sargl) ->
    let ty = newvar() in
    let argl = List.map (fun sarg -> type_expect env sarg ty) sargl in
    { exp_desc = Texp_array argl;
      exp_loc = sexp.pexp_loc;
      exp_type = Predef.type_array ty }
@

%Compiler
<<[[Lambda.primitive]] array operations cases>>=
| Pmakearray of array_kind
| Parraylength of array_kind
| Parrayrefu of array_kind
| Parraysetu of array_kind
| Parrayrefs of array_kind
| Parraysets of array_kind
@

<<type [[Lambda.array_kind]]>>=
and array_kind =
  | Pgenarray 
  | Paddrarray 
  | Pintarray 
  | Pfloatarray
@


%instruct
<<array opcodes>>=
VECTLENGTH, GETVECTITEM, SETVECTITEM,
@

%interpreter
<<[[interpreter()]] array cases>>=
/* Array operations */

    Instruct(VECTLENGTH):
      accu = Val_long(Wosize_val(accu));
      Next;
    Instruct(GETVECTITEM):
      accu = Field(accu, Long_val(sp[0]));
      sp += 1;
      Next;
    Instruct(SETVECTITEM):
      modify_dest = &Field(accu, Long_val(sp[0]));
      modify_newval = sp[1];
      sp += 2;
      goto modify;
@

%Array.get external spec:
%Array.set external spec:

%runtime support
<<function [[array_get]]>>=
value array_get(value array, value index)   /* ML */
{
  long idx = Long_val(index);
  if (idx < 0 || idx >= Wosize_val(array)) invalid_argument("Array.get");
  return Field(array, idx);
}
@

<<function [[array_set]]>>=
value array_set(value array, value index, value newval)   /* ML */
{
  long idx = Long_val(index);
  if (idx < 0 || idx >= Wosize_val(array)) invalid_argument("Array.set");
  Modify(&Field(array, idx), newval);
  return Val_unit;
}
@

<<function [[make_vect]]>>=
value make_vect(value len, value init)      /* ML */
{
  value res;
  mlsize_t size, i;

  size = Long_val(len);
  if (size > Max_wosize) invalid_argument("Array.make");

  Begin_root(init);
    if (size == 0) {
      res = Atom(0);
    }
    else if (size < Max_young_wosize) {
      res = alloc(size, 0);
      for (i = 0; i < size; i++) Field(res, i) = init;
    }
    else if (Is_block(init) && Is_young(init)) {
      minor_collection();
      res = alloc_shr(size, 0);
      for (i = 0; i < size; i++) Field(res, i) = init;
      res = check_urgent_gc (res);
    }
    else {
      res = alloc_shr(size, 0);
      for (i = 0; i < size; i++) initialize(&Field(res, i), init);
      res = check_urgent_gc (res);
    }
  End_roots();
  return res;
}
@

\subsection{[[-unsafe]]}

<<constant [[Clflags.fast]]>>=
let fast = ref false                    (* -unsafe *)
@

<<[[Main.main()]] command line options>>=
"-unsafe", Arg.Set fast,
      " No bounds checking on array and string access";
@

<<function [[Parser.array_function]]>>=
let array_function str name =
  Ldot(Lident str, (if !Clflags.fast then "unsafe_" ^ name else name))
@

\section{Floats}

% lambda
<<[[Lambda.primitive]] float operations cases>>=
| Pintoffloat | Pfloatofint
| Pnegfloat | Pabsfloat
| Paddfloat | Psubfloat | Pmulfloat | Pdivfloat
| Pfloatcomp of comparison
@

% values
<<constant [[Double_tag]]>>=
/* Floating-point numbers. */
#define Double_tag 253
@

% bytecode
% no builtins? float operations are regular C external calls?

\subsection{Floats array optimisation}

<<[[Lambda.structured_constant]] other cases>>=
| Const_float_array of string list
@

<<[[Lambda.primitive]] operations on heap blocks other cases>>=
| Pfloatfield of int
| Psetfloatfield of int
@

<<constant [[Double_array_tag]]>>=
/* Arrays of floating-point numbers. */
#define Double_array_tag 254
@

\section{Character ranges patterns}

<<[[Lexer.token()]] operator cases>>=
| ".." { DOTDOT }
@

<<rule [[simple_pattern]] other cases>>=
| CHAR DOTDOT CHAR
    { mkrangepat $1 $3 }
@

<<function [[Parser.mkrangepat]]>>=
let rec mkrangepat c1 c2 =
  if c1 > c2 
  then mkrangepat c2 c1 
  else
    if c1 = c2 
    then mkpat(Ppat_constant(Const_char c1)) 
    else mkpat(Ppat_or(mkpat(Ppat_constant(Const_char c1)),
                       mkrangepat (Char.chr(Char.code c1 + 1)) c2))
@
% simple :) recursive unsugaring!

\section{Strings}

% sugar, .[], .[] <-
<<rule [[simple_expr]] cases>>=
| simple_expr DOT LBRACKET seq_expr RBRACKET
    { mkexp(Pexp_apply(mkexp(Pexp_ident(array_function "String" "get")),
                       [$1; $4])) }
@

<<rule expr cases>>=
| simple_expr DOT LBRACKET seq_expr RBRACKET LESSMINUS expr
    { mkexp(Pexp_apply(mkexp(Pexp_ident(array_function "String" "set")),
                       [$1; $4; $7])) }
@
%$
% meh


%codegen
<<[[Lambda.primitive]] string operations cases>>=
| Pstringlength | Pstringrefu | Pstringsetu | Pstringrefs | Pstringsets
@

<<string opcodes>>=
GETSTRINGCHAR, SETSTRINGCHAR, 
@

% interpreter
<<[[interpreter()]] string cases>>=
/* String operations */

    Instruct(GETSTRINGCHAR):
      accu = Val_int(Byte_u(accu, Long_val(sp[0])));
      sp += 1;
      Next;
    Instruct(SETSTRINGCHAR):
      Byte_u(accu, Long_val(sp[0])) = Int_val(sp[1]);
      sp += 2;
      accu = Val_unit;
      Next;
@

% values
<<constant [[String_tag]]>>=
/* Strings. */
#define String_tag 252
@

\section{[[assert()]], and [[-noassert]]}

<<[[Lexer.keyword_table]] elements>>=
"assert", ASSERT;
@

<<rule expr cases>>=
| ASSERT simple_expr %prec prec_appl
    { mkassert $2 }
@
%$

% assert x --> ()  |   raise Assert_failure ... if noassert flag is set
<<function [[Parser.mkassert]]>>=
let mkassert e =
  let {loc_start = st; loc_end = en} = Location.symbol_loc () in
  let triple = mkexp (Pexp_tuple
                       [mkexp (Pexp_constant (Const_string !input_name));
                        mkexp (Pexp_constant (Const_int st));
                        mkexp (Pexp_constant (Const_int en))]) in
  let ex = Ldot (Lident "Pervasives", "Assert_failure") in
  let bucket = mkexp (Pexp_construct (ex, Some triple)) in
  let ra = Ldot (Lident "Pervasives", "raise") in
  let raiser = mkexp (Pexp_apply (mkexp (Pexp_ident ra), [bucket])) in
  let un = mkexp (Pexp_construct (Lident "()", None)) in
  match e with
  | {pexp_desc = Pexp_construct (Lident "false", None) } -> raiser
  | _ -> if !Clflags.noassert
         then un
         else mkexp (Pexp_ifthenelse (e, un, Some raiser))
@

%\section{[[-noassert]]}

<<constant [[Clflags.noassert]]>>=
let noassert = ref false                (* -noassert *)
@
<<[[Main.main()]] command line options>>=
"-noassert", Arg.Set noassert, " Don't compile assertion checks";
@

\section{[[lazy()]] evaluation}

<<[[Lexer.keyword_table]] elements>>=
"lazy", LAZY;
@

<<rule expr cases>>=
| LAZY simple_expr %prec prec_appl
    { mklazy $2 }
@
%$

% lazy x -->  ref (Lazy.Delayed (fun () -> e))
<<function [[Parser.mklazy]]>>=
let mklazy e =
  let void_pat = mkpat (Ppat_construct (Lident "()", None)) in
  let f = mkexp (Pexp_function ([void_pat, e])) in
  let delayed = Ldot (Lident "Lazy", "Delayed") in
  let df = mkexp (Pexp_construct (delayed, Some f)) in
  let r = mkexp (Pexp_ident (Ldot (Lident "Pervasives", "ref"))) in
  mkexp (Pexp_apply (r, [df]))
@

\section{Compile-time reflection, [[deriving]]}
% aka extension points in ocaml, aka attributes in other languages

%http://whitequark.org/blog/2014/04/16/a-guide-to-extension-points-in-ocaml/

% can use it on ocaml compiler source itself! save a whole appendix.
% LOC saved? (vs LOC to implement :) )

\section{Objects}

% deleted. But then compatibility pb? no, just use make boostrap.

%<<oo opcodes>>=
%  GETMETHOD,
%@
%
%<<[[interpreter()]] oo cases>>=
%/* Object-oriented operations */
%
%#define Lookup(obj, lab) \
%  Field (Field (Field (obj, 0), ((lab) >> 16) / sizeof (value)), \
%         ((lab) / sizeof (value)) & 0xFF)
%
%    Instruct(GETMETHOD):
%      accu = Lookup(sp[0], accu);
%      Next;
%@

<<constant [[Object_tag]]>>=
/* Another special case: objects */
#define Object_tag 248
@
%todo: delete? yes!


<<function [[Class_val]]>>=
#define Class_val(val) Field(val, 0)
@

<<function [[Oid_val]]>>=
#define Oid_val(val) Long_val(Field(val, 1))
@

\section{Functors}

\chapter{Standard Library}
% vs one in appendix???

\section{[[Pervasives]]}

\section{Marshalling}
% very useful, used a lot actually in the compiler itself
% to store marshalled values in the .cmo. Also for the debugger
% and backtrace metadata.

\section{Threads}

<<constant [[Clflags.thread_safe]]>>=
let thread_safe = ref false             (* -thread *)
@
<<[[Main.main()]] command line options>>=
"-thread", Arg.Set thread_safe, " Use thread-safe standard library";
@

% needs lots of space to explain the scheduler

% play with extern_sp and fact that
% thread primitives are called first from ML function
% that just call the thread C primitive (see thread.ml)

%look at code of:
% #define Restore_after_c_call { sp = extern_sp; env = *sp++; }
%then look at code of RETURN interpreting.
%If put in sp the right thing, you can return to right stack at right pc.

%in thread.ml
% (* It is mucho important that the primitives that reschedule are called 
%    through an ML function call, not directly. That's because when such a
%    primitive returns, the bytecode interpreter is only semi-obedient:
%    it takes sp from the new thread, but keeps pc from the old thread.
%    But that's OK if all calls to rescheduling primitives are immediately
%    followed by a RETURN operation, which will restore the correct pc
%    from the stack. Furthermore, the RETURNs must all have the same
%    frame size, which means that both the primitives and their ML wrappers
%    must take exactly one argument. *)


\chapter{Advanced Topics}


<<constant [[Clflags.optimize_for_speed]]>>=
let optimize_for_speed = ref true       (* -compact *)
@

\section{Printing types, [[-i]]}

<<constant [[Clflags.print_types]]>>=
let print_types = ref false             (* -i *)
@

<<[[Main.main()]] command line options>>=
"-i", Arg.Set print_types, " Print the types";
@



\section{Preprocessing}
% but extension points better now

<<constant [[Clflags.preprocessor]]>>=
let preprocessor = ref(None : string option) (* -pp *)
@

<<[[Main.main()]] command line options>>=
"-pp", Arg.String(fun s -> preprocessor := Some s),
      "<command>  Pipe sources through preprocessor <command>";
@

<<function [[Compile.preprocess]]>>=
(* Optionally preprocess a source file *)

let preprocess sourcefile tmpfile =
  match !Clflags.preprocessor with
    None -> sourcefile
  | Some pp ->
      let comm = pp ^ " " ^ sourcefile ^ " > " ^ tmpfile in
      if Ccomp.command comm <> 0 then begin
        Printf.eprintf "Preprocessing error\n";
        flush stderr;
        exit 2
      end;
      tmpfile
@

<<function [[Compile.remove_preprocessed]]>>=
let remove_preprocessed inputfile =
  match !Clflags.preprocessor with
    None -> ()
  | Some _ -> remove_file inputfile
@


\subsection{[[#line]]}

% see 5a, lineno is important!

<<[[Lexer.token()]] directive case>>=
| "#" [' ' '\t']* ['0'-'9']+ [' ' '\t']* "\"" [^ '\n' '\r'] *
  ('\n' | '\r' | "\r\n")
    (* # linenum "filename" flags \n *)
    { token lexbuf }
@

<<signature [[Linenum.for_position]]>>=
(* An auxiliary lexer for determining the line number corresponding to
   a file position, honoring the directives # linenum "filename" *)

val for_position: string -> int -> string * int * int
        (* [Linenum.for_position file loc] returns a triple describing
           the location [loc] in the file named [file].
           First result is name of actual source file.
           Second result is line number in that source file.
           Third result is position of beginning of that line in [file]. *)
@
% in linenum.mll

% for syncweb
<<parsing/linenum.ml>>=
@

\section{AST files}
%todo: useful? meh, comment it, so have less noise in ocamlc --help


%  let ast = parse_file inputfile Parse.implementation ast_impl_magic_number in
%  let ast = parse_file inputfile Parse.interface ast_intf_magic_number in

<<signature [[Config.ast_impl_magic_number]]>>=
val ast_impl_magic_number: string
        (* Magic number for file holding an implementation syntax tree *)
@
<<signature [[Config.ast_intf_magic_number]]>>=
val ast_intf_magic_number: string
        (* Magic number for file holding an interface syntax tree *)
@
% ???

<<[[Compile.parse_file()]] let [[is_ast_file]]>>=
let is_ast_file =
  try
    let buffer = Bytes.create (String.length ast_magic) in
    really_input ic buffer 0 (String.length ast_magic);
    if Bytes.to_string buffer = ast_magic then true
    else if String.sub (Bytes.to_string buffer) 0 9 = String.sub ast_magic 0 9 then
      raise Outdated_version
    else false
  with
    Outdated_version ->
      fatal_error "Ocaml and preprocessor have incompatible versions"
  | _ -> false
in
@

<<[[Compile.parse_file()]] if [[is_ast_file]]>>=
if is_ast_file then begin
  Location.input_name := input_value ic;
  input_value ic
end 
@

% useful to unit tests? to not depend on lexer/parser?


\section{[[#!/usr/local/bin/ocamlrun]]}

<<[[link_bytecode()]] copy header>>=
if copy_header then begin
  try
    let inchan = open_in (find_in_path !load_path "camlheader") in
    copy_file inchan outchan;
    close_in inchan
  with Not_found | Sys_error _ -> ()
end;
@


\section{Toplevel interpreter}

% well it looks like an interpreter, but it's really
% an on-the-fly bytecode compiler.

<<Parser entry points types>>=
%start toplevel_phrase                  /* for interactive use */
%type <Parsetree.toplevel_phrase> toplevel_phrase
%start use_file                         /* for the #use directive */
%type <Parsetree.toplevel_phrase list> use_file
@

<<function [[Parser.mkstrexp]]>>=
let mkstrexp e =
  { pstr_desc = Pstr_eval e; pstr_loc = e.pexp_loc }
@
% mv that only for toplevel?

<<entry points rules>>=

toplevel_phrase:
    top_structure SEMISEMI               { Ptop_def $1 }
  | seq_expr SEMISEMI                    { Ptop_def[mkstrexp $1] }
  | toplevel_directive SEMISEMI          { $1 }
  | EOF                                  { raise End_of_file }
;
top_structure:
    structure_item                       { [$1] }
  | structure_item top_structure         { $1 :: $2 }
;
use_file:
    use_file_tail                        { $1 }
  | seq_expr use_file_tail               { Ptop_def[mkstrexp $1] :: $2 }
;
use_file_tail:
    EOF                                         { [] }
  | SEMISEMI EOF                                { [] }
  | SEMISEMI seq_expr use_file_tail             { Ptop_def[mkstrexp $2] :: $3 }
  | SEMISEMI structure_item use_file_tail       { Ptop_def[$2] :: $3 }
  | SEMISEMI toplevel_directive use_file_tail   { $2 :: $3 }
  | structure_item use_file_tail                { Ptop_def[$1] :: $2 }
  | toplevel_directive use_file_tail            { $1 :: $2 }
;

@
%$

<<toplevel [[rules]]>>=
toplevel_directive:
    SHARP ident                 { Ptop_dir($2, Pdir_none) }
  | SHARP ident STRING          { Ptop_dir($2, Pdir_string $3) }
  | SHARP ident INT             { Ptop_dir($2, Pdir_int $3) }
  | SHARP ident val_longident   { Ptop_dir($2, Pdir_ident $3) }
;
@
%$


<<[[Lexer.token()]] operator cases>>=
| ";;" { SEMISEMI }
@

<<signature [[Parse.toplevel_phrase]]>>=
val toplevel_phrase : Lexing.lexbuf -> Parsetree.toplevel_phrase
@

<<signature [[Parse.use_file]]>>=
val use_file : Lexing.lexbuf -> Parsetree.toplevel_phrase list
@

<<function [[Parse.skip_phrase]]>>=
(* Skip tokens to the end of the phrase *)
let rec skip_phrase lexbuf =
  try
    match Lexer.token lexbuf with
      Parser.SEMISEMI | Parser.EOF -> ()
    | _ -> skip_phrase lexbuf
  with
    | Lexer.Error (Lexer.Unterminated_comment, _, _) -> ()
    | Lexer.Error (Lexer.Unterminated_string, _, _) -> ()
    | Lexer.Error(_,_,_) -> skip_phrase lexbuf
@

<<function [[Parse.maybe_skip_phrase]]>>=
let maybe_skip_phrase lexbuf =
  if Parsing.is_current_lookahead Parser.SEMISEMI
  || Parsing.is_current_lookahead Parser.EOF
  then ()
  else skip_phrase lexbuf
@


<<function [[Parse.xxx]]>>=
let toplevel_phrase = wrap Parser.toplevel_phrase
let use_file = wrap Parser.use_file
@

<<signature [[Translmod.transl_toplevel_definition]]>>=
val transl_toplevel_definition: 
  Typedtree.structure -> lambda
@

\subsection{Phrases}

<<type [[Parsetree.toplevel_phrase]]>>=
type toplevel_phrase =
    Ptop_def of structure
  | Ptop_dir of string * directive_argument
@

<<type [[Parsetree.directive_argument]]>>=
and directive_argument =
    Pdir_none
  | Pdir_string of string
  | Pdir_int of int
  | Pdir_ident of Longident.t
@

\section{Interpreter optimisations}
% Threaded interpreter? but can be confusing
% thread in this context means something else

%less: have another special chapter on optimisations?

\subsection{Registers}

<<[[interpreter()]] ifdef [[PC_REG]]>>=
#ifdef PC_REG
  register code_t pc PC_REG;
  register value * sp SP_REG;
  register value accu ACCU_REG;
@

\subsection{Threaded code}

<<macro [[Instruct]] for [[THREADED_CODE]]>>=
#  define Instruct(name) lbl_##name
@

<<macro [[Next]] for [[THREADED_CODE]]>>=
#    define Next goto *(void *)(jumptbl_base + *pc++)
@

<<[[interpreter()]] ifdef [[THREADED_CODE]], [[jumptbl_base]] register declaration>>=
#if defined(THREADED_CODE) && defined(ARCH_SIXTYFOUR) && !defined(ARCH_CODE32)
#ifdef JUMPTBL_BASE_REG
  register char * jumptbl_base JUMPTBL_BASE_REG;
#else
  register char * jumptbl_base;
#endif
#endif
@
% register too!


<<[[interpreter()]] ifdef [[THREADED_CODE]] initialisations>>=
<<[[interpreter()]] ifdef [[THREADED_CODE]], [[jumptable]] declaration>>
if (prog == NULL) {           /* Interpreter is initializing */
  <<[[interpreter()]] ifdef [[THREADED_CODE]], initializing>>
  return Val_unit;
}
<<[[interpreter()]] ifdef [[THREADED_CODE]], [[jumptbl_base]] setting>>
@


<<[[interpreter()]] ifdef [[THREADED_CODE]], [[jumptable]] declaration>>=
#ifdef THREADED_CODE
  static void * jumptable[] = {
#    include "jumptbl.h"
  };
#endif
@




<<[[interpreter()]] ifdef [[THREADED_CODE]], initializing>>=
#ifdef THREADED_CODE
    instr_table = (char **) jumptable; 
    instr_base = Jumptbl_base;
#endif
@

<<[[interpreter()]] ifdef [[THREADED_CODE]], [[jumptbl_base]] setting>>=
#if defined(THREADED_CODE) && defined(ARCH_SIXTYFOUR) && !defined(ARCH_CODE32)
  jumptbl_base = Jumptbl_base;
#endif
@

<<[[interpreter()]] ifdef [[THREADED_CODE]], loop start>>=
#ifdef THREADED_CODE
#ifdef DEBUG
 next_instr:
  if (icount-- == 0) stop_here ();
  Assert(sp >= stack_low);
  Assert(sp <= stack_high);
#endif
  goto *(void *)(jumptbl_base + *pc++); /* Jump to the first instruction */
@



\chapter{Conclusion}







\appendix

\chapter{Debugging}

% tricky when have a bug in ocamlc or ocamlrun itself.
% remember trouble with porting to plan9 and efuns.
% Needed to add backtrace but hard to debug backtrace failing.


\section{Verbose mode, [[-verbose]]}
% different of -v which just print ocaml version and where the libs
% are installed

<<constant [[Clflags.verbose]]>>=
let verbose = ref false                 (* -verbose *)
@
<<[[Main.main()]] command line options>>=
"-verbose", Arg.Unit (fun () ->
                verbose := true;
                Logs.set_level (Some Logs.Info)
              ),
" Print calls to external commands and info level for logs";
(* new: *)
"-debug", Arg.Unit (fun () ->
                verbose := true;
                Logs.set_level (Some Logs.Debug)
              ),
" debug level for logs";
@

% when compiling c stuff, calling linker, compiler, etc -> <>
<<function [[Ccomp.command]]>>=
let command cmdline =
  if !Clflags.verbose then begin
    prerr_string "+ ";
    prerr_string cmdline;
    prerr_newline()
  end;
  let ret = Sys.command cmdline in
  if !Clflags.verbose then begin
    prerr_string "- ";
    prerr_int ret;
    prerr_newline()
  end;
  ret
  
@

\section{Dumpers, [[-dxxx]]}

%later: could be autogenerated! and save lots of boilerplate code?
% use extension points!! deriving!! can even specialize!



\subsection{Typed data structures}

\subsubsection{Primitives}

% primitives
<<signature [[Primitive.print_description]]>>=
val print_description: description -> unit
@


<<function [[Primitive.print_description]]>>=
let print_description p =
  print_quoted p.prim_name;
  if not p.prim_alloc then
    (print_space(); print_quoted "noalloc");
  if p.prim_native_name <> "" then
    (print_space(); print_quoted p.prim_native_name);
  if p.prim_native_float then
    (print_space(); print_quoted "float")
@

<<function [[Primitive.print_quoted]]>>=
let print_quoted s = print_char '"'; print_string s; print_char '"'
@


\subsubsection{Names}

<<signature [[Printtyp.longident]]>>=
val longident: Longident.t -> unit
@

<<signature [[Printtyp.ident]]>>=
val ident: Ident.t -> unit
@

<<signature [[Printtyp.path]]>>=
val path: Path.t -> unit
@






<<function [[Printtyp.longident]]>>=
(* Print a long identifier *)

let rec longident = function
    Lident s -> print_string s
  | Ldot(p, s) -> longident p; print_string "."; print_string s
@

<<function [[Printtyp.ident]]>>=
(* Print an identifier *)

let ident id =
  print_string(Ident.name id)
@

<<constant [[Printtyp.ident_pervasive]]>>=
(* Print a path *)

let ident_pervasive = Ident.create_persistent "Pervasives"
@

<<function [[Printtyp.path]]>>=
let rec path = function
    Pident id ->
      ident id
  | Pdot(Pident id, s, pos) when Ident.same id ident_pervasive ->
      print_string s
  | Pdot(p, s, pos) ->
      path p; print_string "."; print_string s
@


\subsubsection{Types}

<<signature [[Printtyp.type_expr]]>>=
val type_expr: type_expr -> unit
@

<<function [[Printtyp.type_expr]]>>=
let type_expr ty = 
  typexp false 0 ty
@


<<function [[Printtyp.typeexp]]>>=
let rec typexp sch prio = function
    Tvar {tvar_link = Some ty} ->
      typexp sch prio ty
  | Tvar {tvar_link = None; tvar_level = lvl} as v ->
      if (not sch) || lvl = -1 (* generic *)
      then print_string "'"
      else print_string "'_";
      print_string(name_of_var v)
  | Tarrow(ty1, ty2) ->
      if prio >= 1 then begin open_hovbox 1; print_string "(" end
                   else open_hovbox 0;
      typexp sch 1 ty1;
      print_string " ->"; print_space();
      typexp sch 0 ty2;
      if prio >= 1 then print_string ")";
      close_box()
  | Ttuple tyl ->
      if prio >= 2 then begin open_hovbox 1; print_string "(" end
                   else open_hovbox 0;
      typlist sch 2 " *" tyl;
      if prio >= 2 then print_string ")";
      close_box()
  | Tconstr(p, tyl) ->
      open_hovbox 0;
      begin match tyl with
        [] -> ()
      | [ty1] ->
          typexp sch 2 ty1; print_space()
      | tyl ->
          open_hovbox 1; print_string "("; typlist sch 0 "," tyl;
          print_string ")"; close_box(); print_space()
      end;
      path p;
      close_box()

and typlist sch prio sep = function
    [] -> ()
  | [ty] -> typexp sch prio ty
  | ty::tyl ->
      typexp sch prio ty; print_string sep; print_space();
      typlist sch prio sep tyl

@


<<constant [[Printtyp.var_names]]>>=
(* Print a type expression *)

let var_names = ref ([] : (type_expr * string) list)
@
<<constant [[Printtyp.var_counter]]>>=
let var_counter = ref 0
@

<<function [[Printtyp.reset_var_names]]>>=
let reset_var_names () = 
  var_names := []; 
  var_counter := 0
@

<<function [[Printtyp.name_of_var]]>>=
let name_of_var v =
  try
    List.assq v !var_names
  with Not_found ->
    let name = 
      if !var_counter < 26
      then String.make 1 (Char.chr(97 + !var_counter)) 
      else String.make 1 (Char.chr(97 + !var_counter mod 26)) ^
           string_of_int(!var_counter / 26) in
    var_names := (v, name) :: !var_names;
    incr var_counter;
    name
@



\subsubsection{Expressions}

<<signature [[Printtyp.value_description]]>>=
val value_description: Ident.t -> value_description -> unit
@

<<function [[Printtyp.value_description]]>>=
(* Print a value declaration *)

let value_description id decl =
  open_hovbox 2;
  print_string "val "; ident id; print_string " :"; print_space();
  type_scheme decl.val_type;
  begin match decl.val_prim with
    None -> ()
  | Some p -> print_space(); print_string "= "; Primitive.print_description p
  end;
  close_box()
@

<<function [[Printtyp.type_scheme]]>>=
and type_scheme ty = 
  reset_var_names(); 
  typexp true 0 ty
@

\subsubsection{Type declarations}

<<signature [[Printtyp.type_declaration]]>>=
val type_declaration: Ident.t -> type_declaration -> unit
@

<<signature [[Printtyp.exception_declaration]]>>=
val exception_declaration: Ident.t -> exception_declaration -> unit
@


<<function [[Printtyp.type_declaration]]>>=
let rec type_declaration id decl =
  reset_var_names();
  open_hvbox 2;
  print_string "type ";
  type_expr (Tconstr(Pident id, decl.type_params));
  begin match decl.type_manifest with
    None -> ()
  | Some ty -> print_string " ="; print_space(); type_expr ty
  end;
  begin match decl.type_kind with
    Type_abstract -> ()
  | Type_variant [] -> ()
      (* A fatal error actually, except when printing type exn... *)
  | Type_variant (cstr1 :: cstrs) ->
      print_string " ="; print_break 1 2;
      constructor cstr1;
      List.iter
        (fun cstr -> print_space(); print_string "| "; constructor cstr)
        cstrs
  | Type_record (lbl1 :: lbls) ->
      print_string " ="; print_space();
      print_string "{ "; label lbl1;
      List.iter
        (fun lbl -> print_string ";"; print_break 1 2; label lbl)
        lbls;
      print_string " }"
  end;
  close_box()

and constructor (name, args) =
  print_string name;
  match args with
    [] -> ()
  | _  -> print_string " of ";
          open_hovbox 2; typlist false 2 " *" args; close_box()

and label (name, mut, arg) =
  begin match mut with
      Immutable -> ()
    | Mutable -> print_string "mutable "
  end;
  print_string name;
  print_string ": ";
  type_expr arg
@

<<function [[Printtyp.exception_declaration]]>>=
(* Print an exception declaration *)

let exception_declaration id decl =
  print_string "exception "; constructor (Ident.name id, decl)
@

\subsubsection{Modules}

<<signature [[Printtyp.modtype]]>>=
val modtype: module_type -> unit
@

<<signature [[Printtyp.signature]]>>=
val signature: signature -> unit
@



<<function [[Printtyp.modtype]]>>=

let rec modtype = function
    Tmty_ident p ->
      path p
  | Tmty_signature [] ->
      print_string "sig end"
  | Tmty_signature(item :: rem) ->
      open_hvbox 2;
      print_string "sig"; print_space(); 
      signature_item item;
      List.iter
        (fun item -> print_space(); signature_item item)
      rem;
      print_break 1 (-2); print_string "end";
      close_box()

and signature_item = function
    Tsig_value(id, decl) ->
      value_description id decl
  | Tsig_type(id, decl) ->
      type_declaration id decl
  | Tsig_exception(id, decl) ->
      exception_declaration id decl
  | Tsig_module(id, mty) ->
      open_hovbox 2; print_string "module "; ident id; print_string " :";
      print_space(); modtype mty; close_box()

@


<<function [[Printtyp.signature]]>>=
(* Print a signature body (used when compiling a .mli and printing results
   in interactive use). *)

let signature sg =
  open_vbox 0;
  List.iter (fun item -> signature_item item; print_space()) sg;
  close_box()
@





\subsection{Bytecode data structures}

\subsubsection{[[-dlambda]]}

<<constant [[Clflags.dump_lambda]]>>=
let dump_lambda = ref false             (* -dlambda *)
@

<<constant [[Clflags.dump_rawlambda]]>>=
let dump_rawlambda = ref false          (* -drawlambda *)
@
% before simplify

<<[[Main.main()]] command line options>>=
"-dlambda", Arg.Set dump_lambda, " (undocumented)";
"-drawlambda", Arg.Set dump_rawlambda, " (undocumented)";
@



<<signature [[Printlambda.lambda]]>>=
val lambda: lambda -> unit
@


<<function [[Printlambda.lambda]]>>=
let rec lambda = function
    Lvar id ->
      Ident.print id
  | Lconst cst ->
      structured_constant cst
  | Lapply(lfun, largs) ->
      open_box 2;
      print_string "(apply"; print_space();
      lambda lfun;
      List.iter (fun l -> print_space(); lambda l) largs;
      print_string ")";
      close_box()
  | Lfunction(kind, params, body) ->
      open_box 2;
      print_string "(function";
      begin match kind with
        Curried ->
          List.iter (fun param -> print_space(); Ident.print param) params
      | Tupled ->
          print_string " (";
          let first = ref true in
          List.iter
            (fun param ->
              if !first
              then first := false
              else begin print_string ",";print_space() end;
              Ident.print param)
            params
      end;
      print_space(); lambda body; print_string ")"; close_box()
  | Llet(str, id, arg, body) ->
      open_box 2;
      print_string "(let"; print_space();
      open_hvbox 1;
      print_string "(";
      open_box 2; Ident.print id; print_space(); lambda arg; close_box();
      letbody body;
      print_string ")";
      close_box()
  | Lletrec(id_arg_list, body) ->
      open_box 2;
      print_string "(letrec"; print_space();
      print_string "(";
      open_hvbox 1;
      let spc = ref false in
      List.iter
        (fun (id, l) ->
          if !spc then print_space() else spc := true;
          open_box 2;
          Ident.print id; print_space(); lambda l;
          close_box())
        id_arg_list;
      close_box();
      print_string ")";
      print_space(); lambda body;
      print_string ")"; close_box()
  | Lprim(prim, largs) ->
      open_box 2;
      print_string "("; primitive prim;
      List.iter (fun l -> print_space(); lambda l) largs;
      print_string ")";
      close_box()
  | Lswitch(larg, sw) ->
      open_box 1;
      print_string (if sw.sw_checked then "(switch-checked " else "(switch ");
      lambda larg; print_space();
      open_vbox 0;
      let spc = ref false in
      List.iter
        (fun (n, l) ->
          if !spc then print_space() else spc := true;
          open_hvbox 1;
          print_string "case int "; print_int n;
          print_string ":"; print_space();
          lambda l;
          close_box())
        sw.sw_consts;
      List.iter
        (fun (n, l) ->
          if !spc then print_space() else spc := true;
          open_hvbox 1;
          print_string "case tag "; print_int n;
          print_string ":"; print_space();
          lambda l;
          close_box())
        sw.sw_blocks;
      print_string ")"; close_box(); close_box()
  | Lstaticfail ->
      print_string "exit"
  | Lcatch(lbody, lhandler) ->
      open_box 2;
      print_string "(catch"; print_space();
      lambda lbody; print_break 1 (-1);
      print_string "with"; print_space(); lambda lhandler;
      print_string ")";
      close_box()
  | Ltrywith(lbody, param, lhandler) ->
      open_box 2;
      print_string "(try"; print_space();
      lambda lbody; print_break 1 (-1);
      print_string "with "; Ident.print param; print_space();
      lambda lhandler;
      print_string ")";
      close_box()
  | Lifthenelse(lcond, lif, lelse) ->
      open_box 2;
      print_string "(if"; print_space();
      lambda lcond; print_space();
      lambda lif; print_space();
      lambda lelse; print_string ")";
      close_box()
  | Lsequence(l1, l2) ->
      open_box 2;
      print_string "(seq"; print_space();
      lambda l1; print_space(); sequence l2; print_string ")";
      close_box()
  | Lwhile(lcond, lbody) ->
      open_box 2;
      print_string "(while"; print_space();
      lambda lcond; print_space();
      lambda lbody; print_string ")";
      close_box()
  | Lfor(param, lo, hi, dir, body) ->
      open_box 2;
      print_string "(for "; Ident.print param; print_space();
      lambda lo; print_space();
      print_string(match dir with Upto -> "to" | Downto -> "downto");
      print_space();
      lambda hi; print_space();
      lambda body; print_string ")";
      close_box()
  | Lassign(id, expr) ->
      open_box 2;
      print_string "(assign"; print_space();
      Ident.print id; print_space();
      lambda expr; print_string ")";
      close_box()
  | Levent(lam, ev) ->
      open_box 2;
      begin match ev.lev_kind with
        Lev_before   -> print_string "(before "
      | Lev_after _  -> print_string "(after "
      | Lev_function -> print_string "(funct-body "
      end;
      print_int ev.lev_loc;
      print_space();
      lambda lam;
      print_string ")";
      close_box()

and sequence = function
    Lsequence(l1, l2) ->
      sequence l1; print_space(); sequence l2
  | Llet(str, id, arg, body) ->
      open_box 2;
      print_string "let"; print_space();
      Ident.print id; print_space(); lambda arg;
      close_box();
      print_space();
      sequence body
  | l ->
      lambda l

and letbody = function
    Llet(str, id, arg, body) ->
      print_space();
      open_box 2; Ident.print id; print_space(); lambda arg;
      close_box();
      letbody body
  | l ->
      print_string ")";
      close_box();
      print_space();
      lambda l
@


<<signature [[Printlambda.structured_constant]]>>=
val structured_constant: structured_constant -> unit
@


<<function [[Printlambda.structured_constant]]>>=
let rec structured_constant = function
    Const_base(Const_int n) -> print_int n
  | Const_base(Const_char c) ->
      print_string "'"; print_string(Char.escaped c); print_string "'"
  | Const_base(Const_string s) ->
      print_string "\""; print_string(String.escaped s); print_string "\""
  | Const_base(Const_float s) ->
      print_string s
  | Const_pointer n -> print_int n; print_string "a"
  | Const_block(tag, []) ->
      print_string "["; print_int tag; print_string "]"
  | Const_block(tag, sc1::scl) ->
      open_box 1;
      print_string "["; print_int tag; print_string ":";
      print_space();
      open_box 0;
      structured_constant sc1;
      List.iter (fun sc -> print_space(); structured_constant sc) scl;
      close_box();
      print_string "]";
      close_box()
  | Const_float_array [] ->
      print_string "[| |]"
  | Const_float_array (f1 :: fl) ->
      open_box 1;
      print_string "[|";
      open_box 0;
      print_string f1;
      List.iter (fun f -> print_space(); print_string f) fl;
      close_box();
      print_string "|]";
      close_box()
@

<<function [[Printlambda.primitive]]>>=
let primitive = function
    Pidentity -> print_string "id"
  | Pgetglobal id -> print_string "global "; Ident.print id
  | Psetglobal id -> print_string "setglobal "; Ident.print id
  | Pmakeblock(tag, Immutable) -> print_string "makeblock "; print_int tag
  | Pmakeblock(tag, Mutable) -> print_string "makemutable "; print_int tag
  | Pfield n -> print_string "field "; print_int n
  | Psetfield(n, _) -> print_string "setfield "; print_int n
  | Pfloatfield n -> print_string "floatfield "; print_int n
  | Psetfloatfield n -> print_string "setfloatfield "; print_int n
  | Pccall p -> print_string p.prim_name
  | Praise -> print_string "raise"
  | Psequand -> print_string "&&"
  | Psequor -> print_string "||"
  | Pnot -> print_string "not"
  | Pnegint -> print_string "~"
  | Paddint -> print_string "+"
  | Psubint -> print_string "-"
  | Pmulint -> print_string "*"
  | Pdivint -> print_string "/"
  | Pmodint -> print_string "mod"
  | Pandint -> print_string "and"
  | Porint -> print_string "or"
  | Pxorint -> print_string "xor"
  | Plslint -> print_string "lsl"
  | Plsrint -> print_string "lsr"
  | Pasrint -> print_string "asr"
  | Pintcomp(Ceq) -> print_string "=="
  | Pintcomp(Cneq) -> print_string "!="
  | Pintcomp(Clt) -> print_string "<"
  | Pintcomp(Cle) -> print_string "<="
  | Pintcomp(Cgt) -> print_string ">"
  | Pintcomp(Cge) -> print_string ">="
  | Poffsetint n -> print_int n; print_string "+"
  | Poffsetref n -> print_int n; print_string "+:="
  | Pintoffloat -> print_string "int_of_float"
  | Pfloatofint -> print_string "float_of_int"
  | Pnegfloat -> print_string "~."
  | Pabsfloat -> print_string "abs."
  | Paddfloat -> print_string "+."
  | Psubfloat -> print_string "-."
  | Pmulfloat -> print_string "*."
  | Pdivfloat -> print_string "/."
  | Pfloatcomp(Ceq) -> print_string "==."
  | Pfloatcomp(Cneq) -> print_string "!=."
  | Pfloatcomp(Clt) -> print_string "<."
  | Pfloatcomp(Cle) -> print_string "<=."
  | Pfloatcomp(Cgt) -> print_string ">."
  | Pfloatcomp(Cge) -> print_string ">=."
  | Pstringlength -> print_string "string.length"
  | Pstringrefu -> print_string "string.unsafe_get"
  | Pstringsetu -> print_string "string.unsafe_set"
  | Pstringrefs -> print_string "string.get"
  | Pstringsets -> print_string "string.set"
  | Parraylength _ -> print_string "array.length"
  | Pmakearray _ -> print_string "makearray "
  | Parrayrefu _ -> print_string "array.unsafe_get"
  | Parraysetu _ -> print_string "array.unsafe_set"
  | Parrayrefs _ -> print_string "array.get"
  | Parraysets _ -> print_string "array.set"
  | Pisint -> print_string "isint"
  | Pbittest -> print_string "testbit"
@



\subsubsection{[[-dInstr]]}


<<constant [[Clflags.dump_instr]]>>=
let dump_instr = ref false              (* -dinstr *)
@
<<[[Main.main()]] command line options>>=
"-dinstr", Arg.Set dump_instr, " (undocumented)";
@


<<signature [[Printinstr.instruction]]>>=
val instruction: instruction -> unit
@

<<signature [[Printinstr.instrlist]]>>=
val instrlist: instruction list -> unit
@


<<constant [[Printinstr.instruction]]>>=
let instruction = function
    Klabel lbl -> print_string "L"; print_int lbl; print_string ":"
  | Kacc n -> print_string "\tacc "; print_int n
  | Kenvacc n -> print_string "\tenvacc "; print_int n
  | Kpush -> print_string "\tpush"
  | Kpop n -> print_string "\tpop "; print_int n
  | Kassign n -> print_string "\tassign "; print_int n
  | Kpush_retaddr lbl -> print_string "\tpush_retaddr L"; print_int lbl
  | Kapply n -> print_string "\tapply "; print_int n
  | Kappterm(n, m) ->
      print_string "\tappterm "; print_int n; print_string ", "; print_int m
  | Kreturn n -> print_string "\treturn "; print_int n
  | Krestart -> print_string "\trestart"
  | Kgrab n -> print_string "\tgrab "; print_int n
  | Kclosure(lbl, n) ->
      print_string "\tclosure L"; print_int lbl; print_string ", "; print_int n
  | Kclosurerec(lbl, n) ->
      print_string "\tclosurerec L"; print_int lbl;
      print_string ", "; print_int n
  | Kgetglobal id -> print_string "\tgetglobal "; Ident.print id
  | Ksetglobal id -> print_string "\tsetglobal "; Ident.print id
  | Kconst cst ->
      open_box 10; print_string "\tconst"; print_space();
      Printlambda.structured_constant cst; close_box()
  | Kmakeblock(n, m) ->
      print_string "\tmakeblock "; print_int n; print_string ", "; print_int m
  | Kgetfield n -> print_string "\tgetfield "; print_int n
  | Ksetfield n -> print_string "\tsetfield "; print_int n
  | Kdummy n -> print_string "\tdummy "; print_int n
  | Kupdate n -> print_string "\tupdate"; print_int n
  | Kvectlength -> print_string "\tvectlength"
  | Kgetvectitem -> print_string "\tgetvectitem"
  | Ksetvectitem -> print_string "\tsetvectitem"
  | Kgetstringchar -> print_string "\tgetstringchar"
  | Ksetstringchar -> print_string "\tsetstringchar"
  | Kbranch lbl -> print_string "\tbranch L"; print_int lbl
  | Kbranchif lbl -> print_string "\tbranchif L"; print_int lbl
  | Kbranchifnot lbl -> print_string "\tbranchifnot L"; print_int lbl
  | Kstrictbranchif lbl -> print_string "\tstrictbranchif L"; print_int lbl
  | Kstrictbranchifnot lbl ->
      print_string "\tstrictbranchifnot L"; print_int lbl
  | Kswitch(consts, blocks) ->
      open_box 10;
      print_string "\tswitch";
      Array.iter (fun lbl -> print_space(); print_int lbl) consts;
      print_string "/";
      Array.iter (fun lbl -> print_space(); print_int lbl) blocks;
      close_box()
  | Kboolnot -> print_string "\tboolnot"
  | Kpushtrap lbl -> print_string "\tpushtrap L"; print_int lbl
  | Kpoptrap -> print_string "\tpoptrap"
  | Kraise -> print_string "\traise"
  | Kcheck_signals -> print_string "\tcheck_signals"
  | Kccall(s, n) ->
      print_string "\tccall "; print_string s; print_string ", "; print_int n
  | Knegint -> print_string "\tnegint"
  | Kaddint -> print_string "\taddint"
  | Ksubint -> print_string "\tsubint"
  | Kmulint -> print_string "\tmulint"
  | Kdivint -> print_string "\tdivint"
  | Kmodint -> print_string "\tmodint"
  | Kandint -> print_string "\tandint"
  | Korint -> print_string "\torint"
  | Kxorint -> print_string "\txorint"
  | Klslint -> print_string "\tlslint"
  | Klsrint -> print_string "\tlsrint"
  | Kasrint -> print_string "\tasrint"
  | Kintcomp Ceq -> print_string "\teqint"
  | Kintcomp Cneq -> print_string "\tneqint"
  | Kintcomp Clt -> print_string "\tltint"
  | Kintcomp Cgt -> print_string "\tgtint"
  | Kintcomp Cle -> print_string "\tleint"
  | Kintcomp Cge -> print_string "\tgeint"
  | Koffsetint n -> print_string "\toffsetint "; print_int n
  | Koffsetref n -> print_string "\toffsetref "; print_int n
  | Kisint -> print_string "\tisint"
  | Kstop -> print_string "\tstop"
  | Kevent ev -> print_string "\tevent "; print_int ev.ev_char
@

<<constant [[Printinstr.instruction_list]]>>=
let rec instruction_list = function
    [] -> ()
  | Klabel lbl :: il ->
      print_string "L"; print_int lbl; print_string ":"; instruction_list il
  | instr :: il ->
      instruction instr; print_space(); instruction_list il
@

<<function [[Printinstr.instrlist]]>>=
let instrlist il =
  open_vbox 0;
  instruction_list il;
  close_box()
@


\subsection{Native code data structures}

<<constant [[Clflags.dump_cmm]]>>=
let dump_cmm = ref false                (* -dcmm *)
@




<<constant [[Clflags.dump_selection]]>>=
let dump_selection = ref false          (* -dsel *)
@

<<constant [[Clflags.dump_live]]>>=
let dump_live = ref false               (* -dlive *)
@

<<constant [[Clflags.dump_spill]]>>=
let dump_spill = ref false              (* -dspill *)
@

<<constant [[Clflags.dump_split]]>>=
let dump_split = ref false              (* -dsplit *)
@

<<constant [[Clflags.dump_scheduling]]>>=
let dump_scheduling = ref false         (* -dscheduling *)
@

<<constant [[Clflags.dump_interf]]>>=
let dump_interf = ref false             (* -dinterf *)
@

<<constant [[Clflags.dump_prefer]]>>=
let dump_prefer = ref false             (* -dprefer *)
@

<<constant [[Clflags.dump_regalloc]]>>=
let dump_regalloc = ref false           (* -dalloc *)
@

<<constant [[Clflags.dump_reload]]>>=
let dump_reload = ref false             (* -dreload *)
@

<<constant [[Clflags.dump_linear]]>>=
let dump_linear = ref false             (* -dlinear *)
@

\subsubsection{[[-dcmm]]}

\section{[[dump_obj]]}
% for .cmo, and also for .byte

\section{Verbose interpreter, [[ocamlrun -v]]}

<<[[parse_command_line()]] cases>>=
case 'v':
  verbose_init = 1;
  break;
@

<<global [[verbose_init]]>>=
/* Configuration parameters and flags */

static unsigned long verbose_init = 0;
@

<<[[caml_startup_code()]] ifdef [[DEBUG]], set [[verbose_init]]>>=
#ifdef DEBUG
  verbose_init = 1;
#endif
@

% stuff to set gc parameters, also stuff for debugging

<<[[parse_camlrunparam()]] switch opt cases>>=
case 'v': scanmult (opt, &verbose_init); break;
@

\section{Tracing interpreter, [[ocamlrun -t]]}

% but available only when recompiled because
% has a cost and didn't want to pay this cost
% for the regular interpreter.

<<[[parse_command_line()]] cases>>=
#ifdef DEBUG
    case 't':
      trace_flag = 1;
      break;
#endif
@

<<global [[trace_flag]]>>=
int trace_flag = 0;
@

<<global [[icount]]>>=
long icount = 0;
@

<<function [[stop_here]]>>=
void stop_here () {}
@


<<[[interpreter()]] ifdef [[DEBUG]], loop start>>=
#ifdef DEBUG
    if (icount-- == 0) stop_here ();
    if (trace_flag) disasm_instr(pc);
    Assert(sp >= stack_low);
    Assert(sp <= stack_high);
#endif
@

<<macro [[Next]] for [[THREADED_CODE]] ifdef [[DEBUG]]>>=
#    define Next goto next_instr
@


<<function [[disasm_instr]]>>=
void disasm_instr(pc)
     code_t pc;
{
  int instr = *pc;
  printf("%6ld  %s", (long) (pc - start_code),
         instr < 0 || instr > STOP ? "???" : names_of_instructions[instr]);
  pc++;
  switch(instr) {
      /* Instructions with one integer operand */
    case PUSHACC: case ACC: case POP: case ASSIGN:
    case PUSHENVACC: case ENVACC: case PUSH_RETADDR: case APPLY:
    case APPTERM1: case APPTERM2: case APPTERM3: case RETURN:
    case GRAB: case PUSHGETGLOBAL: case GETGLOBAL: case SETGLOBAL:
    case PUSHATOM: case ATOM: case MAKEBLOCK1: case MAKEBLOCK2:
    case MAKEBLOCK3: case GETFIELD: case SETFIELD: case DUMMY:
    case BRANCH: case BRANCHIF: case BRANCHIFNOT: case PUSHTRAP:
    case CONSTINT: case PUSHCONSTINT: case OFFSETINT: case OFFSETREF:
      printf(" %d\n", pc[0]); break;
      /* Instructions with two operands */
    case APPTERM: case CLOSURE: case CLOSUREREC: case PUSHGETGLOBALFIELD:
    case GETGLOBALFIELD: case MAKEBLOCK:
      printf(" %d, %d\n", pc[0], pc[1]); break;
      /* Instructions with a C primitive as operand */
    case C_CALL1: case C_CALL2: case C_CALL3: case C_CALL4: case C_CALL5:
      printf(" %s\n", names_of_cprim[pc[0]]); break;
    case C_CALLN:
      printf(" %d, %s\n", pc[0], names_of_cprim[pc[1]]); break;
    default:
      printf("\n");
    }
}
@

\section{Verbose garbage collector}

<<global [[verb_gc]]>>=
int verb_gc;
@

<<function [[gc_message]]>>=
void gc_message (char *msg, long unsigned int arg)
{
  if (verb_gc){
    fprintf (stderr, msg, arg);
    fflush (stderr);
  }
}
@


\chapter{Profiling}

\chapter{Error Management}

<<signature [[Errors.report_error]]>>=
(* Error report *)

val report_error: exn -> unit
@


% main -> <>
<<function [[Errors.report_error]]>>=
(* Report an error *)

let report_error exn =
  open_box 0;
  begin match exn with
    Lexer.Error(err, start, stop) ->
      Location.print {loc_start = start; loc_end = stop};
      Lexer.report_error err
  | Syntaxerr.Error err ->
      Syntaxerr.report_error err

  | Env.Error err ->
      Env.report_error err
  | Typecore.Error(loc, err) ->
      Location.print loc; Typecore.report_error err
  | Typetexp.Error(loc, err) ->
      Location.print loc; Typetexp.report_error err
  | Typedecl.Error(loc, err) ->
      Location.print loc; Typedecl.report_error err
  | Includemod.Error err ->
      Includemod.report_error err
  | Typemod.Error(loc, err) ->
      Location.print loc; Typemod.report_error err

  | Translcore.Error(loc, err) ->
      Location.print loc; Translcore.report_error err
  | Symtable.Error code ->
      Symtable.report_error code
  | Bytelink.Error code ->
      Bytelink.report_error code
  | Bytelibrarian.Error code ->
      Bytelibrarian.report_error code

  | Sys_error msg ->
      print_string "I/O error: "; print_string msg

  | x ->
      close_box(); raise x
  end;
  close_box(); print_newline()
@



%\section{Location errors}

<<signature [[Location.print]]>>=
val print: t -> unit
@

<<signature [[Location.print_warning]]>>=
val print_warning: t -> string -> unit
@



<<constants [[Location.msg_xxx]]>>=
let (msg_file, msg_line, msg_chars, msg_to, msg_colon, warn_head) =
  match Sys.os_type with
  | _ -> ("File \"", "\", line ", ", characters ", "-", ":", "")
@

<<function [[Location.print]]>>=
let print loc =
  if String.length !input_name = 0 then
    if highlight_locations loc none then () else begin
      print_string "Characters ";
      print_int loc.loc_start; print_string "-";
      print_int loc.loc_end; print_string ":";
      force_newline()
    end
  else begin
    let (filename, linenum, linebeg) =
            Linenum.for_position !input_name loc.loc_start in
    print_string msg_file; print_string filename;
    print_string msg_line; print_int linenum;
    print_string msg_chars; print_int (loc.loc_start - linebeg);
    print_string msg_to; print_int (loc.loc_end - linebeg);
    print_string msg_colon;
    force_newline()
  end
@




<<function [[Location.print_warning]]>>=
let print_warning loc msg =
  let (f1, f2) = Format.get_formatter_output_functions() in
  if not !Sys.interactive then Format.set_formatter_out_channel stderr;
  print loc;
  print_string warn_head;
  print_string "Warning: "; print_string msg; print_newline();
  incr num_loc_lines;
  Format.set_formatter_output_functions f1 f2
@





\section{Fatal errors}
% internal error in compiler, should never happen

% ?? -> <>
<<signature [[Misc.fatal_error]]>>=
val fatal_error: string -> 'a
@

<<exception [[Misc.Fatal_error]]>>=
exception Fatal_error
@

<<function [[Misc.fatal_error]]>>=
let fatal_error msg =
  prerr_string ">> Fatal error: "; prerr_endline msg; raise Fatal_error
@

\section{Lexing errors}

<<type [[Lexer.error]]>>=
type error =
    Illegal_character
  | Unterminated_comment
  | Unterminated_string
@
<<exception [[Lexer.Error]]>>=
exception Error of error * int * int
@
<<signature [[Lexer.report_error]]>>=
val report_error: error -> unit
@

% in .mll
<<function [[Lexer.report_error]]>>=
let report_error = function
    Illegal_character ->
      print_string "Illegal character"
  | Unterminated_comment ->
      print_string "Comment not terminated"
  | Unterminated_string ->
      print_string "String literal not terminated"
@

\section{Syntax errors}

%\subsection{Grammar managment}

% error yacc terminal!
% useful, but in the end not enough! it happens sometimes
% that I got a syntax error at one place but have no idea
% how to close it or how to fix it (usually I then use
% emacs M-x backward-paren to find errors)

<<rule [[module_expr]] error cases>>=
| STRUCT structure error
    { unclosed "struct" 1 "end" 3 }
| LPAREN module_expr COLON module_type error
    { unclosed "(" 1 ")" 5 }
| LPAREN module_expr error
    { unclosed "(" 1 ")" 3 }
@

<<rule [[module_type]] error cases>>=
| SIG signature error
    { unclosed "sig" 1 "end" 3 }
| LPAREN module_type error
    { unclosed "(" 1 ")" 3 }
@

<<rule [[simple_expr]] error cases>>=
| LPAREN seq_expr error
    { unclosed "(" 1 ")" 3 }
| BEGIN seq_expr error
    { unclosed "begin" 1 "end" 3 }
| simple_expr DOT LPAREN seq_expr error
    { unclosed "(" 3 ")" 5 }
| simple_expr DOT LBRACKET seq_expr error
    { unclosed "[" 3 "]" 5 }
| LBRACE lbl_expr_list opt_semi error
    { unclosed "{" 1 "}" 4 }
| LBRACKETBAR expr_semi_list opt_semi error
    { unclosed "[|" 1 "|]" 4 }
| LBRACKET expr_semi_list opt_semi error
    { unclosed "[" 1 "]" 4 }
@

<<rule expr error cases>>=
| TRY seq_expr WITH error %prec prec_try
    { syntax_error() }
@

<<rule [[simple_pattern]] error cases>>=
| LBRACE lbl_pattern_list opt_semi error
    { unclosed "{" 1 "}" 4 }
| LBRACKET pattern_semi_list opt_semi error
    { unclosed "{" 1 "}" 4 }
| LPAREN pattern error
    { unclosed "(" 1 ")" 3 }
| LPAREN pattern COLON core_type error
    { unclosed "(" 1 ")" 5 }
@


<<type [[Syntaxerr.error]]>>=
(* Auxiliary type for reporting syntax errors *)

type error =
    Unclosed of Location.t * string * Location.t * string
  | Other of Location.t
@
%Other for ?
<<exception [[Syntaxerr.Error]]>>=
exception Error of error
@
<<signature [[Syntaxerr.report_error]]>>=
val report_error: error -> unit
@

<<exception [[Syntaxerr.Escape_error]]>>=
exception Escape_error
@
% why not an error case? 



<<function [[Syntaxerr.report_error]]>>=
let report_error = function
    Unclosed(opening_loc, opening, closing_loc, closing) ->
      if String.length !Location.input_name = 0
      && Location.highlight_locations opening_loc closing_loc
      then begin
        print_string "Syntax error: '";
        print_string closing;
        print_string "' expected, the highlighted '";
        print_string opening;
        print_string "' might be unmatched"
      end else begin
        Location.print closing_loc;
        print_string "Syntax error: '";
        print_string closing;
        print_string "' expected"; force_newline();
        Location.print opening_loc;
        print_string "This '";
        print_string opening;
        print_string "' might be unmatched"
      end
  | Other loc ->
      Location.print loc;
      print_string "Syntax error"
@





\section{Naming errors}

<<type [[Env.error]]>>=
(* Error report *)

type error =
    Not_an_interface of string
  | Corrupted_interface of string
  | Illegal_renaming of string * string
@
<<exception [[Env.Error]]>>=
exception Error of error
@
<<signature [[Env.report_error]]>>=
val report_error: error -> unit
@

<<function [[Env.report_error]]>>=
(* Error report *)

let report_error = function
    Not_an_interface filename ->
      print_string filename; print_space();
      print_string "is not a compiled interface."
  | Corrupted_interface filename ->
      print_string "Corrupted compiled interface"; print_space();
      print_string filename
  | Illegal_renaming(modname, filename) ->
      print_string "Wrong file naming:"; print_space();
      print_string filename; print_space();
      print_string "contains the compiled interface for"; print_space();
      print_string modname
@
%TODO: forward port Inconsistent_import check
%  | Inconsistent_import(name, source1, source2) ->
%      open_hvbox 0;
%      print_string "The compiled interfaces for "; print_string source1;
%      print_string " and "; print_string source2; print_space();
%      print_string "make inconsistent assumptions over interface ";
%      print_string name;
%      close_box()


\section{Typing errors}

\subsection*{Types}

<<type [[Typetexp.error]]>>=
type error =
    Unbound_type_variable of string
  | Unbound_type_constructor of Longident.t
  | Type_arity_mismatch of Longident.t * int * int
@
% no unify error?
%TODO: error a la julien? far easier to understand
<<exception [[Typetexp.Error]]>>=
exception Error of Location.t * error
@
<<signature [[Typetexp.report_error]]>>=
val report_error: error -> unit
@


<<function [[Typetexp.report_error]]>>=
let report_error = function
    Unbound_type_variable name ->
      print_string "Unbound type parameter "; print_string name
  | Unbound_type_constructor lid ->
      print_string "Unbound type constructor "; longident lid
  | Type_arity_mismatch(lid, expected, provided) ->
      open_hovbox 0;
      print_string "The type constructor "; longident lid;
      print_space(); print_string "expects "; print_int expected;
      print_string " argument(s),"; print_space();
      print_string "but is here applied to "; print_int provided;
      print_string " argument(s)";
      close_box()
@

\subsection*{Modules}

<<type [[Typemod.error]]>>=
type error =
    Unbound_module of Longident.t
  | Not_included of Includemod.error list
  | Signature_expected
  | Structure_expected of module_type
  | With_no_component of Longident.t
  | Repeated_name of string * string
  | Non_generalizable of type_expr
@
<<exception [[Typemod.Error]]>>=
exception Error of Location.t * error
@
<<signature [[Typemod.report_error]]>>=
val report_error: error -> unit
@


<<function [[Typemod.report_error]]>>=
let report_error = function
    Unbound_module lid ->
      print_string "Unbound module "; longident lid
  | Not_included errs ->
      open_vbox 0;
      print_string "Signature mismatch:"; print_space();
      Includemod.report_error errs;
      close_box()
  | Signature_expected ->
      print_string "This module type is not a signature"
  | Structure_expected mty ->
      open_hovbox 0;
      print_string "This module is not a structure; it has type";
      print_space(); modtype mty;
      close_box()
  | With_no_component lid ->
      print_string "The signature constrained by `with' has no component named";
      print_space(); longident lid
  | Repeated_name(kind, name) ->
      open_hovbox 0;
      print_string "Multiple definition of the "; print_string kind;
      print_string " name "; print_string name; print_string ".";
      print_space();
      print_string "Names must be unique in a given structure.";
      close_box()
  | Non_generalizable typ ->
      open_hovbox 0;
      print_string "The type of this expression,"; print_space();
      type_scheme typ; print_string ","; print_space();
      print_string "contains type variables that cannot be generalized"
@


<<type [[Includemod.error]]>>=
type error =
    Missing_field of Ident.t
  (* X do not match Y *)
  | Value_descriptions of Ident.t * value_description * value_description
  | Type_declarations of Ident.t * type_declaration * type_declaration
  | Exception_declarations of
      Ident.t * exception_declaration * exception_declaration
  | Module_types of module_type * module_type

  | Interface_mismatch of string * string
@
% last one is probably the most classic?
<<exception [[Includemod.Error]]>>=
exception Error of error list
@
<<signature [[Includemod.report_error]]>>=
val report_error: error list -> unit
@


<<function [[Includemod.include_err]]>>=
let include_err = function
    Missing_field id ->
      print_string "The field `"; ident id; 
      print_string "' is required but not provided"
  | Value_descriptions(id, d1, d2) ->
      open_hvbox 2;
      print_string "Values do not match:"; print_space();
      value_description id d1; 
      print_break 1 (-2);
      print_string "is not included in"; print_space();
      value_description id d2;
      close_box()
  | Type_declarations(id, d1, d2) ->
      open_hvbox 2;
      print_string "Type declarations do not match:"; print_space();
      type_declaration id d1; 
      print_break 1 (-2);
      print_string "is not included in"; print_space();
      type_declaration id d2;
      close_box()
  | Exception_declarations(id, d1, d2) ->
      open_hvbox 2;
      print_string "Exception declarations do not match:"; print_space();
      exception_declaration id d1; 
      print_break 1 (-2);
      print_string "is not included in"; print_space();
      exception_declaration id d2;
      close_box()
  | Module_types(mty1, mty2)->
      open_hvbox 2;
      print_string "Modules do not match:"; print_space();
      modtype mty1;
      print_break 1 (-2);
      print_string "is not included in"; print_space();
      modtype mty2;
      close_box()
  | Interface_mismatch(impl_name, intf_name) ->
      open_hovbox 0;
      print_string "The implementation "; print_string impl_name;
      print_space(); print_string "does not match the interface ";
      print_string intf_name;
      print_string ":";
      close_box()
@

<<function [[Includemod.report_error]]>>=
let report_error errlist =
  match errlist with
    [] -> ()
  | err :: rem ->
      open_vbox 0;
      include_err err;
      List.iter (fun err -> print_space(); include_err err) rem;
      close_box()
@

\subsection*{Declarations}

<<type [[Typedecl.error]]>>=
type error =
    Repeated_parameter
  | Duplicate_constructor of string
  | Too_many_constructors
  | Duplicate_label of string
  | Recursive_abbrev of string
  | Definition_mismatch of type_expr
@
<<exception [[Typedecl.Error]]>>=
exception Error of Location.t * error
@
<<signature [[Typedecl.report_error]]>>=
val report_error: error -> unit
@


<<function [[Typedecl.report_error]]>>=
let report_error = function
    Repeated_parameter ->
      print_string "A type parameter occurs several times"
  | Duplicate_constructor s ->
      print_string "Two constructors are named "; print_string s
  | Too_many_constructors ->
      print_string "Too many constructors -- maximum is ";
      print_int Config.max_tag; print_string " constructors"
  | Duplicate_label s ->
      print_string "Two labels are named "; print_string s
  | Recursive_abbrev s ->
      print_string "The type abbreviation "; print_string s;
      print_string " is cyclic"
  | Definition_mismatch ty ->
      print_string
        "The variant or record definition does not match that of type";
      print_space(); Printtyp.type_expr ty
@


\subsection*{Expressions}

<<type [[Typecore.error]]>>=
type error =
    Unbound_value       of Longident.t
  | Unbound_constructor of Longident.t
  | Unbound_label       of Longident.t

  | Constructor_arity_mismatch of Longident.t * int * int
  | Label_mismatch of Longident.t * type_expr * type_expr
  | Pattern_type_clash of type_expr * type_expr

  | Multiply_bound_variable
  | Orpat_not_closed
  | Expr_type_clash of type_expr * type_expr
  | Apply_non_function of type_expr

  | Label_multiply_defined of Longident.t
  | Label_missing
  | Label_not_mutable of Longident.t

  | Bad_format of string

  | Too_many_arguments
@
<<exception [[Typecore.Error]]>>=
exception Error of Location.t * error
@
<<signature [[Typecore.report_error]]>>=
val report_error: error -> unit
@


<<function [[Typecore.report_error]]>>=
let report_error = function
    Unbound_value lid ->
      print_string "Unbound value "; longident lid
  | Unbound_constructor lid ->
      print_string "Unbound constructor "; longident lid
  | Unbound_label lid ->
      print_string "Unbound label "; longident lid
  | Constructor_arity_mismatch(lid, expected, provided) ->
      open_hovbox 0;
      print_string "The constructor "; longident lid;
      print_space(); print_string "expects "; print_int expected;
      print_string " argument(s),"; print_space();
      print_string "but is here applied to "; print_int provided;
      print_string " argument(s)";
      close_box()
  | Label_mismatch(lid, actual, expected) ->
      open_hovbox 0;
      print_string "The label "; longident lid;
      print_space(); print_string "belongs to the type"; print_space();
      type_expr actual; print_space();
      print_string "but is here mixed with labels of type"; print_space();
      type_expr expected;
      close_box()
  | Pattern_type_clash(inferred, expected) ->
      open_hovbox 0;
      print_string "This pattern matches values of type"; print_space();
      type_expr inferred; print_space();
      print_string "but is here used to match values of type"; print_space();
      type_expr expected;
      close_box()
  | Multiply_bound_variable ->
      print_string "This variable is bound several times in this matching"
  | Orpat_not_closed ->
      print_string "A pattern with | must not bind variables"
  | Expr_type_clash(inferred, expected) ->
      open_hovbox 0;
      print_string "This expression has type"; print_space();
      type_expr inferred; print_space();
      print_string "but is here used with type"; print_space();
      type_expr expected;
      close_box()
  | Apply_non_function typ ->
      begin match Ctype.repr typ with
        Tarrow(_, _) ->
          print_string "This function is applied to too many arguments"
      | _ ->
          print_string "This expression is not a function, it cannot be applied"
      end
  | Label_multiply_defined lid ->
      print_string "The label "; longident lid;
      print_string " is defined several times"
  | Label_missing ->
      print_string "Some labels are undefined"
  | Label_not_mutable lid ->
      print_string "The label "; longident lid;
      print_string " is not mutable"
  | Bad_format s ->
      print_string "Bad format `"; print_string s; print_string "'"
  | Too_many_arguments ->
      print_string "This function has too many arguments"
@


\section{Compilation errors}

<<type [[Translcore.error]]>>=
type error =
    Illegal_letrec_pat
  | Illegal_letrec_expr
@
<<exception [[Translcore.Error]]>>=
exception Error of Location.t * error
@
<<signature [[Translcore.report_error]]>>=
val report_error: error -> unit
@

<<constant [[Translcore.report_error]]>>=
let report_error = function
    Illegal_letrec_pat ->
      print_string
      "Only variables are allowed as left-hand side of `let rec'"
  | Illegal_letrec_expr ->
      print_string
      "This kind of expression is not allowed as right-hand side of `let rec'"
@

\section{Linking errors}

<<type [[Bytelink.error]]>>=
type error =
    File_not_found of string
  | Not_an_object_file of string
  | Symbol_error of string * Symtable.error
  | Inconsistent_import of string * string * string
  | Custom_runtime
  | File_exists of string
@
<<exception [[Bytelink.Error]]>>=
exception Error of error
@
<<signature [[Bytelink.report_error]]>>=
val report_error: error -> unit
@



<<constant [[Bytelink.report_error]]>>=
let report_error = function
    File_not_found name ->
      print_string "Cannot find file "; print_string name
  | Not_an_object_file name ->
      print_string "The file "; print_string name;
      print_string " is not a bytecode object file"
  | Symbol_error(name, err) ->
      print_string "Error while linking "; print_string name; print_string ":";
      print_space();
      Symtable.report_error err
  | Inconsistent_import(intf, file1, file2) ->
      open_hvbox 0;
      print_string "Files "; print_string file1; print_string " and ";
      print_string file2; print_space();
      print_string "make inconsistent assumptions over interface ";
      print_string intf;
      close_box()
  | Custom_runtime ->
      print_string "Error while building custom runtime system"
  | File_exists file ->
      print_string "Cannot overwrite existing file "; print_string file
@



<<type [[Bytelibrarian.error]]>>=
type error =
    File_not_found of string
  | Not_an_object_file of string
@
<<exception [[Bytelibrarian.Error]]>>=
exception Error of error
@
<<signature [[Bytelibrarian.report_error]]>>=
val report_error: error -> unit
@


<<constant [[Bytelibrarian.report_error]]>>=
let report_error = function
    File_not_found name ->
      print_string "Cannot find file "; print_string name
  | Not_an_object_file name ->
      print_string "The file "; print_string name;
      print_string " is not a bytecode object file"
@

\chapter{Standard Library}

\section{Generic comparisons}
%byterun/compare.c?

\section{Hash tables}

\section{Strings}

<<function [[string_length]]>>=
mlsize_t string_length(value s)
{
  mlsize_t temp;
  temp = Bosize_val(s) - 1;
  Assert (Byte (s, temp - Byte (s, temp)) == 0);
  return temp - Byte (s, temp);
}
@


<<function [[ml_string_length]]>>=
value ml_string_length(value s)     /* ML */
{
  mlsize_t temp;
  temp = Bosize_val(s) - 1;
  Assert (Byte (s, temp - Byte (s, temp)) == 0);
  return Val_long(temp - Byte (s, temp));
}
@

<<function [[create_string]]>>=
value create_string(value len)        /* ML */
{
  mlsize_t size = Long_val(len);
  if (size > Bsize_wsize (Max_wosize) - 1) invalid_argument("String.create");
  return alloc_string(size);
}
@

<<function [[string_get]]>>=
value string_get(value str, value index)    /* ML */
{
  long idx = Long_val(index);
  if (idx < 0 || idx >= string_length(str)) invalid_argument("String.get");
  return Val_int(Byte_u(str, idx));
}
@

<<function [[string_set]]>>=
value string_set(value str, value index, value newval)    /* ML */
{
  long idx = Long_val(index);
  if (idx < 0 || idx >= string_length(str)) invalid_argument("String.set");
  Byte_u(str, idx) = Int_val(newval);
  return Val_unit;
}
@

<<function [[string_equal]]>>=
value string_equal(value s1, value s2)      /* ML */
{
  mlsize_t sz1 = Wosize_val(s1);
  mlsize_t sz2 = Wosize_val(s2);
  value * p1, * p2;
  if (sz1 != sz2) return Val_false;
  for(p1 = Op_val(s1), p2 = Op_val(s2); sz1 > 0; sz1--, p1++, p2++)
    if (*p1 != *p2) return Val_false;
  return Val_true;
}
@

<<function [[string_notequal]]>>=
value string_notequal(value s1, value s2)   /* ML */
{
  return Val_not(string_equal(s1, s2));
}
@

<<function [[blit_string]]>>=
value blit_string(value s1, value ofs1, value s2, value ofs2, value n)   /* ML */
{
  bcopy(&Byte(s1, Long_val(ofs1)), &Byte(s2, Long_val(ofs2)), Int_val(n));
  return Val_unit;
}
@

<<function [[fill_string]]>>=
value fill_string(value s, value offset, value len, value init) /* ML */
{
  register char * p;
  register mlsize_t n;
  register char c;

  c = Long_val(init);
  for(p = &Byte(s, Long_val(offset)), n = Long_val(len);
      n > 0; n--, p++)
    *p = c;
  return Val_unit;
}
@


\section{IO channels}

\subsection{Output}

<<function [[caml_output]]>>=
value caml_output(value vchannel, value buff, value start, value length) /* ML */
{
  struct channel * channel = Channel(vchannel);
  long pos = Long_val(start);
  long len = Long_val(length);

  Begin_root(buff)
    Lock(channel);
      while (len > 0) {
        int written = putblock(channel, &Byte(buff, pos), len);
        pos += written;
        len -= written;
      }
    Unlock(channel);
  End_roots();
  return Val_unit;
}
@

\subsection{Input}

<<function [[caml_input]]>>=
value caml_input(value vchannel, value buff, value start, value length) /* ML */
{
  struct channel * channel = Channel(vchannel);
  long res;

  Begin_root(buff)
    Lock(channel);
    res = getblock(channel, &Byte(buff, Long_val(start)), Long_val(length));
    Unlock(channel);
  End_roots();
  return Val_long(res);
}
@

\section{Marshalling}

\subsection{Output}

%byterun/extern.c?


% called "structured output"

<<function [[output_value]]>>=
value output_value(value vchan, value v, value flags) /* ML */
{
  struct channel * channel = Channel(vchan);
  Begin_root(v)
    Lock(channel);
    output_val(channel, v, flags);
    Unlock(channel);
  End_roots();
  return Val_unit;
}
@

\subsection{Input}
%byterun/intext.c

<<function [[input_value]]>>=
value input_value(value vchan)        /* ML */
{
  struct channel * chan = Channel(vchan);
  value res = Val_unit;

  Begin_root(res)
    Lock(chan);
    res = input_val(chan);
    Unlock(chan);
  End_roots();
  return res;
}
@

\section{Obj meta module}

<<function [[obj_tag]]>>=
value obj_tag(value arg)                 /* ML */
{
  return Val_int(Tag_val(arg));
}
@

<<function [[obj_is_block]]>>=
value obj_is_block(value arg)             /* ML */
{
  return Val_bool(Is_block(arg));
}
@

\section{Operating system interaction}
%sys.c

\chapter{Containers Library}

\section{Lists}

<<signature [[Misc.map_end]]>>=
val map_end: ('a -> 'b) -> 'a list -> 'b list -> 'b list
        (* [map_end f l t] is [map f l @ t], just more efficient. *)
@

<<signature [[Misc.for_all2]]>>=
val for_all2: ('a -> 'b -> bool) -> 'a list -> 'b list -> bool
        (* Same as [List.for_all] but for a binary predicate. *)
@

<<signature [[Misc.filter]]>>=
val filter: ('a -> bool) -> 'a list -> 'a list
@
%todo: vs List.filter?

<<signature [[Misc.replicate_list]]>>=
val replicate_list: 'a -> int -> 'a list
        (* [replicate_list elem n] is the list with [n] elements
           all identical to [elem]. *)
@

% implem


<<function [[Misc.map_end]]>>=
let rec map_end f l1 l2 =
  match l1 with
    [] -> l2
  | hd::tl -> f hd :: map_end f tl l2
@

<<function [[Misc.for_all2]]>>=
let rec for_all2 pred l1 l2 =
  match (l1, l2) with
    ([], []) -> true
  | (hd1::tl1, hd2::tl2) -> pred hd1 hd2 && for_all2 pred tl1 tl2
  | (_, _) -> false
@

<<function [[Misc.filter]]>>=
let rec filter pred =
  function
    [] ->
      []
  | a::l ->
      if pred a then
        a::(filter pred l)
      else
        filter pred l
@

<<function [[Misc.replicate_list]]>>=
let rec replicate_list elem n =
  if n <= 0 then [] else elem :: replicate_list elem (n-1)
@

\section{Assocs}

<<signature [[Misc.mem_assq]]>>=
val mem_assq: 'a -> ('a * 'b) list -> bool
@

<<function [[Misc.mem_assq]]>>=
let rec mem_assq x = function
    [] -> false
  | (a,_b)::l -> a == x || mem_assq x l
@

\section{Hashes}

<<signature [[Misc.create_hashtable]]>>=
val create_hashtable: int -> ('a * 'b) list -> ('a, 'b) Hashtbl.t
        (* Create a hashtable of the given size and fills it with the
           given bindings. *)
@

<<function [[Misc.create_hashtable]]>>=
let create_hashtable size init =
  let tbl = Hashtbl.create size in
  List.iter (fun (key, data) -> Hashtbl.add tbl key data) init;
  tbl
@

\chapter{Utilities Library}

\section{Files}

<<signature [[Misc.find_in_path]]>>=
val find_in_path: string list -> string -> string
        (* Search a file in a list of directories. *)
@

<<signature [[Misc.remove_file]]>>=
val remove_file: string -> unit
        (* Delete the given file if it exists. Never raise an error. *)
@

<<signature [[Misc.copy_file]]>>=
val copy_file: in_channel -> out_channel -> unit
        (* [copy_file ic oc] reads the contents of file [ic] and copies
           them to [oc]. It stops when encountering EOF on [ic]. *)
@

<<signature [[Misc.copy_file_chunk]]>>=
val copy_file_chunk: in_channel -> out_channel -> int -> unit
        (* [copy_file_chunk ic oc n] reads [n] bytes from [ic] and copies
           them to [oc]. It raises [End_of_file] when encountering
           EOF on [ic]. *)
@



<<function [[Misc.find_in_path]]>>=
let find_in_path path name =
  if not (Filename.is_implicit name) then
    if Sys.file_exists name then name else raise Not_found
  else begin
    let rec try_dir = function
      [] -> raise Not_found
    | dir::rem ->
        let fullname = Filename.concat dir name in
        if Sys.file_exists fullname then fullname else try_dir rem
    in try_dir path
  end
@

<<function [[Misc.remove_file]]>>=
let remove_file filename =
  try
    Sys.remove filename
  with Sys_error _msg ->
    ()
@


<<function [[Misc.copy_file]]>>=
let copy_file ic oc =
  let buff = Bytes.create 0x1000 in
  let rec copy () =
    let n = input ic buff 0 0x1000 in
    if n = 0 then () else (output oc buff 0 n; copy())
  in copy()
@

<<function [[Misc.copy_file_chunk]]>>=
let copy_file_chunk ic oc len =
  let buff = Bytes.create 0x1000 in
  let rec copy n =
    if n <= 0 then () else begin
      let r = input ic buff 0 (min n 0x1000) in
      if r = 0 then raise End_of_file else (output oc buff 0 r; copy(n-r))
    end
  in copy len
@


\section{Math}

<<signature [[Misc.log2]]>>=
val log2: int -> int
        (* [log2 n] returns [s] such that [n = 1 lsl s] 
           if [n] is a power of 2*)
@

<<signature [[Misc.align]]>>=
val align: int -> int -> int
        (* [align n a] rounds [n] upwards to a multiple of [a]
           (a power of 2). *)
@

<<signature [[Misc.no_overflow_add]]>>=
val no_overflow_add: int -> int -> bool
        (* [no_overflow_add n1 n2] returns [true] if the computation of
           [n1 + n2] does not overflow. *)
@

<<signature [[Misc.no_overflow_sub]]>>=
val no_overflow_sub: int -> int -> bool
        (* [no_overflow_add n1 n2] returns [true] if the computation of
           [n1 - n2] does not overflow. *)
@



<<function [[Misc.log2]]>>=
let rec log2 n =
  if n <= 1 then 0 else 1 + log2(n asr 1)
@

<<function [[Misc.align]]>>=
(* @Scheck: dead by nice to have *)
let align n a =
  if n >= 0 then (n + a - 1) land (-a) else n land (-a)
@

<<function [[Misc.no_overflow_add]]>>=
let no_overflow_add a b = (a lxor b) lor (a lxor (lnot (a+b))) < 0
@

<<function [[Misc.no_overflow_sub]]>>=
let no_overflow_sub a b = (a lxor (lnot b)) lor (b lxor (a-b)) < 0
@

\section{Pretty printing}

% lots of use of Format, maybe could be good to explain,
% as it's not as common as other stuff from stdlib/


\chapter{Extra Code}

#include "OCaml_extra.nw"
\ifallcode
#include "OCaml_native.nw"
\fi

%\chapter{Changelog}
%\label{sec:changelog}

\chapter*{Glossary}
\addcontentsline{toc}{chapter}{Glossary}
\label{sec:glossary}

\begin{verbatim}
\end{verbatim}

\chapter*{Indexes}
\addcontentsline{toc}{chapter}{Index}

%\chapter{References} 
\addcontentsline{toc}{chapter}{References}

\bibliography{../docs/latex/Principia}
\bibliographystyle{alpha}

%******************************************************************************
% Postlude
%******************************************************************************

\end{document}

